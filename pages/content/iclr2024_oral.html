
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>PubSummarizer - ICLR 2024 Oral Papers</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <script src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
</head>
<body>
    <div class="container py-4">
        <h1 class="mb-4">ICLR 2024 Oral Papers</h1>
        <p class="text-muted"><em>Generated on 2024-11-18 13:09:33 by <a href="https://github.com/Logan-Lin/PubSummarizer">PubSummarizer</a></em></p>
        <div class="row" data-masonry='{"percentPosition": true }'>
            <div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">"What Data Benefits My Classifier?" Enhancing Model Performance and Interpretability through Influence-Based Data Selection</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=HE9eUQlAvo&name=pdf" class="link-primary">https://openreview.net/attachment?id=HE9eUQlAvo&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">data selection</span>
<span class="badge bg-primary">model interpretability</span>
<span class="badge bg-primary">influence functions</span>
<span class="badge bg-primary">machine learning fairness</span>
<span class="badge bg-primary">robustness</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents a novel approach to improve the performance and interpretability of classification models by utilizing influence estimation models to identify beneficial training data. The authors propose influence-based data selection strategies that enhance model utility, fairness, and robustness, particularly in challenging scenarios such as distribution shifts, fairness poisoning attacks, and active learning. Through extensive experiments on both synthetic and real-world datasets, they demonstrate that their methods significantly outperform traditional approaches, offering valuable insights into the feature contributions of training samples. The findings highlight the importance of data quality in machine learning, advocating for a shift in focus from solely model architecture to the strategic selection of training data for optimal performance.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=9JQtrumvg8&name=pdf" class="link-primary">https://openreview.net/attachment?id=9JQtrumvg8&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">web automation</span>
<span class="badge bg-primary">large language models</span>
<span class="badge bg-primary">HTML understanding</span>
<span class="badge bg-primary">program synthesis</span>
<span class="badge bg-primary">self-supervised learning</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces WebAgent, an advanced LLM-driven autonomous agent designed for real-world web automation, addressing challenges such as open domainness, lengthy HTML documents, and lack of HTML-specific knowledge. WebAgent utilizes two specialized language models: HTML-T5 for planning and summarization, and Flan-U-PaLM for generating executable Python programs. By employing a modular architecture and self-experience supervision, WebAgent achieves over 50% improvement in task success rates on real websites compared to previous models. The study also demonstrates HTML-T5's superior performance on various benchmarks, suggesting that specialized approaches combining task decomposition and HTML comprehension significantly enhance the capabilities of autonomous web agents.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Accelerating Distributed Stochastic Optimization via Self-Repellent Random Walks</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=BV1PHbTJzd&name=pdf" class="link-primary">https://openreview.net/attachment?id=BV1PHbTJzd&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">distributed optimization</span>
<span class="badge bg-primary">stochastic approximation</span>
<span class="badge bg-primary">self-repellent random walk</span>
<span class="badge bg-primary">Markov chains</span>
<span class="badge bg-primary">asymptotic analysis</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces a novel approach to distributed stochastic optimization by employing a Self-Repellent Random Walk (SRRW) to enhance the convergence rates of optimization algorithms driven by stochastic approximations. Unlike conventional methods that utilize linear Markov chains, the proposed SRRW, which reduces the likelihood of revisiting frequently visited states, significantly decreases asymptotic variance in gradient sampling. The authors prove that their SA-SRRW algorithm converges to zero optimization error almost surely, demonstrating a clear performance advantage over traditional methods, particularly in decentralized learning environments. Empirical results validate the theoretical claims, showing superior performance of the SRRW-driven algorithms across various scenarios, emphasizing the benefits of employing non-linear Markov chains in stochastic optimization contexts.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Amortizing intractable inference in large language models</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=Ouj6p4ca60&name=pdf" class="link-primary">https://openreview.net/attachment?id=Ouj6p4ca60&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Amortized Inference</span>
<span class="badge bg-primary">Language Models</span>
<span class="badge bg-primary">Bayesian Inference</span>
<span class="badge bg-primary">Reinforcement Learning</span>
<span class="badge bg-primary">Chain-of-Thought Reasoning</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents a novel approach to address the limitations of autoregressive large language models (LLMs) in performing intractable inference tasks, such as sequence continuation and chain-of-thought reasoning. By employing amortized Bayesian inference through generative flow networks (GFlowNets), the authors demonstrate a method that fine-tunes LLMs to sample from intractable posterior distributions effectively. The proposed GFlowNet fine-tuning improves sample diversity, data efficiency, and generalization on various tasks, including natural language reasoning and arithmetic problem solving. The empirical results indicate significant performance enhancements over traditional maximum-likelihood training and reward-maximizing policy optimization, showcasing the potential of GFlowNet fine-tuning for flexible reasoning in LLMs.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">An Analytical Solution to Gauss-Newton Loss for Direct Image Alignment</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=mE52zURNGc&name=pdf" class="link-primary">https://openreview.net/attachment?id=mE52zURNGc&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Gauss-Newton Loss</span>
<span class="badge bg-primary">Direct Image Alignment</span>
<span class="badge bg-primary">Pose Estimation</span>
<span class="badge bg-primary">Feature Descriptors</span>
<span class="badge bg-primary">Image Localization</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents an analytical solution to the Gauss-Newton loss to enhance direct image alignment, a method crucial for estimating the relative pose between images. The authors derive a closed-form solution that allows for dynamic adjustment of the convergence basin, thereby improving the robustness of alignment against imprecise initialization. Utilizing self-supervised feature descriptors, their approach achieves competitive accuracy compared to state-of-the-art supervised methods while revealing limitations in conventional end-to-end learning strategies. The experiments, conducted on various datasets, demonstrate the effectiveness of the proposed method in diverse scenarios, indicating enhanced localization accuracy and robustness to initialization noise.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Approximating Nash Equilibria in Normal-Form Games via Stochastic Optimization</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=cc8h3I3V4E&name=pdf" class="link-primary">https://openreview.net/attachment?id=cc8h3I3V4E&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Nash Equilibria</span>
<span class="badge bg-primary">Stochastic Optimization</span>
<span class="badge bg-primary">Monte Carlo Estimation</span>
<span class="badge bg-primary">Game Theory</span>
<span class="badge bg-primary">Machine Learning</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces a novel loss function for approximating Nash equilibria in normal-form games that enables unbiased Monte Carlo estimation, allowing standard non-convex stochastic optimization techniques, such as stochastic gradient descent (SGD), to be effectively employed. The authors demonstrate that their approach can outperform existing algorithms in approximating Nash equilibria, particularly in larger games, while also addressing the challenges of equilibrium selection and computational intractability. The theoretical framework is supported by empirical results, showcasing the potential of this method to transform equilibrium computation in multi-agent systems and highlight future research directions in computational game theory.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">ASID: Active Exploration for System Identification in Robotic Manipulation</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=jNR6s6OSBT&name=pdf" class="link-primary">https://openreview.net/attachment?id=jNR6s6OSBT&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">system identification</span>
<span class="badge bg-primary">robotic manipulation</span>
<span class="badge bg-primary">simulation-to-reality transfer</span>
<span class="badge bg-primary">active exploration</span>
<span class="badge bg-primary">reinforcement learning</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents ASID, a novel learning system aimed at enhancing robotic manipulation by autonomously refining simulation models with minimal real-world data. The approach addresses challenges in sim-to-real transfer by proposing a three-stage pipeline: first, it utilizes an exploration policy informed by Fisher information to gather informative data from the real environment; second, it employs this data for system identification to update simulation parameters; and finally, it trains a control policy in the refined simulator that can effectively transfer to real-world tasks. Empirical results demonstrate that ASID successfully identifies critical physical parameters and enables zero-shot transfer of learned policies to real-world scenarios, outperforming traditional reinforcement learning methods that require extensive data collection.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Batched Low-Rank Adaptation of Foundation Models</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=w4abltTZ2f&name=pdf" class="link-primary">https://openreview.net/attachment?id=w4abltTZ2f&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Low-Rank Adaptation</span>
<span class="badge bg-primary">FLORA</span>
<span class="badge bg-primary">Foundation Models</span>
<span class="badge bg-primary">Multilingual Tasks</span>
<span class="badge bg-primary">Real-time Serving</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents Fast Low-Rank Adaptation (FLORA), a novel framework that enhances Low-Rank Adaptation (LORA) for efficiently adapting foundation models in real-time serving scenarios. While LORA has been effective in reducing the number of trainable parameters by employing low-rank matrices, it struggles with batching multiple requests that require distinct task-specific adaptations. FLORA addresses this limitation by allowing each input in a minibatch to use unique low-rank adaptation weights, thereby improving throughput and reducing latency without sacrificing accuracy. Empirical results demonstrate FLORA's advantages over LORA in multilingual code generation and speech recognition tasks, highlighting its potential for real-world applications requiring diverse and personalized model adaptations.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Beyond Weisfeiler-Lehman: A Quantitative Framework for GNN Expressiveness</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=HSKaGOi7Ar&name=pdf" class="link-primary">https://openreview.net/attachment?id=HSKaGOi7Ar&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Graph Neural Networks</span>
<span class="badge bg-primary">Expressiveness</span>
<span class="badge bg-primary">Homomorphism</span>
<span class="badge bg-primary">Weisfeiler-Lehman</span>
<span class="badge bg-primary">Subgraph Counting</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces a novel framework for quantitatively assessing the expressiveness of Graph Neural Networks (GNNs) by establishing the concept of homomorphism expressivity, which measures a GNN's ability to count graphs under homomorphism. The authors argue that traditional measures, particularly the Weisfeiler-Lehman hierarchy, are insufficient due to their coarse and qualitative nature. By analyzing several prominent GNN architectures, the study provides unified descriptions of their homomorphism expressivity and demonstrates the practical implications of this expressivity in real-world tasks, including subgraph counting. Extensive experiments validate the proposed framework, showcasing a strong correlation between theoretical expressiveness and empirical performance across various GNN models.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">BooookScore: A systematic exploration of book-length summarization in the era of LLMs</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=7Ttk3RzDeu&name=pdf" class="link-primary">https://openreview.net/attachment?id=7Ttk3RzDeu&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">book summarization</span>
<span class="badge bg-primary">large language models</span>
<span class="badge bg-primary">coherence evaluation</span>
<span class="badge bg-primary">automatic metrics</span>
<span class="badge bg-primary">prompting strategies</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents a comprehensive study on summarizing book-length texts using large language models (LLMs), addressing the challenges posed by their limited context window size. It introduces a systematic evaluation framework to assess coherence in LLM-generated summaries, validated through 1193 human annotations on summaries from 100 recently published books. The authors develop an automatic metric called BOOOOK SCORE, which successfully measures coherence by identifying common error types in summaries and demonstrates high agreement with human evaluations. The study finds that summarization strategies such as hierarchical merging yield more coherent summaries but at the cost of detail, while incremental updating offers richer detail but may reduce coherence. The results indicate that closed-source models like GPT-4 outperform open-source counterparts, and the findings aim to advance research in book-length summarization by releasing both the metric and annotated data for further exploration.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Cameras as Rays: Pose Estimation via Ray Diffusion</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=EanCFCwAjM&name=pdf" class="link-primary">https://openreview.net/attachment?id=EanCFCwAjM&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Pose Estimation</span>
<span class="badge bg-primary">Ray Diffusion</span>
<span class="badge bg-primary">3D Reconstruction</span>
<span class="badge bg-primary">Camera Representation</span>
<span class="badge bg-primary">Deep Learning</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents a novel approach to camera pose estimation via a distributed ray representation, addressing challenges arising from sparsely sampled views. Unlike conventional methods that predict global camera parameters, the authors treat cameras as bundles of rays, enabling improved coupling with spatial image features and enhanced pose precision. They develop a regression-based method to map image patches to corresponding rays and extend this to a denoising diffusion model, which captures inherent uncertainties and generates plausible modes for pose inference. The proposed methods achieve state-of-the-art performance on camera pose estimation tasks, demonstrating strong generalization capabilities to unseen object categories and in-the-wild captures.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Candidate Label Set Pruning: A Data-centric Perspective for Deep Partial-label Learning</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=Fk5IzauJ7F&name=pdf" class="link-primary">https://openreview.net/attachment?id=Fk5IzauJ7F&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">partial-label learning</span>
<span class="badge bg-primary">candidate label pruning</span>
<span class="badge bg-primary">data-centric approach</span>
<span class="badge bg-primary">deep learning</span>
<span class="badge bg-primary">performance enhancement</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces a novel task called Candidate Label Set Pruning (CLSP) within the framework of Partial-Label Learning (PLL), shifting the focus from traditional learning-centric methods to a data-centric perspective. The authors propose a training-free CLSP method that aims to filter out potential false candidate labels based on the inconsistency between the representation space and the candidate label space. By utilizing a per-example pruning scheme derived from k-nearest neighbor instances, the method effectively reduces the size of candidate label sets, thus enhancing the performance of existing deep PLL methods. Theoretical analyses establish an upper bound on pruning error rates, while extensive empirical evaluations on benchmark and real-world datasets demonstrate significant improvements in the accuracy of deep PLL methods, validating the efficacy of the proposed CLSP approach.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">ClimODE: Climate and Weather Forecasting with Physics-informed Neural ODEs</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=xuY33XhEGR&name=pdf" class="link-primary">https://openreview.net/attachment?id=xuY33XhEGR&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">climate modeling</span>
<span class="badge bg-primary">weather forecasting</span>
<span class="badge bg-primary">neural ODE</span>
<span class="badge bg-primary">uncertainty quantification</span>
<span class="badge bg-primary">deep learning</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces ClimODE, a novel climate and weather forecasting model that integrates physics-informed principles with neural ordinary differential equations (ODEs) to enhance predictive accuracy and uncertainty quantification. Unlike traditional data-driven models that act as black boxes, ClimODE emphasizes value-conserving dynamics by modeling weather as a continuous-time advection process, enabling more stable long-term forecasts. The model incorporates both local convolutions and global attention mechanisms to effectively capture spatiotemporal dynamics, achieving state-of-the-art performance in global and regional weather predictions with significantly fewer parameters. Empirical results demonstrate ClimODE's superiority over existing methods, laying the groundwork for further advancements in climate modeling amidst evolving atmospheric conditions.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Detecting, Explaining, and Mitigating Memorization in Diffusion Models</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=84n3UwkH7b&name=pdf" class="link-primary">https://openreview.net/attachment?id=84n3UwkH7b&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">memorization</span>
<span class="badge bg-primary">diffusion models</span>
<span class="badge bg-primary">image generation</span>
<span class="badge bg-primary">detection methods</span>
<span class="badge bg-primary">mitigation strategies</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper addresses the issue of memorization in diffusion models, which can lead to the generation of outputs that closely replicate training data, raising legal concerns. The authors propose a novel detection method that evaluates the magnitude of text-conditional predictions to identify memorized prompts efficiently, achieving high accuracy even with a single generation. They also introduce an explainable approach to highlight the significance of individual tokens in the memorization process, enabling users to adjust their prompts accordingly. Furthermore, two mitigation strategies are proposed: one for inference that minimizes text-conditional prediction magnitudes and another for training that filters out potential memorized examples. These methods effectively reduce memorization while maintaining the quality of generated outputs, providing a comprehensive solution to mitigate the risks associated with diffusion model memorization.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Diffusion Model for Dense Matching</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=Zsfiqpft6K&name=pdf" class="link-primary">https://openreview.net/attachment?id=Zsfiqpft6K&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Diffusion models</span>
<span class="badge bg-primary">Dense correspondence</span>
<span class="badge bg-primary">Image matching</span>
<span class="badge bg-primary">Generative models</span>
<span class="badge bg-primary">Neural networks</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces DiffMatch, a novel framework for establishing dense correspondences between paired images using a conditional denoising diffusion model. Unlike traditional methods that rely on hand-designed prior terms, DiffMatch explicitly models both data and prior distributions, addressing challenges such as textureless regions and large displacements. The framework employs a cascaded pipeline to enhance resolution, starting with a low-resolution model and transitioning to a super-resolution model for fine details. Experimental results show that DiffMatch outperforms existing state-of-the-art methods, particularly in challenging conditions, demonstrating the effectiveness of a generative prior in dense matching tasks.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=UyNXMqnN3c&name=pdf" class="link-primary">https://openreview.net/attachment?id=UyNXMqnN3c&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">3D Content Creation</span>
<span class="badge bg-primary">Generative Models</span>
<span class="badge bg-primary">Gaussian Splatting</span>
<span class="badge bg-primary">Texture Refinement</span>
<span class="badge bg-primary">Optimization Efficiency</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents DreamGaussian, a novel framework for efficient 3D content generation that significantly reduces the time required to create high-quality textured meshes from images or text prompts, achieving results in as little as two minutes. The authors introduce a generative 3D Gaussian splatting method, which improves upon existing optimization-based techniques by facilitating faster convergence during the 3D generation process. DreamGaussian incorporates a two-stage pipeline: the first stage handles the generation of 3D Gaussians and their progressive densification, while the second stage focuses on extracting a polygonal mesh and refining its texture. Experimental results demonstrate that DreamGaussian achieves superior efficiency and competitive quality compared to existing methods, marking a significant advancement in the field of automated 3D content creation.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Efficient Episodic Memory Utilization of Cooperative Multi-Agent Reinforcement Learning</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=LjivA1SLZ6&name=pdf" class="link-primary">https://openreview.net/attachment?id=LjivA1SLZ6&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">multi-agent reinforcement learning</span>
<span class="badge bg-primary">episodic memory</span>
<span class="badge bg-primary">semantic embedding</span>
<span class="badge bg-primary">exploration-exploitation</span>
<span class="badge bg-primary">local optima</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces Efficient Episodic Memory Utilization (EMU) for cooperative multi-agent reinforcement learning (MARL), addressing challenges such as long convergence times and local optima in complex tasks. EMU enhances learning efficiency through a trainable semantic memory embedding that enables coherent memory recall and an episodic incentive that promotes desirable state transitions. By leveraging these components, EMU significantly improves performance over traditional MARL methods, as demonstrated in experiments on challenging environments like StarCraft II and Google Research Football. The proposed framework allows for better exploration of promising state spaces and effectively mitigates the risk of local convergence, presenting a strong advancement in MARL methodologies.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">ExeDec: Execution Decomposition for Compositional Generalization in Neural Program Synthesis</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=oTRwljRgiv&name=pdf" class="link-primary">https://openreview.net/attachment?id=oTRwljRgiv&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">execution decomposition</span>
<span class="badge bg-primary">compositional generalization</span>
<span class="badge bg-primary">neural program synthesis</span>
<span class="badge bg-primary">programming by example</span>
<span class="badge bg-primary">transformer models</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces ExeDec, a novel decomposition-based strategy for enhancing compositional generalization in neural program synthesis. It highlights the importance of breaking down complex programming tasks into simpler subtasks, akin to human programmers' approach. The authors establish a meta-benchmark comprising five distinct forms of compositional generalization, and through experiments on datasets like RobustFill and DeepCoder, they demonstrate that ExeDec significantly improves synthesis performance and generalization capabilities over existing baseline methods. Additionally, the research reveals that large language models (LLMs) struggle with compositional generalization in programming tasks but can benefit from an ExeDec-inspired prompting approach, further emphasizing the potential of systematic decomposition in program synthesis.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=hTEGyKf0dZ&name=pdf" class="link-primary">https://openreview.net/attachment?id=hTEGyKf0dZ&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">fine-tuning</span>
<span class="badge bg-primary">language models</span>
<span class="badge bg-primary">safety alignment</span>
<span class="badge bg-primary">adversarial attacks</span>
<span class="badge bg-primary">risk assessment</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper investigates the safety risks associated with fine-tuning large language models (LLMs), specifically Meta's Llama-2 and OpenAI's GPT-3.5 Turbo, revealing that customization through fine-tuning can significantly compromise their safety alignment. Through red teaming studies, the authors demonstrate that even a small number of adversarially designed training examples can lead to the models being "jailbroken," allowing harmful instructions to be executed. Alarmingly, they also find that benign datasets can inadvertently degrade the models' safety, highlighting a critical gap in existing safety protocols. The study emphasizes the need for improved mitigation strategies, combining technical and policy measures, to reinforce safety during the fine-tuning process, urging further research to address these vulnerabilities effectively.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Finetuning Text-to-Image Diffusion Models for Fairness</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=hnrB5YHoYu&name=pdf" class="link-primary">https://openreview.net/attachment?id=hnrB5YHoYu&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">text-to-image models</span>
<span class="badge bg-primary">fairness</span>
<span class="badge bg-primary">bias mitigation</span>
<span class="badge bg-primary">distributional alignment</span>
<span class="badge bg-primary">fine-tuning</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper addresses biases in text-to-image (T2I) diffusion models, proposing a novel approach that frames fairness as a distributional alignment problem. The authors introduce a distributional alignment loss and an adjusted direct fine-tuning (DFT) method, which effectively reduces gender, racial, and intersectional biases in generated images. Empirical results demonstrate significant improvements in fairness without sacrificing image quality, even when fine-tuning only a few soft tokens. The method allows for flexible adjustments to various demographic distributions, such as age and gender, while maintaining semantic integrity in the generated outputs. The findings promote broader discussions on the ethical implications and social alignment of multimedia generative AI.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Flow Matching on General Geometries</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=g7ohDlTITL&name=pdf" class="link-primary">https://openreview.net/attachment?id=g7ohDlTITL&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Riemannian Flow Matching</span>
<span class="badge bg-primary">Continuous Normalizing Flows</span>
<span class="badge bg-primary">Generative Modeling</span>
<span class="badge bg-primary">Non-Euclidean Spaces</span>
<span class="badge bg-primary">Manifolds</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces Riemannian Flow Matching (RFM), a novel framework for training continuous normalizing flows (CNFs) on Riemannian manifolds, addressing limitations of existing generative modeling techniques that often require expensive simulations and struggle with high-dimensional data. RFM is distinguished by its simulation-free approach on simple geometries, closed-form computation of target vector fields, and lack of divergence requirements, making it efficient for various datasets. The methodology employs a premetric to define target vector fields and utilizes spectral decompositions for real-time computation on general geometries. Experimental results demonstrate that RFM achieves state-of-the-art performance across multiple non-Euclidean datasets, facilitating scalable training even on complex manifolds with non-trivial curvature and boundaries.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Gene Regulatory Network Inference in the Presence of Dropouts: a Causal View</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=gFR4QwK53h&name=pdf" class="link-primary">https://openreview.net/attachment?id=gFR4QwK53h&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">gene regulatory networks</span>
<span class="badge bg-primary">dropout mechanisms</span>
<span class="badge bg-primary">causal inference</span>
<span class="badge bg-primary">single-cell RNA sequencing</span>
<span class="badge bg-primary">statistical modeling</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper addresses the challenge of inferring gene regulatory networks (GRNs) from single-cell RNA sequencing data, which often suffers from dropout issuesâ€”zeros that may arise from both biological causes and technical errors. The authors introduce a novel Causal Dropout Model that characterizes these dropout mechanisms and presents a theoretical result showing that conditional independence relations remain intact when samples with zeros for conditioned variables are excluded. This insight leads to a systematic approach for GRN inference that integrates seamlessly with existing causal discovery algorithms, ensuring asymptotic correctness. Empirical evaluations on synthetic, curated, and real-world datasets demonstrate the effectiveness of the proposed method, highlighting its advantages over traditional imputation and statistical models in handling dropout errors.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Generalization in diffusion models arises from geometry-adaptive harmonic representations</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=ANvmVS2Yr0&name=pdf" class="link-primary">https://openreview.net/attachment?id=ANvmVS2Yr0&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">diffusion models</span>
<span class="badge bg-primary">generalization</span>
<span class="badge bg-primary">denoising</span>
<span class="badge bg-primary">geometry-adaptive harmonic bases</span>
<span class="badge bg-primary">inductive biases</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper investigates how deep neural networks (DNNs) used in score-based reverse diffusion processes for image denoising exhibit strong generalization capabilities, particularly when trained on large datasets. The authors demonstrate that as the training set size increases, DNNs trained on non-overlapping subsets of data learn nearly identical score functions, leading to high-quality image generation that does not merely memorize training samples. The study identifies that these networks perform a shrinkage operation in geometry-adaptive harmonic bases (GAHBs), which adapt to the underlying image structure and enhance denoising performance. This relationship between denoising and density estimation reveals that DNN inductive biases align well with the data distribution, enabling effective learning from relatively small training sets and confirming the significance of GAHBs in achieving optimal denoising outcomes.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Generative Modeling with Phase Stochastic Bridge</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=tUtGjQEDd4&name=pdf" class="link-primary">https://openreview.net/attachment?id=tUtGjQEDd4&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">generative modeling</span>
<span class="badge bg-primary">phase space dynamics</span>
<span class="badge bg-primary">sampling efficiency</span>
<span class="badge bg-primary">stochastic optimal control</span>
<span class="badge bg-primary">image generation</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents a novel generative modeling framework called Acceleration Generative Modeling (AGM), which is based on the principles of phase space dynamics and stochastic optimal control. By leveraging the structural characteristics of the model, AGM enhances early-stage data prediction and generates more favorable trajectories for efficient sampling, thereby reducing sampling complexity. The approach notably incorporates velocity information, allowing for a significant reduction in the number of function evaluations (NFEs) required to generate realistic data samples. Experimental results demonstrate that AGM achieves competitive image generation performance compared to existing models, particularly in scenarios where NFEs are limited, while showcasing superior efficiency over traditional methods like Critical-damped Langevin Dynamics.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Ghost on the Shell: An Expressive Representation of General 3D Shapes</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=Ad87VjRqUw&name=pdf" class="link-primary">https://openreview.net/attachment?id=Ad87VjRqUw&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">3D Representation</span>
<span class="badge bg-primary">Mesh Reconstruction</span>
<span class="badge bg-primary">Non-Watertight Meshes</span>
<span class="badge bg-primary">Generative Modeling</span>
<span class="badge bg-primary">Differentiable Rendering</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents Ghost-on-the-Shell (G-S HELL), a novel 3D mesh representation that efficiently models both watertight and non-watertight surfaces using a manifold signed distance field (mSDF) on a watertight template. This framework enables fast and differentiable reconstruction of complex geometries from multiview images and facilitates unconditional generative modeling of non-watertight meshes using diffusion models. G-S HELL addresses limitations in current mesh representations by capturing a broader range of object shapes while maintaining performance in physics-based rendering and material optimization. Experimental results demonstrate its superiority over existing methods in both reconstruction and generation tasks, highlighting its potential for creating high-fidelity 3D models in various applications.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">GNNCert: Deterministic Certification of Graph Neural Networks against Adversarial Perturbations</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=IGzaH538fz&name=pdf" class="link-primary">https://openreview.net/attachment?id=IGzaH538fz&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Graph Neural Networks</span>
<span class="badge bg-primary">Adversarial Attacks</span>
<span class="badge bg-primary">Certified Defenses</span>
<span class="badge bg-primary">Graph Classification</span>
<span class="badge bg-primary">Robustness Guarantees</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents GNNCert, a novel certified defense mechanism for graph classification that addresses vulnerabilities to adversarial perturbations in graph structure and node features. Unlike existing defenses that offer probabilistic guarantees or only address specific types of perturbations, GNNCert provides deterministic robustness by dividing input graphs into sub-graphs and employing majority voting for classification. Experimental results across eight benchmark datasets demonstrate that GNNCert outperforms state-of-the-art methods in terms of both certified accuracy and computational efficiency, making it a viable solution for security-critical applications in graph analytics.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Graph Neural Networks for Learning Equivariant Representations of Neural Networks</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=oO6FsMyDBt&name=pdf" class="link-primary">https://openreview.net/attachment?id=oO6FsMyDBt&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Graph Neural Networks</span>
<span class="badge bg-primary">Neural Network Architecture</span>
<span class="badge bg-primary">Equivariance</span>
<span class="badge bg-primary">Implicit Neural Representations</span>
<span class="badge bg-primary">Generalization Performance</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces a novel approach to processing neural networks by representing them as neural graphs, which preserves permutation symmetry inherent in neural architectures. The authors argue that existing methods either neglect this symmetry or require complex weight-sharing patterns that limit their flexibility. Their model effectively learns from diverse neural network architectures, enabling applications such as classifying implicit neural representations, predicting generalization errors, and optimizing neural networks. The proposed method, which integrates graph neural networks and transformers, demonstrates superior performance across multiple tasks compared to state-of-the-art techniques, highlighting the importance of accounting for architectural variations and symmetries in neural network processing.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">How I Warped Your Noise: a Temporally-Correlated Noise Prior for Diffusion Models</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=pzElnMrgSD&name=pdf" class="link-primary">https://openreview.net/attachment?id=pzElnMrgSD&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">diffusion models</span>
<span class="badge bg-primary">video generation</span>
<span class="badge bg-primary">noise correlation</span>
<span class="badge bg-primary">temporal coherence</span>
<span class="badge bg-primary">noise transport</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces a novel approach to address the limitations of traditional noise sampling techniques in diffusion models used for video editing and generation. The authors propose a new noise representation called R-noise, which treats noise samples as an integral over an underlying continuous noise field, thereby preserving temporal correlations across video frames. The method involves a specialized noise transport equation and algorithm that maintains the distribution properties of the noise while maximizing correlations between samples. Experimental results demonstrate the effectiveness of R-noise in various applications, including video restoration, appearance transfer, and conditional video generation, showing significant improvements in temporal coherence and visual quality compared to existing methods.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">How Well Do Supervised 3D Models Transfer to Medical Imaging Tasks?</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=AhizIPytk4&name=pdf" class="link-primary">https://openreview.net/attachment?id=AhizIPytk4&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Transfer Learning</span>
<span class="badge bg-primary">Medical Imaging</span>
<span class="badge bg-primary">Supervised Pre-training</span>
<span class="badge bg-primary">3D Segmentation</span>
<span class="badge bg-primary">Dataset Construction</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper investigates the transfer learning capabilities of supervised models pre-trained on a newly constructed dataset, AbdomenAtlas 1.1, which contains 9,262 annotated 3D CT volumes for medical imaging tasks. It highlights the challenges of transferring models trained on 2D datasets like ImageNet to 3D tasks due to the absence of large, annotated 3D datasets. The authors demonstrate that their supervised pre-training method significantly improves transfer learning efficiency, achieving comparable performance with far fewer resources than existing models. Their findings suggest that well-annotated 3D datasets can enhance model generalizability and performance across various medical imaging tasks, ultimately advancing the field of 3D image segmentation.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Improved Active Learning via Dependent Leverage Score Sampling</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=IYxDy2jDFL&name=pdf" class="link-primary">https://openreview.net/attachment?id=IYxDy2jDFL&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">active learning</span>
<span class="badge bg-primary">leverage score sampling</span>
<span class="badge bg-primary">pivotal sampling</span>
<span class="badge bg-primary">polynomial regression</span>
<span class="badge bg-primary">agnostic learning</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents an improved active learning method that enhances the efficiency of sampling in agnostic settings by integrating marginal leverage score sampling with pivotal sampling strategies that ensure spatial coverage. The authors propose a pivotal sampling algorithm that significantly reduces the number of samples needed to achieve a target accuracy, outperforming independent sampling by up to 50%. They establish two key theoretical results: one demonstrating that any non-independent leverage score sampling method adhering to a weak one-sided independence condition can match the sample complexity of independent sampling, and another specifically for polynomial regression, showing that pivotal sampling achieves an improved sample bound. Experimental results on problems related to parametric PDEs confirm the effectiveness of their method, highlighting the advantages of spatially-aware sampling in practical applications.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Improved Techniques for Training Consistency Models</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=WNzy9bRDvG&name=pdf" class="link-primary">https://openreview.net/attachment?id=WNzy9bRDvG&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">consistency models</span>
<span class="badge bg-primary">generative models</span>
<span class="badge bg-primary">training techniques</span>
<span class="badge bg-primary">sample quality</span>
<span class="badge bg-primary">Pseudo-Huber loss</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents improved techniques for training consistency models, a type of generative model that generates high-quality samples without adversarial training. The authors address limitations of existing methods that rely on distillation from diffusion models and learned metrics such as LPIPS, proposing a direct training approach from data. Key innovations include removing the Exponential Moving Average from the teacher model, adopting Pseudo-Huber losses for evaluation, and implementing a lognormal noise schedule along with an enhanced curriculum for discretization steps. These modifications lead to significant improvements in FrÃ©chet Inception Distance (FID) scores on CIFAR-10 and ImageNet datasets, demonstrating the efficacy of the new techniques and positioning consistency models as competitive alternatives to other leading generative models.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Improving Convergence and Generalization Using Parameter Symmetries</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=L0r0GphlIL&name=pdf" class="link-primary">https://openreview.net/attachment?id=L0r0GphlIL&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">parameter symmetries</span>
<span class="badge bg-primary">optimization algorithms</span>
<span class="badge bg-primary">generalization</span>
<span class="badge bg-primary">convergence</span>
<span class="badge bg-primary">teleportation</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper explores the use of parameter space symmetries, specifically through a method called teleportation, to enhance the convergence speed and generalization capability of neural network optimization. The authors demonstrate that teleportation not only accelerates short-term optimization but also leads to an overall faster convergence to stationary points in the parameter space. Furthermore, they establish a correlation between the curvature of minima and generalization performance, suggesting that moving towards minima with different curvatures can improve model generalization. The findings are supported by theoretical guarantees and empirical results across various optimization algorithms, highlighting the versatility and potential of integrating symmetry into optimization strategies.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">InfoBatch: Lossless Training Speed Up by Unbiased Dynamic Data Pruning</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=C61sk5LsK6&name=pdf" class="link-primary">https://openreview.net/attachment?id=C61sk5LsK6&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">data pruning</span>
<span class="badge bg-primary">training acceleration</span>
<span class="badge bg-primary">gradient approximation</span>
<span class="badge bg-primary">deep learning</span>
<span class="badge bg-primary">model efficiency</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces InfoBatch, a novel framework designed to enhance training efficiency through unbiased dynamic data pruning while ensuring lossless performance across various deep learning tasks. By selectively pruning less informative samples based on their loss values and subsequently adjusting the gradients of the remaining samples, InfoBatch maintains a consistent gradient expectation similar to that of training on the full dataset. The framework is plug-and-play, architecture-agnostic, and demonstrates impressive results, achieving 20% to 40% reductions in overall training costs on datasets like CIFAR10/100 and ImageNet-1K, while also ensuring lossless outcomes. Extensive experiments validate its effectiveness in classification, segmentation, and instruction fine-tuning tasks, highlighting its potential for practical applications in large-scale model training.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Interpreting CLIP's Image Representation via Text-Based Decomposition</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=5Ca9sSzuDp&name=pdf" class="link-primary">https://openreview.net/attachment?id=5Ca9sSzuDp&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">CLIP</span>
<span class="badge bg-primary">image representation</span>
<span class="badge bg-primary">attention heads</span>
<span class="badge bg-primary">model interpretability</span>
<span class="badge bg-primary">zero-shot segmentation</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper investigates the CLIP image encoder by decomposing its representation into contributions from individual image patches, model layers, and attention heads. The authors develop a method called TEXTSPAN to characterize the roles of attention heads based on text representations, revealing property-specific functions such as shape detection and spatial localization. The study shows that understanding these components allows for improved model performance, as demonstrated through applications that reduce spurious correlations in classification tasks and enhance zero-shot segmentation capabilities, suggesting that a scalable understanding of transformer models can lead to more effective and robust AI systems.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Is ImageNet worth 1 video? Learning strong image encoders from 1 long unlabelled video</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=Yen1lGns2o&name=pdf" class="link-primary">https://openreview.net/attachment?id=Yen1lGns2o&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">self-supervised learning</span>
<span class="badge bg-primary">video dataset</span>
<span class="badge bg-primary">image encoding</span>
<span class="badge bg-primary">object tracking</span>
<span class="badge bg-primary">transformer models</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents a novel approach to self-supervised learning by introducing a new dataset, the Walking Tours dataset, comprising high-resolution, continuous first-person videos and a tailored pretraining method called DORA (Discover and Track Objects). The dataset contains 10 long, unlabeled videos capturing diverse urban scenes, which are argued to be more efficient for training image encoders than traditional image datasets like ImageNet. DORA incorporates implicit multi-object tracking through a transformer model, significantly enhancing the ability to learn robust visual representations from video data. Experimental results show that models pretrained on a single Walking Tours video achieve performance comparable to those trained on extensive image datasets across various downstream tasks, thus demonstrating the effectiveness of leveraging continuous video for self-supervised learning.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Knowledge Card: Filling LLMs' Knowledge Gaps with Plug-in Specialized Language Models</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=WbWtOYIzIK&name=pdf" class="link-primary">https://openreview.net/attachment?id=WbWtOYIzIK&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Knowledge Integration</span>
<span class="badge bg-primary">Large Language Models</span>
<span class="badge bg-primary">Modular Framework</span>
<span class="badge bg-primary">Factuality</span>
<span class="badge bg-primary">Dynamic Knowledge Synthesis</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents KNOWLEDGE CARD, a modular framework designed to enhance large language models (LLMs) by filling knowledge gaps through the integration of specialized language models, termed "knowledge cards." These knowledge cards, trained on diverse domain-specific corpora, act as parametric repositories that provide relevant, factual, and up-to-date information during LLM inference. The framework employs three content selectors to ensure quality by controlling relevance, brevity, and factual accuracy of the knowledge integrated. TWO approaches, bottom-up and top-down, are proposed for knowledge integration, allowing for dynamic synthesis of information from various sources while maintaining modularity and facilitating collaborative contributions from the research community. Extensive experiments demonstrate that KNOWLEDGE CARD significantly outperforms existing LLMs and retrieval-augmented models across multiple tasks, showcasing its ability to enhance LLM performance in knowledge-intensive contexts.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Latent Trajectory Learning for Limited Timestamps under Distribution Shift over Time</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=bTMMNT7IdW&name=pdf" class="link-primary">https://openreview.net/attachment?id=bTMMNT7IdW&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Evolving Domain Generalization</span>
<span class="badge bg-primary">Stochastic Differential Equations</span>
<span class="badge bg-primary">Latent Trajectory Learning</span>
<span class="badge bg-primary">Distribution Shift</span>
<span class="badge bg-primary">Machine Learning Adaptability</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents a novel method, SDE-EDG, to address the challenges of Evolving Domain Generalization (EDG) in machine learning, particularly in scenarios where distribution shifts occur over time. Existing EDG methods struggle with limited timestamps, leading to overfitting and poor generalization to unseen domains. To overcome this, the authors introduce the Infinitely Fined-Grid Evolving Trajectory (IFGET) that utilizes continuous-interpolated samples to fill temporal gaps between timestamps. They leverage Stochastic Differential Equations (SDEs) to model and align these trajectories, capturing evolving patterns in the data. The approach is empirically validated on various benchmark datasets, demonstrating superior performance compared to existing state-of-the-art methods, thereby enhancing adaptability and generalization in time-varying environments.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Learning Energy Decompositions for Partial Inference in GFlowNets</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=P15CHILQlg&name=pdf" class="link-primary">https://openreview.net/attachment?id=P15CHILQlg&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">GFlowNets</span>
<span class="badge bg-primary">partial inference</span>
<span class="badge bg-primary">energy decomposition</span>
<span class="badge bg-primary">generative modeling</span>
<span class="badge bg-primary">machine learning</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces Learning Energy Decompositions for GFlowNets (LED-GFN), which enhances generative flow networks by enabling effective partial inference through the decomposition of terminal state energies into learnable potential functions. The authors identify limitations in existing methods, particularly the reliance on costly and potentially misleading evaluations of intermediate state energies in prior approaches like Forward-Looking GFlowNet (FL-GFN). LED-GFN addresses these issues by regularizing potential functions to minimize variance and ensure informative local credits during training. Empirical evaluations across various tasks, including generating unstructured sets, molecular structures, and RNA sequences, demonstrate that LED-GFN outperforms both FL-GFN and traditional GFlowNets, establishing its efficacy in producing diverse and high-quality samples.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Learning Interactive Real-World Simulators</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=sFyTZEqmUY&name=pdf" class="link-primary">https://openreview.net/attachment?id=sFyTZEqmUY&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">universal simulator</span>
<span class="badge bg-primary">generative modeling</span>
<span class="badge bg-primary">reinforcement learning</span>
<span class="badge bg-primary">vision-language policies</span>
<span class="badge bg-primary">interactive simulation</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents a novel approach to developing a universal simulator (UniSim) capable of simulating realistic interactions in various environments by integrating diverse datasets. This simulator addresses the challenge of creating a cohesive action-in-video-out interface that allows for both high-level instructions and low-level controls, thereby enabling agents to learn policies purely in simulation and generalize effectively to real-world scenarios. The authors demonstrate that UniSim can facilitate training for both vision-language and reinforcement learning policies, bridging the sim-to-real gap and expanding potential applications to video captioning and rare event detection. The results indicate that UniSim can generate high-quality training data, significantly improving the performance of models trained solely on simulated experiences.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">LEGO-Prover: Neural Theorem Proving with Growing Libraries</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=3f5PALef5B&name=pdf" class="link-primary">https://openreview.net/attachment?id=3f5PALef5B&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">theorem proving</span>
<span class="badge bg-primary">neural networks</span>
<span class="badge bg-primary">skill library</span>
<span class="badge bg-primary">formal verification</span>
<span class="badge bg-primary">modular proof construction</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces LEGO-Prover, a novel approach to neural theorem proving that enhances the capabilities of large language models (LLMs) by employing a growing skill library of verified lemmas. Unlike previous static methods, LEGO-Prover constructs mathematical proofs in a modular fashion, utilizing existing skills and generating new ones during the proving process. This method allows for a dynamic and reusable library that adapts over time, significantly improving success rates in theorem proving tasks. Experimental results demonstrate that LEGO-Prover achieves higher pass rates on the miniF2F dataset compared to existing methods, showcasing the effectiveness of its modular approach and the importance of a continuously evolving skill library in formal verification tasks.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Less is More: Fewer Interpretable Region via Submodular Subset Selection</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=jKTUlxo5zy&name=pdf" class="link-primary">https://openreview.net/attachment?id=jKTUlxo5zy&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">image attribution</span>
<span class="badge bg-primary">interpretability</span>
<span class="badge bg-primary">submodular optimization</span>
<span class="badge bg-primary">machine learning</span>
<span class="badge bg-primary">model explanations</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents a novel approach to image attribution by reformulating the problem as a submodular subset selection task, aiming to enhance interpretability through fewer, more precise regions. The authors address limitations of existing attribution methods, such as the generation of inaccurate small regions and difficulties in explaining incorrect predictions. By constructing a submodular function that incorporates four constraintsâ€”confidence, effectiveness, consistency, and collaboration scoresâ€”the proposed method effectively identifies important regions in images. Extensive experiments demonstrate that this approach outperforms state-of-the-art methods on multiple datasets (Celeb-A, VGG-Face2, and CUB-200-2011) by significantly improving attribution scores for both correctly and incorrectly predicted samples, thereby providing clearer explanations for model decisions.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Lipschitz Singularities in Diffusion Models</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=WNkW0cOwiz&name=pdf" class="link-primary">https://openreview.net/attachment?id=WNkW0cOwiz&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">diffusion models</span>
<span class="badge bg-primary">Lipschitz singularities</span>
<span class="badge bg-primary">E-TSDM</span>
<span class="badge bg-primary">image synthesis</span>
<span class="badge bg-primary">stability</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper investigates the phenomenon of infinite Lipschitz constants in diffusion models, particularly near time zero, which can adversely affect the stability and accuracy of these generative models. The authors provide both theoretical proof and empirical evidence demonstrating the presence of these Lipschitz singularities and propose a novel method called Early Timestep-shared Diffusion Model (E-TSDM) to mitigate this issue. E-TSDM operates by sharing timestep conditions within sub-intervals to effectively reduce the Lipschitz constants to zero, thus enhancing model performance. Extensive experiments across various datasets confirm that E-TSDM significantly improves synthesis quality and stability compared to traditional diffusion model approaches, while also providing insights into the underlying diffusion process.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">LLMCarbon: Modeling the End-to-End Carbon Footprint of Large Language Models</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=aIok3ZD9to&name=pdf" class="link-primary">https://openreview.net/attachment?id=aIok3ZD9to&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">carbon footprint</span>
<span class="badge bg-primary">large language models</span>
<span class="badge bg-primary">LLMCarbon</span>
<span class="badge bg-primary">machine learning</span>
<span class="badge bg-primary">environmental impact</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces LLMCarbon, an advanced end-to-end carbon footprint modeling tool designed to assess the environmental impact of large language models (LLMs) during their training, inference, experimentation, and storage phases. LLMCarbon addresses significant shortcomings in existing tools like mlco2, which primarily focus on GPU-based LLMs and fail to account for critical architectural parameters and embodied carbon emissions. The new model incorporates essential hardware and data center parameters, enabling accurate projections of both operational and embodied carbon footprints for various LLM configurations, including dense and mixture-of-experts architectures. Validation against existing data demonstrates LLMCarbon's improved accuracy, which encourages users and providers to evaluate the trade-offs between LLM performance and carbon emissions, ultimately promoting sustainability in machine learning practices.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">LoftQ: LoRA-Fine-Tuning-aware Quantization for Large Language Models</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=LzPWWPAdY4&name=pdf" class="link-primary">https://openreview.net/attachment?id=LzPWWPAdY4&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">quantization</span>
<span class="badge bg-primary">LoRA</span>
<span class="badge bg-primary">large language models</span>
<span class="badge bg-primary">fine-tuning</span>
<span class="badge bg-primary">natural language processing</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces LoftQ, a novel quantization framework designed to improve the performance of large language models (LLMs) when combined with Low-Rank Adaptation (LoRA) fine-tuning. It addresses the performance gap often observed between full fine-tuning and the quantization plus LoRA approach, particularly in low-bit quantization scenarios. LoftQ achieves this by jointly optimizing quantization and low-rank initialization, leading to significantly improved generalization across various downstream tasks, including natural language understanding, question answering, summarization, and natural language generation. Experimental results demonstrate that LoftQ consistently outperforms existing methods, especially in 2-bit and mixed precision settings, while also proving to be more stable and efficient.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=6PmJoRfdaK&name=pdf" class="link-primary">https://openreview.net/attachment?id=6PmJoRfdaK&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">LongLoRA</span>
<span class="badge bg-primary">fine-tuning</span>
<span class="badge bg-primary">large language models</span>
<span class="badge bg-primary">context extension</span>
<span class="badge bg-primary">efficient attention</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces LongLoRA, an efficient fine-tuning method designed to extend the context length of large language models (LLMs) with minimal computational cost. By utilizing a novel approach called Shifted Sparse Attention (S2-Attn) during training, LongLoRA significantly reduces the complexity associated with long context sizes while maintaining performance comparable to full fine-tuning. The method involves making embedding and normalization layers trainable, thus bridging the performance gap between conventional low-rank adaptation (LoRA) and full fine-tuning. Empirical results demonstrate that LongLoRA can extend the context length of Llama2 models from 4k to 100k tokens or from 2048 to 32k tokens on a single 8 A100 machine, while being compatible with existing optimization techniques. The authors also propose a dataset for supervised fine-tuning, LongAlpaca, and share their code and models openly.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">LRM: Large Reconstruction Model for Single Image to 3D</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=sllU8vvsFF&name=pdf" class="link-primary">https://openreview.net/attachment?id=sllU8vvsFF&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">3D Reconstruction</span>
<span class="badge bg-primary">Neural Radiance Field</span>
<span class="badge bg-primary">Transformer Architecture</span>
<span class="badge bg-primary">Image-to-3D Learning</span>
<span class="badge bg-primary">Large-Scale Datasets</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces the Large Reconstruction Model (LRM), a state-of-the-art framework designed to generate high-quality 3D models from single input images in just five seconds. Unlike prior methods that focus on specific categories and smaller datasets, LRM employs a transformer-based architecture with 500 million parameters, trained on approximately one million diverse 3D objects from both synthetic and real data. By utilizing an image encoder and a triplane decoder, LRM effectively captures the underlying spatial relations and visual features, allowing it to produce accurate and detailed 3D reconstructions. The model's scalability and efficiency make it a significant advancement in the field of single-image 3D reconstruction, with potential applications across various industries.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Mastering Memory Tasks with World Models</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=1vDArHJ68h&name=pdf" class="link-primary">https://openreview.net/attachment?id=1vDArHJ68h&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">model-based reinforcement learning</span>
<span class="badge bg-primary">long-term memory</span>
<span class="badge bg-primary">state space models</span>
<span class="badge bg-primary">credit assignment</span>
<span class="badge bg-primary">neural networks</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces Recall to Imagine (R2I), a novel approach for model-based reinforcement learning (MBRL) that enhances long-term memory and credit assignment by integrating state space models (SSMs) into the world models of MBRL agents. R2I addresses the challenges faced by traditional MBRL methods, particularly in tasks requiring the recall of distant observations across extended time gaps. Experimental results demonstrate that R2I outperforms existing state-of-the-art methods, including DreamerV3, achieving superhuman performance in complex memory tasks like Memory Maze, while maintaining strong performance in standard RL environments such as Atari and DMC. The method's computational efficiency is highlighted, showing up to nine times faster convergence compared to its predecessors. Overall, R2I represents a significant advancement in the ability of reinforcement learning agents to manage long-term dependencies effectively.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=KUNzEQMWU7&name=pdf" class="link-primary">https://openreview.net/attachment?id=KUNzEQMWU7&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">mathematical reasoning</span>
<span class="badge bg-primary">visual contexts</span>
<span class="badge bg-primary">foundation models</span>
<span class="badge bg-primary">benchmark evaluation</span>
<span class="badge bg-primary">multimodal datasets</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents MATHVISTA, a novel benchmark aimed at evaluating the mathematical reasoning capabilities of foundation models in visually complex scenarios. Comprising 6,141 examples derived from 28 existing multimodal datasets and three newly created datasets, MATHVISTA challenges models with diverse tasks requiring deep visual understanding and compositional reasoning. The evaluation of 12 prominent models, including GPT-4V, demonstrates that while GPT-4V achieves the highest accuracy at 49.9%, it still lags behind human performance by 10.4%. The study highlights the challenges faced by these models in understanding complex figures and performing rigorous reasoning, emphasizing the benchmark's importance in guiding future AI development for mathematically intensive real-world applications.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Meta Continual Learning Revisited: Implicitly Enhancing Online Hessian Approximation via Variance Reduction</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=TpD2aG1h0D&name=pdf" class="link-primary">https://openreview.net/attachment?id=TpD2aG1h0D&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">continual learning</span>
<span class="badge bg-primary">Hessian approximation</span>
<span class="badge bg-primary">Meta-Continual Learning</span>
<span class="badge bg-primary">variance reduction</span>
<span class="badge bg-primary">online learning</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper revisits Meta-Continual Learning (Meta-CL) and integrates it with regularization-based methods to enhance the approximation of the Hessian matrix during online learning. The authors introduce Variance Reduced Meta-CL (VR-MCL), which addresses the high variance challenges of Meta-CL caused by random sampling in memory buffers. VR-MCL employs a momentum-based variance reduction technique that improves the accuracy of the Hessian approximation, effectively balancing knowledge transfer and forgetting. Extensive experiments across multiple datasets demonstrate that VR-MCL consistently outperforms state-of-the-art continual learning methods, supported by theoretical analyses confirming its efficacy and regret bounds.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=VtmBAGCN7o&name=pdf" class="link-primary">https://openreview.net/attachment?id=VtmBAGCN7o&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">meta-programming</span>
<span class="badge bg-primary">multi-agent systems</span>
<span class="badge bg-primary">large language models</span>
<span class="badge bg-primary">software engineering</span>
<span class="badge bg-primary">standardized operating procedures</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents MetaGPT, a novel meta-programming framework that enhances multi-agent collaboration utilizing large language models (LLMs). Addressing issues in existing systems such as logic inconsistencies and hallucinations during complex task execution, MetaGPT integrates standardized operating procedures (SOPs) to streamline workflows and improve task decomposition. By assigning specialized roles to agents and employing structured communication protocols, the framework effectively manages collaboration, leading to more coherent solutions in software engineering tasks. Experimental results demonstrate MetaGPT's state-of-the-art performance on code generation benchmarks, achieving high success rates in comparison to existing frameworks, while highlighting the benefits of SOPs in mitigating errors and enhancing productivity.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">METRA: Scalable Unsupervised RL with Metric-Aware Abstraction</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=c5pwL0Soay&name=pdf" class="link-primary">https://openreview.net/attachment?id=c5pwL0Soay&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">unsupervised reinforcement learning</span>
<span class="badge bg-primary">Metric-Aware Abstraction</span>
<span class="badge bg-primary">scalability</span>
<span class="badge bg-primary">behavior discovery</span>
<span class="badge bg-primary">high-dimensional environments</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces Metric-Aware Abstraction (METRA), a novel unsupervised reinforcement learning (RL) approach aimed at addressing the scalability challenges posed by complex, high-dimensional environments. Unlike previous methods that either rely on exhaustive exploration or mutual information skill learning, METRA focuses on covering a compact latent space that connects to the state space through temporal distances. This enables the discovery of diverse, useful behaviors, even in pixel-based environments such as Quadruped and Humanoid. The experimental results demonstrate that METRA successfully learns locomotion skills and achieves superior state coverage compared to existing unsupervised RL methods, establishing itself as the first method to effectively discover such behaviors in challenging pixel-based settings.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Mixed-Type Tabular Data Synthesis with Score-based Diffusion in Latent Space</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=4Ay23yeuz0&name=pdf" class="link-primary">https://openreview.net/attachment?id=4Ay23yeuz0&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">tabular data synthesis</span>
<span class="badge bg-primary">diffusion models</span>
<span class="badge bg-primary">variational autoencoder</span>
<span class="badge bg-primary">mixed data types</span>
<span class="badge bg-primary">synthetic data quality</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents TABSYN, a novel methodology for synthesizing mixed-type tabular data using score-based diffusion models within a variational autoencoder (VAE) crafted latent space. TABSYN effectively addresses challenges associated with varied distributions and data types in tabular datasets by converting them into a unified embedding space, thereby preserving inter-column correlations. The approach offers significant advantages in terms of generality, quality, and speed, demonstrating improved synthetic data generation quality compared to existing methods, reducing error rates by 86% and 67% for column-wise distribution and pair-wise column correlation estimations, respectively. Extensive experiments validate TABSYN's superior performance across multiple datasets and metrics, establishing it as a leading solution in the field of tabular data synthesis.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=uNrFpDPMyo&name=pdf" class="link-primary">https://openreview.net/attachment?id=uNrFpDPMyo&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">KV cache compression</span>
<span class="badge bg-primary">Large Language Models</span>
<span class="badge bg-primary">generative inference</span>
<span class="badge bg-primary">attention mechanisms</span>
<span class="badge bg-primary">memory efficiency</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents FastGen, an innovative method for adaptive KV cache compression aimed at enhancing the efficiency of generative inference in Large Language Models (LLMs). Unlike traditional approaches that retain key and value vectors for all context tokens, FastGen employs targeted profiling of attention modules to identify unique structural patterns among different attention heads. This allows for dynamic eviction of less relevant context tokens, optimizing memory usage without requiring resource-intensive fine-tuning. Experimental results demonstrate that FastGen significantly reduces GPU memory consumptionâ€”up to 40%â€”while maintaining generation quality, showcasing its effectiveness across various tasks and model sizes. FastGen's ability to operate in a plug-and-play manner further emphasizes its practical utility in deploying large models economically.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Monte Carlo guided Denoising Diffusion models for Bayesian linear inverse problems.</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=nHESwXvxWK&name=pdf" class="link-primary">https://openreview.net/attachment?id=nHESwXvxWK&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Bayesian inference</span>
<span class="badge bg-primary">linear inverse problems</span>
<span class="badge bg-primary">denoising diffusion models</span>
<span class="badge bg-primary">Sequential Monte Carlo</span>
<span class="badge bg-primary">generative models</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces MCGdiff, a Sequential Monte Carlo (SMC) algorithm designed to address Bayesian linear inverse problems using score-based generative models (SGMs) as priors. It leverages the specific structure of these priors to construct a series of intermediate inverse problems that converge to the target posterior as noise decreases. The authors demonstrate that MCGdiff is theoretically grounded, providing numerical simulations that show its superior performance compared to existing methods in accurately sampling from the posterior distributions. The proposed method is applicable to various practical contexts, such as computational photography and medical imaging, making it a significant advancement in the field of Bayesian inference for ill-posed problems.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Multi-granularity Correspondence Learning from Long-term Noisy Videos</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=9Cu8MRmhq2&name=pdf" class="link-primary">https://openreview.net/attachment?id=9Cu8MRmhq2&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">video-language understanding</span>
<span class="badge bg-primary">long-term temporal dependencies</span>
<span class="badge bg-primary">optimal transport</span>
<span class="badge bg-primary">multi-granularity noisy correspondence</span>
<span class="badge bg-primary">contrastive learning</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents Norton, a novel framework for addressing the challenges of learning long-term temporal dependencies in video-language tasks, particularly in the context of noisy correspondence between video clips and captions. Existing methods primarily focus on short clips, neglecting the complexities introduced by long videos, which often suffer from multi-granularity noisy correspondence (MNC) issues, including coarse-grained clip-caption misalignments and fine-grained frame-word mismatches. Norton employs a unified optimal transport approach that incorporates video-paragraph and clip-caption contrastive losses to effectively capture long-term dependencies while mitigating MNC. Key innovations include an alignable prompt bucket for filtering irrelevant clips and captions, a soft-maximum operator for fine-grained alignment, and strategies to exploit faulty negatives in contrastive learning. Extensive experiments demonstrate the effectiveness of Norton across various tasks, including video retrieval and action segmentation, highlighting its robustness and computational efficiency in learning from long-term videos.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Multi-Source Diffusion Models for Simultaneous Music Generation and Separation</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=h922Qhkmx1&name=pdf" class="link-primary">https://openreview.net/attachment?id=h922Qhkmx1&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">music generation</span>
<span class="badge bg-primary">source separation</span>
<span class="badge bg-primary">diffusion models</span>
<span class="badge bg-primary">machine learning</span>
<span class="badge bg-primary">audio processing</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents a novel multi-source diffusion model (MSDM) designed for simultaneous music generation and source separation by learning the joint probability density of interdependent audio sources. The authors introduce a framework that facilitates total generation (creating complete music mixtures), partial generation (imputing missing sources given others), and source separation (isolating individual sources from a mixture). The model is trained on the Slakh2100 dataset and leverages a new inference method based on Dirac likelihood functions, yielding competitive results in source separation compared to state-of-the-art methods. By bridging the gap between music generation and source separation, the MSDM represents a significant advancement in creating versatile audio models that can aid in music composition and manipulation.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Multisize Dataset Condensation</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=FVhmnvqnsI&name=pdf" class="link-primary">https://openreview.net/attachment?id=FVhmnvqnsI&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">dataset condensation</span>
<span class="badge bg-primary">on-device processing</span>
<span class="badge bg-primary">computational efficiency</span>
<span class="badge bg-primary">subset degradation</span>
<span class="badge bg-primary">machine learning</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces the Multisize Dataset Condensation (MDC) method, which addresses challenges in dataset condensation for on-device machine learning applications. Traditional methods often require multiple condensation processes to create datasets of varying sizes, leading to unrepresentative subsets due to the subset degradation problem. MDC innovatively consolidates these processes into a single operation, utilizing an adaptive subset loss mechanism that selects the Most Learnable Subset (MLS) to enhance performance without additional computational burden. Experiments demonstrate significant accuracy improvements across various neural network architectures and datasets, showcasing MDC's efficiency in both training and storage requirements.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Neural Fine-Tuning Search for Few-Shot Learning</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=T7YV5UZKBc&name=pdf" class="link-primary">https://openreview.net/attachment?id=T7YV5UZKBc&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">few-shot learning</span>
<span class="badge bg-primary">neural architecture search</span>
<span class="badge bg-primary">fine-tuning</span>
<span class="badge bg-primary">deep learning</span>
<span class="badge bg-primary">adaptation strategies</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents Neural Fine-Tuning Search (NFTS), a novel approach for optimizing adaptation strategies in few-shot learning (FSL) using neural architecture search (NAS). The authors address the challenge of quickly adapting classifiers trained on one set of classes to novel ones by systematically determining which layers to fine-tune and where to insert adaptation modules. By employing a two-stage search approach, NFTS selects a diverse set of architectures during training and refines the choice based on the specific test episode. The framework is validated across various benchmarks, achieving state-of-the-art performance on both Meta-Dataset and Meta-Album, demonstrating its effectiveness in managing the trade-off between adaptability and overfitting in multi-domain FSL scenarios.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Never Train from Scratch: Fair Comparison of Long-Sequence Models Requires Data-Driven Priors</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=PdaPky8MUn&name=pdf" class="link-primary">https://openreview.net/attachment?id=PdaPky8MUn&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">long-range dependencies</span>
<span class="badge bg-primary">self-pretraining</span>
<span class="badge bg-primary">Transformers</span>
<span class="badge bg-primary">state space models</span>
<span class="badge bg-primary">performance evaluation</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper investigates the impact of self-pretraining (SPT) on the performance of long-sequence models, particularly Transformers and state space models (SSMs), in capturing long-range dependencies. The authors reveal that training from random initialization leads to an overestimation of performance differences between architectures. Through empirical studies using the Long Range Arena benchmark, they demonstrate that SPT significantly enhances the performance of vanilla Transformers and S4 models, allowing them to achieve competitive results without architectural modifications. Their findings suggest that data-driven priors from SPT can replace complex hand-crafted biases, highlighting the necessity of incorporating pretraining for accurate evaluation of model capabilities in long-sequence tasks.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">On the Humanity of Conversational AI: Evaluating the Psychological Portrayal of LLMs</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=H3UayAQWoE&name=pdf" class="link-primary">https://openreview.net/attachment?id=H3UayAQWoE&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Large Language Models</span>
<span class="badge bg-primary">Psychometrics</span>
<span class="badge bg-primary">Personality Assessment</span>
<span class="badge bg-primary">Emotional Intelligence</span>
<span class="badge bg-primary">AI Ethics</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents PsychoBench, a novel framework designed to evaluate the psychological portrayal of Large Language Models (LLMs) using thirteen psychometric scales categorized into personality traits, interpersonal relationships, motivational tests, and emotional abilities. By assessing five prominent LLMs, including ChatGPT and LLaMA-2, the study reveals distinct psychological profiles influenced by model variations and a jailbroken version of GPT-4, showcasing differences in personality traits and emotional intelligence compared to human norms. The findings emphasize the potential for LLMs to mimic human-like attributes, raising ethical considerations regarding their integration into society while offering insights for developing more empathetic AI systems. The authors advocate for careful consideration of these psychological evaluations to inform responsible AI deployment.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">On the Joint Interaction of Models, Data, and Features</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=ze7DOLi394&name=pdf" class="link-primary">https://openreview.net/attachment?id=ze7DOLi394&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">feature learning</span>
<span class="badge bg-primary">interaction tensor</span>
<span class="badge bg-primary">generalization disagreement equality</span>
<span class="badge bg-primary">deep learning</span>
<span class="badge bg-primary">model performance</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces the concept of an interaction tensor as a tool for analyzing the interaction between models, data, and features in deep learning. The authors propose a new framework for feature learning based on empirical observations, revealing that features in data are distributed in a long-tailed manner, with dominant and rare features influencing model performance. The study demonstrates that models with different initializations learn distinct features, affecting their predictions and confidence levels. Notably, the framework provides insight into the Generalization Disagreement Equality (GDE) phenomenon, allowing for accurate predictions of model behavior without assuming calibration. The findings highlight the complex relationships between features, data distributions, and model performance, underscoring the need for a deeper theoretical understanding of feature learning in deep learning systems.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">One-shot Empirical Privacy Estimation for Federated Learning</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=0BqyZSWfzo&name=pdf" class="link-primary">https://openreview.net/attachment?id=0BqyZSWfzo&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">federated learning</span>
<span class="badge bg-primary">differential privacy</span>
<span class="badge bg-primary">privacy estimation</span>
<span class="badge bg-primary">Gaussian mechanism</span>
<span class="badge bg-primary">membership inference attacks</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents a novel one-shot empirical privacy estimation method for federated learning (FL) that addresses the limitations of existing techniques, which often require extensive retraining and strong adversarial assumptions. The proposed method enables efficient privacy auditing during a single training run without needing prior knowledge about the model architecture or training tasks. By using random canary clients that generate independent model updates, the method estimates privacy loss under the Gaussian mechanism by analyzing the cosine similarities between canary updates and the final model. Experimental results demonstrate its effectiveness across various adversarial models, showing that the method can provide reasonable privacy estimates without significantly affecting model performance, ultimately serving as a useful metric for understanding privacy leakage in FL settings.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=bNt7oajl2a&name=pdf" class="link-primary">https://openreview.net/attachment?id=bNt7oajl2a&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">inductive reasoning</span>
<span class="badge bg-primary">language models</span>
<span class="badge bg-primary">hypothesis refinement</span>
<span class="badge bg-primary">AI performance</span>
<span class="badge bg-primary">human cognition</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper investigates the inductive reasoning capabilities of language models (LMs) through an iterative hypothesis refinement approach, which mimics human reasoning processes. The authors found that while LMs excel at generating hypotheses for various tasks, they struggle significantly with applying these rules effectively, highlighting a disparity between hypothesis generation and rule application. The study demonstrates that LMs perform well when combined with symbolic interpreters, achieving strong results in inductive reasoning benchmarks. However, LMs are also prone to brittleness when faced with minor perturbations in examples and often produce rules that differ notably from those generated by humans, emphasizing both the potential and limitations of LMs in reasoning tasks.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Pre-Training Goal-based Models for Sample-Efficient Reinforcement Learning</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=o2IEmeLL9r&name=pdf" class="link-primary">https://openreview.net/attachment?id=o2IEmeLL9r&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">reinforcement learning</span>
<span class="badge bg-primary">pre-training</span>
<span class="badge bg-primary">sample efficiency</span>
<span class="badge bg-primary">goal-conditioned policy</span>
<span class="badge bg-primary">hierarchical models</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces Pre-Training Goal-Based Models (PTGM) to enhance sample efficiency in reinforcement learning (RL) by pre-training goal-conditioned policies on large, task-agnostic datasets. PTGM employs a hierarchical approach where a low-level policy is pre-trained to execute goals, while a high-level policy generates these goals during RL tasks. The method addresses high-dimensional goal spaces through clustering, creating a discrete action space, and utilizes a pre-trained goal prior model to regularize high-level policy behavior, thereby improving exploration and learning stability. Experimental results in robotic simulations and the Minecraft environment demonstrate that PTGM significantly outperforms existing methods in sample efficiency and task performance, while also improving the interpretability and generalization of learned low-level skills.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Predictive auxiliary objectives in deep RL mimic learning in the brain</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=agPpmEgf8C&name=pdf" class="link-primary">https://openreview.net/attachment?id=agPpmEgf8C&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">predictive learning</span>
<span class="badge bg-primary">deep reinforcement learning</span>
<span class="badge bg-primary">representation learning</span>
<span class="badge bg-primary">brain modeling</span>
<span class="badge bg-primary">hippocampus</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper investigates the impact of predictive auxiliary objectives on representation learning within deep reinforcement learning (RL) systems and their parallels to representational changes observed in the brain. The authors demonstrate that integrating predictive objectives enhances learning efficiency, particularly in resource-limited architectures, and helps prevent representational collapse. They identify that longer predictive horizons can facilitate better transfer of learned representations to new tasks. The study draws connections between the components of the RL systemâ€”such as the prediction model, encoder network, and value learning networkâ€”and specific brain regions, notably the hippocampus and visual cortex, suggesting that these predictive models can mimic hippocampal functions related to memory and behavior. Overall, the findings propose a new perspective on how predictive learning in artificial intelligence can inform our understanding of brain mechanisms.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Protein Discovery with Discrete Walk-Jump Sampling</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=zMPHKOmQNb&name=pdf" class="link-primary">https://openreview.net/attachment?id=zMPHKOmQNb&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">protein discovery</span>
<span class="badge bg-primary">discrete sampling</span>
<span class="badge bg-primary">generative models</span>
<span class="badge bg-primary">antibody design</span>
<span class="badge bg-primary">energy-based models</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces a novel approach called Discrete Walk-Jump Sampling (dWJS) for generating high-quality, diverse, and functional antibody proteins using discrete generative models. By integrating a smoothed energy function with Langevin Markov chain Monte Carlo sampling and a unique denoising process, the authors improve the training and sampling efficiency of energy-based models while maintaining sample quality. The proposed framework demonstrates significant success in generating viable proteins, with an impressive 97-100% expression rate and 70% functional designs that exhibit enhanced binding affinity in laboratory tests. Additionally, the paper presents the Distributional Conformity Score (DCS) as a benchmark for evaluating generative models in protein design, positioning dWJS as an effective tool for therapeutic molecule discovery.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Provable Compositional Generalization for Object-Centric Learning</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=7VPTUWkiDQ&name=pdf" class="link-primary">https://openreview.net/attachment?id=7VPTUWkiDQ&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">compositional generalization</span>
<span class="badge bg-primary">object-centric learning</span>
<span class="badge bg-primary">autoencoders</span>
<span class="badge bg-primary">identifiability theory</span>
<span class="badge bg-primary">machine perception</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper investigates the conditions under which object-centric representations learned by autoencoders can achieve compositional generalization, which is the capacity to apply learned knowledge to novel combinations of known concepts. The authors address the theoretical and empirical gaps in understanding when compositional generalization is guaranteed, employing identifiability theory to prove that autoencoders with specific structural assumptions on their decoders can learn representations that generalize compositionally. They introduce two key propertiesâ€”additivity of the decoder and compositional consistency of the encoderâ€”which together ensure that the model can accurately identify and reconstruct unseen combinations of objects. Experiments demonstrate that enforcing these properties allows the model to generalize effectively, thus laying a foundation for future work in robust machine perception.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Proving Test Set Contamination in Black-Box Language Models</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=KS8mIvetg2&name=pdf" class="link-primary">https://openreview.net/attachment?id=KS8mIvetg2&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">test set contamination</span>
<span class="badge bg-primary">large language models</span>
<span class="badge bg-primary">statistical testing</span>
<span class="badge bg-primary">data exchangeability</span>
<span class="badge bg-primary">machine learning audits</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces a novel statistical test for identifying test set contamination in black box language models without needing access to their training data or weights. By leveraging the concept of exchangeability, the authors demonstrate that if a language model shows a preference for a specific ordering of a benchmark dataset, this indicates potential contamination. They develop a sharded likelihood comparison test that compares the log probabilities of the canonical ordering against shuffled examples, providing guarantees on false positive rates. The test is shown to be effective in detecting contamination even with small datasets and lower duplication counts, and the authors audit four popular language models, finding little evidence of pervasive contamination. Ultimately, this work paves the way for robust third-party audits of language models regarding dataset contamination.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Quick-Tune: Quickly Learning Which Pretrained Model to Finetune and How</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=tqh1zdXIra&name=pdf" class="link-primary">https://openreview.net/attachment?id=tqh1zdXIra&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">model selection</span>
<span class="badge bg-primary">hyperparameter optimization</span>
<span class="badge bg-primary">transfer learning</span>
<span class="badge bg-primary">meta-learning</span>
<span class="badge bg-primary">Bayesian optimization</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents Quick-Tune, a novel methodology designed to efficiently select the optimal pretrained model and corresponding hyperparameters for fine-tuning on new datasets, addressing the challenge posed by the growing number of available pretrained models. By evaluating over 20,000 hyperparameter configurations across 24 pretrained image classification models on 87 datasets, the authors create a comprehensive meta-dataset. Quick-Tune utilizes gray-box hyperparameter optimization, meta-learning, and cost-awareness to predict performance and costs, allowing for rapid and effective model selection and hyperparameter tuning. Experimental results show that Quick-Tune outperforms existing model selection and hyperparameter optimization techniques, establishing it as a practical solution for practitioners in machine learning. The authors have open-sourced their code and meta-dataset to promote reproducibility.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">ReLU Strikes Back: Exploiting Activation Sparsity in Large Language Models</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=osoWxY8q2E&name=pdf" class="link-primary">https://openreview.net/attachment?id=osoWxY8q2E&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">activation functions</span>
<span class="badge bg-primary">large language models</span>
<span class="badge bg-primary">ReLU</span>
<span class="badge bg-primary">inference efficiency</span>
<span class="badge bg-primary">activation sparsity</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper argues for the reinstatement of the ReLU activation function in large language models (LLMs) to enhance computational efficiency during inference, especially for resource-constrained devices. The authors demonstrate that using ReLU minimally impacts model performance while significantly reducing computation demandsâ€”up to three times lessâ€”due to increased activation sparsity. By fine-tuning existing models previously trained with other activation functions like GELU or SiLU, the authors find that performance can be rapidly restored. Furthermore, they explore innovative applications of activation sparsity for token generation speed and propose the shifted ReLU activation variant to enhance sparsity without sacrificing performance. Overall, the findings advocate for leveraging structured activation sparsity to improve the efficiency of LLMs.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Robust agents learn causal world models</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=pOoKI3ouv1&name=pdf" class="link-primary">https://openreview.net/attachment?id=pOoKI3ouv1&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">causal reasoning</span>
<span class="badge bg-primary">robust adaptation</span>
<span class="badge bg-primary">general intelligence</span>
<span class="badge bg-primary">distributional shifts</span>
<span class="badge bg-primary">causal models</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper investigates the necessity of causal reasoning for agents to adapt robustly to new environments and tasks. It establishes that any agent capable of maintaining a low regret bound amidst various distributional shifts must have learned an approximate causal model of the underlying data-generating process. The authors present theoretical results demonstrating that such causal models are essential for effective transfer learning and causal inference. Additionally, they discuss implications for adaptive agents, suggesting that learning a causal representation may enhance an agent's generalization capabilities across different tasks. The findings reinforce the link between causal understanding and general intelligence, proposing that robust AI systems inherently require causal world models.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Self-Alignment with Instruction Backtranslation</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=1oijHJBRsT&name=pdf" class="link-primary">https://openreview.net/attachment?id=1oijHJBRsT&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">instruction tuning</span>
<span class="badge bg-primary">language models</span>
<span class="badge bg-primary">self-augmentation</span>
<span class="badge bg-primary">self-curation</span>
<span class="badge bg-primary">backtranslation</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents a novel method called "instruction backtranslation" for enhancing instruction-following capabilities in large language models (LLMs) by leveraging large amounts of unlabeled web data. Instead of relying on extensive human-annotated datasets, the approach utilizes a finetuned seed model to generate potential instruction-output pairs from unlabelled text, which are then curated for quality through iterative self-training. This self-augmentation and self-curation process significantly improves the model's performance, as demonstrated by achieving state-of-the-art results on the Alpaca leaderboard without using distillation data. The findings suggest that high-quality, self-generated instruction data can effectively align LLMs to follow instructions while reducing the dependence on human annotation.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=hSyW5go0v8&name=pdf" class="link-primary">https://openreview.net/attachment?id=hSyW5go0v8&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">retrieval-augmented generation</span>
<span class="badge bg-primary">self-reflection</span>
<span class="badge bg-primary">large language models</span>
<span class="badge bg-primary">factual accuracy</span>
<span class="badge bg-primary">model training</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces Self-Reflective Retrieval-Augmented Generation (SELF-RAG), a novel framework designed to enhance the quality and factual accuracy of large language models (LLMs) by integrating on-demand retrieval and self-reflection mechanisms. Unlike conventional Retrieval-Augmented Generation (RAG) methods that retrieve a fixed number of passages indiscriminately, SELF-RAG employs a flexible approach where the model determines the necessity of retrieval, processes relevant passages, and generates special reflection tokens to critique its own outputs. This adaptive generation process allows for improved factuality and citation accuracy across various tasks, outperforming state-of-the-art LLMs like ChatGPT and retrieval-augmented Llama2-chat in diverse evaluations. The framework demonstrates significant advantages in performance while maintaining the versatility of the LLM, making it a promising advancement in addressing the factual shortcomings of previous models.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Small-scale proxies for large-scale Transformer training instabilities</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=d8w0pmvXbZ&name=pdf" class="link-primary">https://openreview.net/attachment?id=d8w0pmvXbZ&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">training stability</span>
<span class="badge bg-primary">Transformers</span>
<span class="badge bg-primary">learning rate sensitivity</span>
<span class="badge bg-primary">small-scale models</span>
<span class="badge bg-primary">optimization techniques</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper investigates the training instabilities encountered when scaling Transformer-based models, focusing on reproducing and understanding these issues at smaller scales. The authors identify two main sources of instabilityâ€”the growth of logits in attention layers and output logit divergenceâ€”and demonstrate that these instabilities can also manifest in small models when trained at high learning rates. They introduce the concept of learning rate (LR) sensitivity as a metric to analyze the relationship between learning rate and loss, revealing that certain mitigations previously effective at large scales, such as qk-layernorm and z-loss regularization, are similarly beneficial for smaller models. Additionally, the study explores various optimizer and model interventions, finding that methods like warm-up and independent weight decay can help reduce LR sensitivity. The findings suggest that small-scale models offer valuable insights into training stability, enabling the prediction of instabilities and highlighting new issues that may arise with scaling.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Statistically Optimal K -means Clustering via Nonnegative Low-rank Semidefinite Programming</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=v7ZPwoHU1j&name=pdf" class="link-primary">https://openreview.net/attachment?id=v7ZPwoHU1j&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">K-means clustering</span>
<span class="badge bg-primary">nonnegative matrix factorization</span>
<span class="badge bg-primary">semidefinite programming</span>
<span class="badge bg-primary">statistical optimality</span>
<span class="badge bg-primary">algorithm scalability</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents a novel algorithm for K-means clustering that combines the simplicity and scalability of nonnegative matrix factorization (NMF) with the strong statistical guarantees provided by semidefinite programming (SDP) relaxations. The proposed method employs a nonnegative low-rank factorization approach, optimized through a primal-dual gradient descent algorithm. This allows it to maintain the computational efficiency of NMF while achieving the same level of statistical optimality as SDP, which is traditionally inaccessible for large datasets due to its high computational cost. Experimental results demonstrate that the new algorithm significantly reduces mis-clustering errors compared to existing state-of-the-art methods while remaining scalable for practical applications.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">SWE-bench: Can Language Models Resolve Real-world Github Issues?</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=VTF8yNQM66&name=pdf" class="link-primary">https://openreview.net/attachment?id=VTF8yNQM66&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">language models</span>
<span class="badge bg-primary">software engineering</span>
<span class="badge bg-primary">benchmark evaluation</span>
<span class="badge bg-primary">GitHub issues</span>
<span class="badge bg-primary">code generation</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents SWE-bench, a novel evaluation framework designed to assess the capabilities of language models (LMs) in resolving real-world software engineering issues derived from GitHub repositories. Comprising 2,294 tasks sourced from 12 popular Python repositories, SWE-bench challenges LMs to understand complex problems that require extensive context and intricate reasoning, often involving multiple functions and files. Despite the complexity of the tasks, evaluations reveal that even the best-performing models, such as Claude 2, only succeed in resolving 1.96% of issues, indicating a significant gap in current LM capabilities for practical software engineering tasks. The paper emphasizes the need for more realistic benchmarks like SWE-bench to facilitate future advancements in LMs, promoting their development toward more intelligent and autonomous systems.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">The mechanistic basis of data dependence and abrupt learning in an in-context classification task</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=aN4Jf6Cx69&name=pdf" class="link-primary">https://openreview.net/attachment?id=aN4Jf6Cx69&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">in-context learning</span>
<span class="badge bg-primary">transformer models</span>
<span class="badge bg-primary">induction heads</span>
<span class="badge bg-primary">data distribution</span>
<span class="badge bg-primary">abrupt transitions</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper investigates the mechanisms underlying in-context learning (ICL) in transformer models, specifically focusing on how data distributional properties influence the emergence of abrupt learning transitions. The authors demonstrate that ICL, which allows models to predict responses based on contextual examples without weight updates, is driven by the formation of an induction head in the model's architecture. Through both empirical experiments and a minimal two-parameter model of the induction head, they reveal that specific distributional features, such as burstiness and rank-frequency distributions, enhance ICL while simultaneously constraining in-weights learning (IWL). The study concludes that the abrupt learning transitions observed in ICL can be attributed to a series of nested logits that create sharp gradients in the loss landscape, highlighting the complex interplay between data characteristics and the architecture of attention-based networks.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Topological data analysis on noisy quantum computers</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=dLrhRIMVmB&name=pdf" class="link-primary">https://openreview.net/attachment?id=dLrhRIMVmB&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Topological Data Analysis</span>
<span class="badge bg-primary">Quantum Computing</span>
<span class="badge bg-primary">NISQ Algorithms</span>
<span class="badge bg-primary">Betti Numbers</span>
<span class="badge bg-primary">Machine Learning</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents NISQ-TDA, a novel quantum algorithm designed for estimating Betti numbers in topological data analysis (TDA) on noisy quantum computers. Unlike classical TDA methods, which are computationally prohibitive for high-dimensional data, NISQ-TDA operates efficiently on Noisy Intermediate-Scale Quantum (NISQ) devices without the need for fault tolerance. The algorithm leverages a short circuit-depth and avoids the data-loading problem by processing input data dynamically. Empirical results demonstrate its robustness against noise, suggesting its potential as a useful tool for machine learning and scientific applications in analyzing complex datasets. The findings indicate that NISQ-TDA could provide significant speedups over classical methods under certain conditions, thus revitalizing the use of TDA in practical scenarios.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Towards a statistical theory of data selection under weak supervision</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=HhfcNgQn6p&name=pdf" class="link-primary">https://openreview.net/attachment?id=HhfcNgQn6p&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">data selection</span>
<span class="badge bg-primary">weak supervision</span>
<span class="badge bg-primary">statistical theory</span>
<span class="badge bg-primary">machine learning</span>
<span class="badge bg-primary">empirical risk minimization</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents a statistical theory for data selection under weak supervision, focusing on how to effectively choose a smaller subset of unlabeled samples from a larger dataset for statistical estimation or learning. The authors explore various data selection methods and demonstrate through theoretical analysis and numerical experiments that certain popular approaches, such as unbiased subsampling, can be suboptimal. They find that selecting data based on uncertainty can outperform full-sample training in some cases, and that the effectiveness of data selection schemes is sensitive to the choice of sampling fraction and the quality of surrogate models. The work emphasizes the potential of biased selection schemes and highlights the need for a tailored approach to data selection depending on the specific learning context.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Understanding In-Context Learning in Transformers and LLMs by Learning to Learn Discrete Functions</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=ekeyCgeRfC&name=pdf" class="link-primary">https://openreview.net/attachment?id=ekeyCgeRfC&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">In-context learning</span>
<span class="badge bg-primary">Transformers</span>
<span class="badge bg-primary">Large Language Models</span>
<span class="badge bg-primary">Boolean functions</span>
<span class="badge bg-primary">Sample efficiency</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper investigates the phenomenon of in-context learning in Transformers and Large Language Models (LLMs) by studying their ability to learn discrete functions, particularly Boolean functions. The authors find that while Transformers can perform well on simpler tasks, their performance declines on more complex functions like parities, suggesting limitations in their learning capabilities. They also demonstrate that Transformers can adaptively select between different algorithms for the same task based on the provided examples, achieving higher sample efficiency when given teaching sequences. Furthermore, pretrained LLMs like GPT-4 and LLaMA-2 show competitive performance on prediction tasks, indicating that they can implement learning algorithms in a practical setting. Overall, the study enhances the understanding of in-context learning and the efficiency of various model architectures.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Unified Generative Modeling of 3D Molecules with Bayesian Flow Networks</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=NSVtmmzeRB&name=pdf" class="link-primary">https://openreview.net/attachment?id=NSVtmmzeRB&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">3D Molecule Generation</span>
<span class="badge bg-primary">Bayesian Flow Networks</span>
<span class="badge bg-primary">Generative Modeling</span>
<span class="badge bg-primary">Molecular Geometry</span>
<span class="badge bg-primary">Noise Sensitivity</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces Geometric Bayesian Flow Networks (GeoBFN), a novel generative model designed for 3D molecular geometry that addresses challenges related to multi-modality and noise sensitivity. By employing a unified probabilistic modeling approach and incorporating equivariant inter-dependency modeling, GeoBFN maintains SE-(3) invariant density properties, enabling effective representation of diverse molecular modalities. The model demonstrates state-of-the-art performance on various 3D molecule generation benchmarks, achieving high molecule and atom stability and allowing flexible sampling steps that optimize the balance between efficiency and quality. GeoBFN's innovative design highlights its potential for advancing scientific discoveries in material and drug design.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Unprocessing Seven Years of Algorithmic Fairness</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=jr03SfWsBS&name=pdf" class="link-primary">https://openreview.net/attachment?id=jr03SfWsBS&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">algorithmic fairness</span>
<span class="badge bg-primary">postprocessing</span>
<span class="badge bg-primary">error rate parity</span>
<span class="badge bg-primary">machine learning</span>
<span class="badge bg-primary">unprocessing</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper critically evaluates the efficacy of postprocessing methods for achieving algorithmic fairness, specifically focusing on equalizing error rates across demographic groups. Through an extensive empirical study involving over 11,000 model evaluations on various tabular datasets, the authors demonstrate that postprocessing consistently dominates other fairness intervention methods in terms of the fairness-accuracy Pareto frontier. They introduce a novel concept termed "unprocessing," which allows for a fair comparison of different fairness methods by mapping fairness-constrained models back to their unconstrained counterparts. The findings indicate that the simplest postprocessing approach remains optimal for achieving error rate parity, challenging the assumption that more complex methods yield better outcomes.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">ValUES: A Framework for Systematic Validation of Uncertainty Estimation in Semantic Segmentation</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=yV6fD7LYkF&name=pdf" class="link-primary">https://openreview.net/attachment?id=yV6fD7LYkF&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">uncertainty estimation</span>
<span class="badge bg-primary">semantic segmentation</span>
<span class="badge bg-primary">evaluation framework</span>
<span class="badge bg-primary">aleatoric uncertainty</span>
<span class="badge bg-primary">epistemic uncertainty</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents a systematic framework, termed ValUES, for the validation of uncertainty estimation methods in semantic segmentation, addressing the significant gap between theoretical advancements and practical applications. It identifies key pitfalls in the current literature regarding the separation and evaluation of aleatoric (AU) and epistemic uncertainty (EU), proposing a controlled environment for studying data ambiguities and distribution shifts. The framework allows for systematic ablations of uncertainty method components and evaluates their effectiveness across five predominant applications: out-of-distribution detection, active learning, failure detection, calibration, and ambiguity modeling. Empirical studies reveal that while AU and EU can be theoretically separated, this often does not translate to real-world scenarios, highlighting the importance of method components, particularly aggregation strategies, in determining the performance of uncertainty methods. The findings offer practical recommendations for researchers and practitioners in the field.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Vision Transformers Need Registers</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=2dnO3LLiJ1&name=pdf" class="link-primary">https://openreview.net/attachment?id=2dnO3LLiJ1&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Vision Transformers</span>
<span class="badge bg-primary">Feature Maps</span>
<span class="badge bg-primary">Artifact Detection</span>
<span class="badge bg-primary">Register Tokens</span>
<span class="badge bg-primary">Dense Prediction Tasks</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper investigates artifacts present in the feature maps of Vision Transformer (ViT) models, specifically DINOv2, which exhibit high-norm tokens in low-informative background areas during inference. The authors propose a solution by introducing additional "register" tokens to the input sequence, which mitigates these artifacts and enhances model performance on dense prediction tasks and object discovery. The findings demonstrate that this approach not only alleviates issues in DINOv2 but is also effective in other supervised models like DeiT-III and OpenCLIP, leading to smoother feature and attention maps, thereby setting new benchmarks in self-supervised visual modeling.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Wrstchen: An Efficient Architecture for Large-Scale Text-to-Image Diffusion Models</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=gU58d5QeGv&name=pdf" class="link-primary">https://openreview.net/attachment?id=gU58d5QeGv&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">text-to-image synthesis</span>
<span class="badge bg-primary">diffusion models</span>
<span class="badge bg-primary">computational efficiency</span>
<span class="badge bg-primary">latent representation</span>
<span class="badge bg-primary">model architecture</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces Wurstchen, an innovative architecture for text-to-image synthesis that significantly enhances computational efficiency while maintaining competitive image quality. By employing a three-stage process, Wurstchen utilizes a latent diffusion technique that generates a highly compressed semantic image representation to guide the diffusion process, resulting in a drastic reduction in training hoursâ€”from 200,000 hours for Stable Diffusion 2.1 to approximately 24,602 hours for Wurstchenâ€”while also achieving superior image quality. The model's architecture decouples text-conditional generation from high-resolution image projection, allowing for faster inference and a smaller carbon footprint. Comprehensive evaluations demonstrate that Wurstchen not only matches the performance of existing state-of-the-art models but also excels in user preference studies, highlighting its potential for democratizing high-quality image generation.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Zipformer: A faster and better encoder for automatic speech recognition</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=9WD9KwssyT&name=pdf" class="link-primary">https://openreview.net/attachment?id=9WD9KwssyT&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">automatic speech recognition</span>
<span class="badge bg-primary">Zipformer</span>
<span class="badge bg-primary">optimization</span>
<span class="badge bg-primary">model efficiency</span>
<span class="badge bg-primary">encoder architecture</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents Zipformer, a novel encoder model designed for automatic speech recognition (ASR) that improves upon the Conformer architecture by enhancing speed, memory efficiency, and performance. Key innovations include a U-Net-like encoder structure with variable frame rates, a redesigned block structure that reuses attention weights, a new normalization technique called BiasNorm, and the introduction of two new activation functions, SwooshR and SwooshL. Additionally, a parameter-scale-invariant optimizer named ScaledAdam is proposed, which enhances convergence speed and model performance. Extensive experiments on multiple datasets, including LibriSpeech, Aishell-1, and WenetSpeech, confirm that Zipformer achieves state-of-the-art results, demonstrating significant improvements in both efficiency and recognition accuracy compared to existing models.</p>
</div>
</div>
</div>
</div>

        </div>
    </div>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>
