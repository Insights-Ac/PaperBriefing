
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>PubSummarizer - ICML 2024 Oral Papers</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <script src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
</head>
<body>
    <div class="container py-4">
        <h1 class="mb-4">ICML 2024 Oral Papers</h1>
        <p class="text-muted"><em>Generated on 2024-11-18 13:03:03 by <a href="https://github.com/Logan-Lin/PubSummarizer">PubSummarizer</a></em></p>
        <div class="row" data-masonry='{"percentPosition": true }'>
            <div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">A Dynamic Algorithm for Weighted Submodular Cover Problem</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=uUeXaKLE1I&name=pdf" class="link-primary">https://openreview.net/attachment?id=uUeXaKLE1I&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">dynamic algorithms</span>
<span class="badge bg-primary">submodular cover</span>
<span class="badge bg-primary">approximation algorithms</span>
<span class="badge bg-primary">query complexity</span>
<span class="badge bg-primary">optimization</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces a randomized algorithm for the dynamic weighted submodular cover problem, where the ground set undergoes insertions and deletions. The authors aim to maintain an approximately optimal solution with low query complexity after each update. The algorithm achieves a (1O(), O(1))-bicriteria approximation, significantly improving upon previous methods that assumed static ground sets. By leveraging a hierarchical data structure and managing updates efficiently, the proposed solution can handle dynamic changes while ensuring performance remains competitive in terms of approximation and query complexity, with expected amortized query complexity being polylogarithmic in nature.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=dBqHGZPGZI&name=pdf" class="link-primary">https://openreview.net/attachment?id=dBqHGZPGZI&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">alignment algorithms</span>
<span class="badge bg-primary">toxicity</span>
<span class="badge bg-primary">direct preference optimization</span>
<span class="badge bg-primary">language models</span>
<span class="badge bg-primary">jailbreaks</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper investigates the mechanisms behind alignment algorithms, specifically focusing on Direct Preference Optimization (DPO) and its effectiveness in reducing toxicity in pre-trained language models such as GPT2 and Llama2. The authors explore how toxicity is represented and elicited within these models, demonstrating that DPO does not eliminate toxic capabilities but rather enables the models to bypass them through minimal parameter adjustments. By analyzing the representation space and using pairwise preference data, the study reveals that although aligned models can suppress undesirable outputs, they remain susceptible to being unaligned or "jailbroken" through targeted interventions. The findings emphasize the importance of understanding these mechanisms to design more robust alignment strategies for safer language models.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">A Touch, Vision, and Language Dataset for Multimodal Alignment</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=tFEOOH9eH0&name=pdf" class="link-primary">https://openreview.net/attachment?id=tFEOOH9eH0&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">tactile perception</span>
<span class="badge bg-primary">multimodal learning</span>
<span class="badge bg-primary">dataset creation</span>
<span class="badge bg-primary">vision-language alignment</span>
<span class="badge bg-primary">generative models</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces a novel dataset called the Touch-Vision-Language (TVL) dataset, comprising 44,000 in-the-wild vision-touch pairs annotated with tactile sensations in natural language. This dataset aims to address the challenge of integrating the tactile modality into multimodal generative language models, which has been hindered by a lack of labeled tactile data. The authors propose a tactile encoder aligned with both vision and language modalities, resulting in a Touch-Vision-Language model (TVL model) that significantly improves tactile-vision-language alignment, outperforming existing models by notable margins. The study demonstrates that the combination of human annotations and pseudo-labels generated by GPT-4V enhances model performance, suggesting a promising direction for future research in multimodal understanding and the role of tactile perception in AI.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Accurate LoRA-Finetuning Quantization of LLMs via Information Retention</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=jQ92egz5Ym&name=pdf" class="link-primary">https://openreview.net/attachment?id=jQ92egz5Ym&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">LoRA</span>
<span class="badge bg-primary">Quantization</span>
<span class="badge bg-primary">Large Language Models</span>
<span class="badge bg-primary">Information Retention</span>
<span class="badge bg-primary">Efficiency</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces IR-QLoRA, a novel method for accurately quantizing large language models (LLMs) utilizing LoRA finetuning through enhanced information retention. It addresses the significant accuracy degradation typically associated with LLM quantization by implementing two key techniques: Information Calibration Quantization (ICQ), which maximizes the retention of original information in quantized parameters, and Information Elastic Connection (IEC), which enhances the representation capacity of LoRA. Extensive experiments demonstrate that IR-QLoRA achieves substantial accuracy improvements across various LLaMA and LLaMA2 models under low bit-width quantization (2-4 bits) while incurring minimal additional time costs, thus proving its versatility and efficiency in resource-constrained deployment scenarios.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">ACE: Off-Policy Actor-Critic with Causality-Aware Entropy Regularization</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=1puvYh729M&name=pdf" class="link-primary">https://openreview.net/attachment?id=1puvYh729M&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Reinforcement Learning</span>
<span class="badge bg-primary">Causality</span>
<span class="badge bg-primary">Off-Policy Algorithms</span>
<span class="badge bg-primary">Actor-Critic</span>
<span class="badge bg-primary">Exploration Efficiency</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces ACE, an off-policy actor-critic algorithm that incorporates causality-aware entropy regularization to enhance exploration efficiency in reinforcement learning (RL). It addresses the limitation of traditional RL methods that overlook the varying significance of primitive behaviors during policy learning. By leveraging causal relationships between actions and rewards, ACE prioritizes exploration of actions with higher impact while mitigating the risk of overfitting through a gradient dormancy-guided reset mechanism. Extensive experiments across 29 continuous control tasks demonstrate that ACE significantly outperforms existing model-free RL baselines, showcasing its effectiveness and versatility in improving sample efficiency and performance across diverse domains.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Active Adaptive Experimental Design for Treatment Effect Estimation with Covariate Choice</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=K6HpbvkrwO&name=pdf" class="link-primary">https://openreview.net/attachment?id=K6HpbvkrwO&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">adaptive experimental design</span>
<span class="badge bg-primary">treatment effect estimation</span>
<span class="badge bg-primary">covariate optimization</span>
<span class="badge bg-primary">semiparametric efficiency</span>
<span class="badge bg-primary">ATE estimator</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents a novel adaptive experimental design aimed at efficiently estimating average treatment effects (ATEs) by optimizing both the covariate density and the propensity score throughout the experiment. The authors derive the semiparametric efficiency bound for ATEs, demonstrating that simultaneous optimization of covariate density enhances the efficiency of treatment allocation compared to traditional methods that focus solely on propensity scores. They introduce the Active-Adaptive-Sampling-and-Augmented-Inverse-Probability-Weighting (AAS-AIPWIW) experiment, which employs adaptive sampling strategies based on past observations to minimize asymptotic variance in ATE estimation. The method incorporates an ATE estimator whose asymptotic variance aligns with the derived efficiency bound, showcasing significant improvements in estimation efficiency through simulation studies that validate the effectiveness of the proposed design across varying conditions.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Active Statistical Inference</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=GKMcCtWC7H&name=pdf" class="link-primary">https://openreview.net/attachment?id=GKMcCtWC7H&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">active inference</span>
<span class="badge bg-primary">statistical inference</span>
<span class="badge bg-primary">machine learning</span>
<span class="badge bg-primary">data collection</span>
<span class="badge bg-primary">confidence intervals</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents "active inference," a novel methodology that leverages machine learning to optimize data labeling under budget constraints in statistical inference tasks. By prioritizing data points where the model is uncertain, active inference allows for more effective use of available labeling resources, resulting in valid confidence intervals and hypothesis tests with fewer samples compared to traditional methods. Experiments on datasets from public opinion research, census analysis, and proteomics demonstrate that active inference significantly reduces sample budgets—up to 85% savings in some cases—while maintaining accuracy, thereby addressing the challenges of collecting high-quality labeled data in data-driven research.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">AI Control: Improving Safety Despite Intentional Subversion</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=KviM5k8pcP&name=pdf" class="link-primary">https://openreview.net/attachment?id=KviM5k8pcP&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">AI control</span>
<span class="badge bg-primary">safety protocols</span>
<span class="badge bg-primary">large language models</span>
<span class="badge bg-primary">intentional subversion</span>
<span class="badge bg-primary">red teaming</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents a novel approach called AI control, focusing on safety measures for large language models (LLMs) that may intentionally subvert protocols designed to prevent harmful outcomes. The authors develop and evaluate various safety protocols within the APPS backdooring setting, aiming to solve programming problems without submitting code that contains backdoors. By employing a combination of trusted and untrusted models, along with human oversight, the study assesses the effectiveness of these protocols against adversarial strategies through red teaming. The results indicate that certain protocols, particularly trusted monitoring and trusted editing, significantly enhance safety while maintaining a high level of usefulness, achieving over 90% safety in preventing backdoor submissions. This work highlights the importance of robust evaluation methodologies for maintaining safety in increasingly autonomous AI systems.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">All-in-one simulation-based inference</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=DL79HYCFFq&name=pdf" class="link-primary">https://openreview.net/attachment?id=DL79HYCFFq&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Amortized Bayesian inference</span>
<span class="badge bg-primary">Probabilistic diffusion models</span>
<span class="badge bg-primary">Transformers</span>
<span class="badge bg-primary">Simulation-based inference</span>
<span class="badge bg-primary">Flexible parameter estimation</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces Simformer, an innovative method for amortized Bayesian inference that utilizes probabilistic diffusion models combined with transformer architectures, addressing limitations of current simulation-based inference methods that are often inflexible and simulation-intensive. Simformer enables rapid inference across various tasks by effectively estimating all conditional distributions of parameters and data, including posterior and likelihood, even when dealing with unstructured or missing data. The method's flexibility allows it to handle function-valued parameters and unstructured datasets, making it suitable for applications in diverse fields like ecology, epidemiology, and neuroscience. Through extensive benchmarking, Simformer demonstrates superior performance compared to existing state-of-the-art approaches, achieving enhanced accuracy and efficiency in Bayesian inference tasks.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">AlphaFold Meets Flow Matching for Generating Protein Ensembles</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=rs8Sh2UASt&name=pdf" class="link-primary">https://openreview.net/attachment?id=rs8Sh2UASt&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">protein ensembles</span>
<span class="badge bg-primary">generative modeling</span>
<span class="badge bg-primary">AlphaFold</span>
<span class="badge bg-primary">molecular dynamics</span>
<span class="badge bg-primary">flow matching</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents a novel approach combining AlphaFold and ESMFold with flow matching to generate protein structural ensembles, addressing the limitations of existing methods that primarily focus on single-state predictions. The proposed methods, named Alpha FLOW and ESM FLOW, are fine-tuned under a custom flow matching framework, enabling them to capture conformational flexibility and diversity more effectively than traditional MSA subsampling techniques. The authors demonstrate that these models outperform existing methods on benchmarks involving both PDB structures and molecular dynamics simulations, offering a promising alternative to expensive physics-based simulations for generating diverse protein conformations. This work significantly enhances our ability to predict and analyze the dynamic nature of protein structures, which is vital for understanding their biological functions.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Any-Precision LLM: Low-Cost Deployment of Multiple, Different-Sized LLMs</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=u09gadH3BU&name=pdf" class="link-primary">https://openreview.net/attachment?id=u09gadH3BU&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">quantization</span>
<span class="badge bg-primary">large language models</span>
<span class="badge bg-primary">memory efficiency</span>
<span class="badge bg-primary">any-precision</span>
<span class="badge bg-primary">deployment</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents a novel approach called "any-precision LLM" aimed at reducing the deployment costs associated with multiple large language models (LLMs) of varying sizes. By leveraging a lightweight method for any-precision quantization, which extends the concept of any-precision deep neural networks to LLMs, the authors propose a solution that allows multiple models to be stored in memory as a single large model while maintaining high quality and inference throughput. The method involves a post-training quantization framework and the development of a specialized software engine designed to optimize memory usage and speed up inference times. Experimental results demonstrate significant memory savings and efficient performance, establishing any-precision LLM as a promising approach for practical deployment scenarios across various devices.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">APT: Adaptive Pruning and Tuning Pretrained Language Models for Efficient Training and Inference</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=sb81Xl50JG&name=pdf" class="link-primary">https://openreview.net/attachment?id=sb81Xl50JG&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Language Models</span>
<span class="badge bg-primary">Fine-tuning</span>
<span class="badge bg-primary">Pruning</span>
<span class="badge bg-primary">Efficiency</span>
<span class="badge bg-primary">Knowledge Distillation</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents APT (Adaptive Pruning and Tuning), a novel approach aimed at enhancing the training and inference efficiency of large pre-trained language models (LMs) like RoBERTa, T5, and LLaMA. APT simultaneously prunes less significant parameters and tunes important ones during the early stages of fine-tuning, thereby optimizing both memory usage and convergence speed. Experimental results show that APT can maintain up to 98% task performance while pruning up to 60% of parameters in RoBERTa and T5, and 86.4% in LLaMA with 70% remaining parameters. Additionally, APT reduces the memory footprint by up to 70% and speeds up training by up to 8 times compared to traditional methods. The method is presented as a solution to the challenges of high resource consumption in fine-tuning large LMs, striking a balance between efficiency and performance.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Arrows of Time for Large Language Models</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=UpSe7ag34v&name=pdf" class="link-primary">https://openreview.net/attachment?id=UpSe7ag34v&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Arrow of Time</span>
<span class="badge bg-primary">Large Language Models</span>
<span class="badge bg-primary">Autoregressive Models</span>
<span class="badge bg-primary">Probabilistic Modeling</span>
<span class="badge bg-primary">Information Theory</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper investigates the concept of "Arrow of Time" (AoT) in the context of Autoregressive Large Language Models (LLMs), focusing on their probabilistic modeling abilities. The authors empirically demonstrate a consistent asymmetry in the prediction performance of these models when tasked with predicting the next versus the previous token, revealing a significant difference in average log-perplexity. This phenomenon appears to be robust across various languages, model sizes, and training configurations. The authors propose a theoretical framework that relates this asymmetry to sparsity and computational complexity, highlighting how certain probabilistic measures are inherently more difficult to learn in a backward context. The findings have implications for understanding the nature of language modeling and the inherent structural features of natural languages.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Automated Evaluation of Retrieval-Augmented Language Models with Task-Specific Exam Generation</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=4jqOV6NlUz&name=pdf" class="link-primary">https://openreview.net/attachment?id=4jqOV6NlUz&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Retrieval-Augmented Language Models</span>
<span class="badge bg-primary">Automated Evaluation</span>
<span class="badge bg-primary">Item Response Theory</span>
<span class="badge bg-primary">Task-Specific Exams</span>
<span class="badge bg-primary">Language Model Performance</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces a novel methodology for evaluating Retrieval-Augmented Large Language Models (RAG) by employing automated, task-specific exams generated from relevant document corpora. The proposed approach utilizes Item Response Theory (IRT) to assess the accuracy and effectiveness of RAG systems through multiple-choice questions, allowing for scalable and interpretable evaluations without the need for manually annotated datasets. The authors demonstrate their method across four distinct open-ended Question-Answering tasks, revealing insights into performance drivers such as retrieval mechanisms and model sizes. Key findings indicate that optimizing retrieval components can yield greater performance improvements than merely increasing model size, emphasizing the importance of a comprehensive design strategy for effective RAG systems. The researchers also provide an open-source implementation of their framework, facilitating further exploration and application in various domains.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Bottleneck-Minimal Indexing for Generative Document Retrieval</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=MFPYCvWsNR&name=pdf" class="link-primary">https://openreview.net/attachment?id=MFPYCvWsNR&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">generative document retrieval</span>
<span class="badge bg-primary">information bottleneck</span>
<span class="badge bg-primary">indexing methods</span>
<span class="badge bg-primary">neural networks</span>
<span class="badge bg-primary">empirical evaluation</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces a novel approach to generative document retrieval (GDR) by applying information-theoretic principles, particularly the information bottleneck theory, to improve the indexing of documents for query mapping. The authors argue that traditional indexing methods have primarily focused on document representation without considering the distribution of queries. They propose a bottleneck-minimal indexing (BMI) method that clusters queries instead of documents, leading to improved indexing performance. Empirical evaluations using the NQ320K and MARCO datasets demonstrate that BMI outperforms existing indexing methods, significantly enhancing retrieval accuracy, especially with smaller neural network models. This work highlights the importance of incorporating query distribution in designing effective document retrieval systems, suggesting that optimal indexing requires a balance between conciseness and retrieval accuracy.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Candidate Pseudolabel Learning: Enhancing Vision-Language Models by Prompt Tuning with Unlabeled Data</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=sBJNokmYuV&name=pdf" class="link-primary">https://openreview.net/attachment?id=sBJNokmYuV&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">candidate pseudolabel learning</span>
<span class="badge bg-primary">vision-language models</span>
<span class="badge bg-primary">prompt tuning</span>
<span class="badge bg-primary">unlabeled data</span>
<span class="badge bg-primary">classification performance</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces Candidate Pseudolabel Learning (CPL), a method designed to enhance the performance of vision-language models (VLMs) by leveraging abundant unlabeled data through a refined pseudolabeling strategy. The approach addresses the shortcomings of traditional hard pseudolabels, which often lead to misclassifications when VLMs exhibit low zero-shot performance. CPL generates candidate pseudolabels by progressively selecting labels based on confidence scores and employing both intra- and inter-instance label selection, resulting in more accurate and balanced representations of classes. Extensive experiments across nine benchmark datasets in various learning paradigms demonstrate CPL's effectiveness, showing superior performance compared to existing methods, particularly in scenarios where the initial zero-shot capabilities of VLMs are inadequate.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Chain of Code: Reasoning with a Language Model-Augmented Code Emulator</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=vKtomqlSxm&name=pdf" class="link-primary">https://openreview.net/attachment?id=vKtomqlSxm&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Language Models</span>
<span class="badge bg-primary">Code Execution</span>
<span class="badge bg-primary">Reasoning</span>
<span class="badge bg-primary">Code Emulation</span>
<span class="badge bg-primary">Machine Learning</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents "Chain of Code" (CoC), a novel approach that enhances reasoning capabilities in language models (LMs) by integrating code generation and execution, leveraging a code interpreter and a language model emulator (LMulator) for tasks that blend semantic and numeric reasoning. CoC allows LMs to generate code that can be executed or simulated, addressing challenges in executing complex semantic tasks that are difficult to express in code alone. Experimental results show that CoC significantly outperforms existing methods, achieving state-of-the-art results on various benchmarks, particularly in tasks requiring both semantic and algorithmic reasoning. This approach exemplifies how combining the structured power of code with the reasoning abilities of LMs can enhance problem-solving across diverse domains, including robotics.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Challenges in Training PINNs: A Loss Landscape Perspective</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=mJGiFr8jLa&name=pdf" class="link-primary">https://openreview.net/attachment?id=mJGiFr8jLa&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Physics-Informed Neural Networks</span>
<span class="badge bg-primary">Optimization</span>
<span class="badge bg-primary">Loss Landscape</span>
<span class="badge bg-primary">Gradient Descent</span>
<span class="badge bg-primary">Ill-conditioning</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper addresses the challenges in training Physics-Informed Neural Networks (PINNs) by focusing on the loss landscape's ill-conditioning, particularly due to differential operators in the residual term. It compares the performance of various optimizers—Adam, L-BFGS, and a combination of both (Adam+L-BFGS)—and introduces a novel second-order optimizer called NysNewton-CG (NNCG), which significantly enhances PINN performance. The authors theoretically and empirically demonstrate that ill-conditioned differential operators lead to difficulties in minimizing the PINN loss function and show how combining first- and second-order methods can improve convergence. Ultimately, the findings provide insights and strategies that enhance the effectiveness of PINNs in solving complex partial differential equations.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">CompeteAI: Understanding the Competition Dynamics of Large Language Model-based Agents</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=wGtzp4ZT1n&name=pdf" class="link-primary">https://openreview.net/attachment?id=wGtzp4ZT1n&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">competition dynamics</span>
<span class="badge bg-primary">large language models</span>
<span class="badge bg-primary">agent-based modeling</span>
<span class="badge bg-primary">simulation environment</span>
<span class="badge bg-primary">sociological theories</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents CompeteAI, a framework designed to explore the competition dynamics among large language model (LLM)-based agents, addressing a research gap in the study of competitive behavior. The authors implement a virtual environment simulating a town with restaurant and customer agents, where the restaurant agents compete to attract customers through strategic adaptations and innovations. The findings reveal that competition among agents leads to improved product quality, aligns with existing sociological and economic theories, and highlights phenomena such as the Matthew Effect and the dynamics of customer decision-making. The study emphasizes the potential of LLMs to simulate complex social interactions and provides insights for future research in sociology and economics.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Compressible Dynamics in Deep Overparameterized Low-Rank Learning & Adaptation</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=uDkXoZMzBv&name=pdf" class="link-primary">https://openreview.net/attachment?id=uDkXoZMzBv&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">overparameterization</span>
<span class="badge bg-primary">low-rank learning</span>
<span class="badge bg-primary">matrix completion</span>
<span class="badge bg-primary">fine-tuning</span>
<span class="badge bg-primary">compressible dynamics</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper explores the advantages of overparameterization in deep learning, specifically focusing on how to leverage low-rank structures and compressible dynamics to reduce computational costs while maintaining performance. The authors demonstrate that the learning dynamics of model parameters can be restricted to low-dimensional invariant subspaces, allowing for effective compression of weight matrices. They introduce techniques for both deep low-rank matrix completion and a new method for fine-tuning language models called Deep LoRA, which enhances existing low-rank adaptation methods by reducing overfitting and simplifying hyperparameter tuning. The proposed methods show significant improvements in training efficiency and performance, especially in scenarios with limited data, while retaining the benefits of overparameterization.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Contrasting Multiple Representations with the Multi-Marginal Matching Gap</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=dV9B9qFeGi&name=pdf" class="link-primary">https://openreview.net/attachment?id=dV9B9qFeGi&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">multi-marginal optimal transport</span>
<span class="badge bg-primary">representation learning</span>
<span class="badge bg-primary">multi-view learning</span>
<span class="badge bg-primary">self-supervised learning</span>
<span class="badge bg-primary">contrastive loss</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces the Multi-Marginal Matching Gap (M3G) loss, a novel approach for learning representations of complex objects viewed through multiple modalities or perspectives (k≥3). Unlike existing methods that adapt pairwise losses for k views, M3G leverages insights from multi-marginal optimal transport (MM-OT) to optimize the matching of k-tuples of embeddings for a batch of objects. The proposed loss measures the discrepancy between the cost of ground-truth k-tuples and the optimal polystochastic matching cost, allowing for a holistic evaluation of representation coherence across all views. Experimental results on various self-supervised and multimodal tasks demonstrate that M3G outperforms traditional pairwise loss extensions, achieving better performance metrics while providing a scalable solution for k=36 views using the Sinkhorn algorithm.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Data-free Neural Representation Compression with Riemannian Neural Dynamics</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=LTifAl5bKb&name=pdf" class="link-primary">https://openreview.net/attachment?id=LTifAl5bKb&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Riemannian geometry</span>
<span class="badge bg-primary">neural compression</span>
<span class="badge bg-primary">data-free methods</span>
<span class="badge bg-primary">neural dynamics</span>
<span class="badge bg-primary">model inference</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents a novel approach to neural representation compression using Riemannian neural dynamics, introducing a Riemannian metric (RieM) that enhances the modeling of interactions between neurons in a more flexible and efficient manner compared to traditional weight-based linear transformations. The proposed method allows for data-free neural compression, significantly reducing model size and computational complexity without the need for fine-tuning on real data. Extensive experiments on various datasets, including MNIST, CIFAR-100, ImageNet-1k, and COCO, demonstrate that models compressed using RieM achieve superior inference accuracy relative to existing data-free compression techniques. The findings highlight the potential of integrating advanced geometric frameworks with neural architectures to improve representation efficiency and computational performance in machine learning tasks.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Debating with More Persuasive LLMs Leads to More Truthful Answers</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=iLCZtl7FTa&name=pdf" class="link-primary">https://openreview.net/attachment?id=iLCZtl7FTa&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">debate</span>
<span class="badge bg-primary">language models</span>
<span class="badge bg-primary">truthfulness</span>
<span class="badge bg-primary">human judgment</span>
<span class="badge bg-primary">AI alignment</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper investigates the efficacy of using weaker language models (non-experts) to assess the correctness of stronger models (experts) through a debate mechanism. This study finds that the debate format significantly enhances the performance of both human and LLM judges compared to traditional consultancy methods, with non-expert judges achieving 76% accuracy in identifying correct answers after engaging in debates, and human judges reaching 88% accuracy. Furthermore, optimizing expert debaters for persuasiveness leads to improved outcomes in identifying the truth by non-expert judges, suggesting that debate can serve as a scalable oversight mechanism for aligning advanced language models without requiring ground truth labels. The findings underscore the potential of adversarial setups in enhancing AI alignment and truthfulness.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Decomposing Uncertainty for Large Language Models through Input Clarification Ensembling</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=byxXa99PtF&name=pdf" class="link-primary">https://openreview.net/attachment?id=byxXa99PtF&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">uncertainty decomposition</span>
<span class="badge bg-primary">large language models</span>
<span class="badge bg-primary">aleatoric uncertainty</span>
<span class="badge bg-primary">epistemic uncertainty</span>
<span class="badge bg-primary">input clarification ensembling</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces an innovative framework called input clarification ensembling for decomposing uncertainty in large language models (LLMs) into aleatoric (data) and epistemic (model) uncertainty. The proposed method enhances reliability and interpretability by generating clarifications for ambiguous inputs and incorporating them into the prediction process. Empirical evaluations demonstrate that this approach allows for accurate uncertainty quantification across various language processing tasks. By focusing on input clarification rather than altering model parameters, the framework effectively addresses the challenges inherent in uncertainty decomposition for black-box LLMs, ultimately improving user interaction and model trustworthiness.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Differentiable Mapper for Topological Optimization of Data Representation</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=QZ1DVzr6N9&name=pdf" class="link-primary">https://openreview.net/attachment?id=QZ1DVzr6N9&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Topological Data Analysis</span>
<span class="badge bg-primary">Mapper Graphs</span>
<span class="badge bg-primary">Filter Optimization</span>
<span class="badge bg-primary">Unsupervised Learning</span>
<span class="badge bg-primary">Persistent Homology</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents a novel approach called Soft Mapper, which introduces a differentiable and probabilistic version of Mapper graphs used in Topological Data Analysis (TDA) for unsupervised data representation and visualization. The primary contribution is the development of a filter optimization scheme that addresses the critical yet previously neglected filter parameter within Mapper graphs, enhancing their structural accuracy and interpretability. By employing a relaxed Mapper construction and leveraging persistent homology, the authors demonstrate the efficacy of their method on various datasets, including 3D shapes and single-cell RNA sequencing data, showcasing significant improvements in the representation of topological features compared to traditional methods. The findings suggest that Soft Mapper not only facilitates better data representation but also guarantees convergence in filter optimization through defined topological loss functions.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">DiJiang: Efficient Large Language Models through Compact Kernelization</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=0uUHfhXdnH&name=pdf" class="link-primary">https://openreview.net/attachment?id=0uUHfhXdnH&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Transformer models</span>
<span class="badge bg-primary">linear attention</span>
<span class="badge bg-primary">kernelization</span>
<span class="badge bg-primary">computational efficiency</span>
<span class="badge bg-primary">natural language processing</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces DiJiang, a novel approach for enhancing the efficiency of large language models by utilizing Frequency Domain Kernelization, which transforms a pre-trained vanilla Transformer into a model with linear complexity while minimizing retraining requirements. This is achieved through a unique weighted Quasi-Monte Carlo sampling method, combined with Discrete Cosine Transform (DCT) operations, leading to significant reductions in training costs (approximately 1/50 of the original) and increased inference speed (up to 10x faster). Experimental results demonstrate that DiJiang maintains performance comparable to original Transformers across various benchmarks while significantly lowering computational demands, making it a promising solution for scalable and efficient natural language processing tasks.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Discovering Environments with XRM</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=gPStP3FSY9&name=pdf" class="link-primary">https://openreview.net/attachment?id=gPStP3FSY9&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">automatic environment discovery</span>
<span class="badge bg-primary">out-of-distribution generalization</span>
<span class="badge bg-primary">machine learning</span>
<span class="badge bg-primary">hyper-parameter tuning</span>
<span class="badge bg-primary">spurious correlations</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces CROSS-RISK MINIMIZATION (XRM), an innovative algorithm designed for automatic environment discovery, which is pivotal for enhancing out-of-distribution (OOD) generalization in machine learning models. Traditional methods requiring human-annotated environments are costly and often biased, limiting their scalability. XRM circumvents this by training twin networks on random halves of the training data, encouraging them to imitate each other's confident misclassifications. This approach enables the discovery of environments that differ solely in spurious correlations, allowing downstream OOD algorithms to achieve oracle-like performance without needing early-stopping or hyper-parameter tuning based on validation sets. The authors demonstrate XRM’s effectiveness across various benchmarks, showing significant improvements in worst-group accuracy compared to existing methods, thereby addressing longstanding challenges in robust AI performance amid distributional shifts.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Discrete Diffusion Modeling by Estimating the Ratios of the Data Distribution</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=CNicRIVIPA&name=pdf" class="link-primary">https://openreview.net/attachment?id=CNicRIVIPA&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">discrete diffusion models</span>
<span class="badge bg-primary">score entropy</span>
<span class="badge bg-primary">generative modeling</span>
<span class="badge bg-primary">natural language processing</span>
<span class="badge bg-primary">autoregressive models</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents Score Entropy Discrete Diffusion models (SEDD), which extend traditional score matching techniques to discrete data, specifically targeting natural language tasks where conventional diffusion models have struggled. By introducing a novel loss function, "score entropy," the authors show significant improvements over existing language diffusion methods, achieving 25-75% reductions in perplexity compared to prior models and outperforming the autoregressive model GPT-2 in several tasks. SEDD models efficiently generate high-quality text samples without needing complex distribution annealing techniques, allowing for better trade-offs between computational resources and output quality. Overall, this work establishes SEDD as a competitive alternative in the landscape of generative language models.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">DITTO: Diffusion Inference-Time T-Optimization for Music Generation</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=z5Ux2u6t7U&name=pdf" class="link-primary">https://openreview.net/attachment?id=z5Ux2u6t7U&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">music generation</span>
<span class="badge bg-primary">diffusion models</span>
<span class="badge bg-primary">optimization</span>
<span class="badge bg-primary">audio editing</span>
<span class="badge bg-primary">controllability</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces DITTO (Diffusion Inference-Time T-Optimization), a novel framework for controlling pre-trained text-to-music diffusion models during inference by optimizing initial noise latents. Unlike traditional methods that require extensive training or struggle with precision, DITTO utilizes gradient checkpointing for memory efficiency and can handle a variety of tasks such as inpainting, outpainting, looping, and melodic control without fine-tuning the model. The authors demonstrate that DITTO achieves state-of-the-art performance across multiple metrics, including audio quality and computational efficiency, while allowing for flexible, training-free control over music generation, thus enhancing the creative possibilities in audio production.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Does Label Smoothing Help Deep Partial Label Learning?</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=drjjxmi2Ha&name=pdf" class="link-primary">https://openreview.net/attachment?id=drjjxmi2Ha&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">label smoothing</span>
<span class="badge bg-primary">partial label learning</span>
<span class="badge bg-primary">deep learning</span>
<span class="badge bg-primary">noise reduction</span>
<span class="badge bg-primary">classification performance</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper investigates the effectiveness of label smoothing (LS) in improving deep partial label learning (deep PLL) models, which struggle with noisy false-positive labels. The authors provide a theoretical foundation by proving lower and upper bounds on expected risk related to label smoothing, deriving an optimal smoothing rate and defining a generalized ambiguity degree to quantify label noise. Empirically, they introduce a novel algorithm called Label Smoothing-based Partial Label Learning (LS-PLL) and demonstrate its effectiveness through extensive experiments on various datasets and deep architectures, showing that label smoothing significantly enhances classification performance and helps in learning more distinguishable representations, especially when the empirical smoothing rate aligns closely with the theoretically derived optimal rate.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">DoRA: Weight-Decomposed Low-Rank Adaptation</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=3d5CIRG1n2&name=pdf" class="link-primary">https://openreview.net/attachment?id=3d5CIRG1n2&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Low-Rank Adaptation</span>
<span class="badge bg-primary">Fine-Tuning</span>
<span class="badge bg-primary">Parameter Efficiency</span>
<span class="badge bg-primary">Weight Decomposition</span>
<span class="badge bg-primary">Neural Networks</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces Weight-Decomposed Low-Rank Adaptation (DoRA), a novel method that enhances parameter-efficient fine-tuning (PEFT) techniques like LoRA by decomposing pre-trained weights into magnitude and directional components. This approach allows DoRA to mimic the learning capacity of full fine-tuning (FT) while maintaining efficiency and minimizing additional inference costs. The authors conduct a weight decomposition analysis to reveal the distinct learning patterns between FT and LoRA, leading to the conclusion that DoRA consistently outperforms LoRA across various tasks, including commonsense reasoning and visual instruction tuning, without increasing the number of trainable parameters. The experimental results validate the effectiveness of DoRA across multiple large language models and various downstream tasks.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Doubly Robust Causal Effect Estimation under Networked Interference via Targeted Learning</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=5lI9wm4dws&name=pdf" class="link-primary">https://openreview.net/attachment?id=5lI9wm4dws&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Causal Effect Estimation</span>
<span class="badge bg-primary">Networked Interference</span>
<span class="badge bg-primary">Targeted Learning</span>
<span class="badge bg-primary">Doubly Robust Estimator</span>
<span class="badge bg-primary">Neural Networks</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents a novel doubly robust causal effect estimator, termed TNet, designed to address the challenges of estimating causal effects in the presence of networked interference. Traditional parametric methods often fall short due to their restrictive model assumptions, while semiparametric approaches, which typically rely on a single nuisance function, may suffer from bias when model specifications are incorrect. The authors extend the targeted learning framework to establish a doubly robust estimator that retains consistency even if one of the nuisance models is accurate. The paper provides a theoretical foundation for the estimator, demonstrating its superior convergence rate compared to single nuisance function models. Extensive experiments on real-world networks with semisynthetic data validate the effectiveness of TNet, showcasing its robustness and lower estimation bias in causal inference under networked interference scenarios.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Emergent Equivariance in Deep Ensembles</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=plXXbXjvQ9&name=pdf" class="link-primary">https://openreview.net/attachment?id=plXXbXjvQ9&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Deep Ensembles</span>
<span class="badge bg-primary">Equivariance</span>
<span class="badge bg-primary">Neural Tangent Kernel</span>
<span class="badge bg-primary">Data Augmentation</span>
<span class="badge bg-primary">Machine Learning</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents a novel finding that deep ensembles exhibit emergent equivariance across all inputs and training times when trained with full data augmentation. The authors demonstrate that while individual ensemble members lack equivariance, the collective predictions of the ensemble do not show this deficiency, effectively behaving as a fully equivariant network in the infinite width limit. Utilizing neural tangent kernel theory, the authors derive rigorous theoretical insights and validate these findings through extensive numerical experiments across various datasets, including the Ising model and FashionMNIST. They also discuss the implications of finite ensemble sizes and the challenges posed by approximating continuous symmetry groups, ultimately showing that deep ensembles can achieve a high degree of equivariance even with limited members.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Environment Design for Inverse Reinforcement Learning</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=Ar0dsOMStE&name=pdf" class="link-primary">https://openreview.net/attachment?id=Ar0dsOMStE&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Inverse Reinforcement Learning</span>
<span class="badge bg-primary">Environment Design</span>
<span class="badge bg-primary">Sample Efficiency</span>
<span class="badge bg-primary">Robustness</span>
<span class="badge bg-primary">Bayesian Inference</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents a novel framework for Inverse Reinforcement Learning (IRL) that improves sample efficiency and robustness by utilizing adaptive environment design. The authors propose a method where learners can selectively choose environments in which experts demonstrate tasks, thereby accelerating the learning of reward functions from expert behavior. By leveraging a maximin Bayesian regret objective, the proposed approach, called ED-BIRL for Bayesian IRL and ED-AIRL for maximum entropy IRL, demonstrates significant improvements in recovering true reward functions and maintaining performance across varying environment dynamics. Extensive experimental results validate the effectiveness of the proposed methods, showcasing their superior performance compared to traditional fixed environment approaches and domain randomization strategies.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">EquiPocket: an E(3)-Equivariant Geometric Graph Neural Network for Ligand Binding Site Prediction</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=1vGN3CSxVs&name=pdf" class="link-primary">https://openreview.net/attachment?id=1vGN3CSxVs&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">ligand binding</span>
<span class="badge bg-primary">graph neural networks</span>
<span class="badge bg-primary">E(3)-equivariance</span>
<span class="badge bg-primary">drug discovery</span>
<span class="badge bg-primary">protein structure</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces EquiPocket, an E(3)-equivariant geometric graph neural network designed for predicting ligand binding sites on proteins, addressing limitations of existing CNN-based methods. Traditional approaches often represent proteins as 3D voxel images, leading to inefficiencies in handling irregular structures, sensitivity to rotations, and inadequate surface geometry representation. EquiPocket resolves these issues through three integral modules: a local geometric information extractor for surface atoms, a global structure model capturing chemical and spatial properties, and an equivariant message passing mechanism that enhances surface geometry understanding. Additionally, a novel dense attention output layer adapts to variable protein sizes, significantly improving prediction accuracy across diverse datasets. Extensive experiments affirm EquiPocket's superiority over state-of-the-art methods, marking a substantial advancement in the field of drug discovery and ligand binding site prediction.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Evaluation of LLMs on Syntax-Aware Code Fill-in-the-Middle Tasks</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=jKYyFbH8ap&name=pdf" class="link-primary">https://openreview.net/attachment?id=jKYyFbH8ap&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Large Language Models</span>
<span class="badge bg-primary">Code Generation</span>
<span class="badge bg-primary">Syntax-Aware Benchmark</span>
<span class="badge bg-primary">Fill-in-the-Middle</span>
<span class="badge bg-primary">Pretraining Strategies</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents the Syntax-Aware Fill-in-the-Middle (SAFIM) benchmark, a novel framework for evaluating Large Language Models (LLMs) on code completion tasks that prioritize syntax awareness. SAFIM consists of 17,720 examples from multiple programming languages, specifically collected post-April 2022 to prevent data contamination. The benchmark includes various prompt designs and syntax-aware post-processing techniques to ensure fair comparisons among different LLMs. Findings from evaluating 15 LLMs indicate that pretraining methods and data quality significantly influence model performance, often more than model size. SAFIM also reveals that Fill-in-the-Middle (FIM) pretraining enhances performance in both FIM tasks and traditional Left-to-Right (L2R) inference, suggesting a shift towards FIM as a primary training objective in code LLM development. The benchmark and evaluation tools are made publicly available for further research.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Evolution of Heuristics: Towards Efficient Automatic Algorithm Design Using Large Language Model</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=BwAkaxqiLB&name=pdf" class="link-primary">https://openreview.net/attachment?id=BwAkaxqiLB&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Heuristics</span>
<span class="badge bg-primary">Large Language Models</span>
<span class="badge bg-primary">Evolutionary Computation</span>
<span class="badge bg-primary">Algorithm Design</span>
<span class="badge bg-primary">Optimization</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces the "Evolution of Heuristics" (EoH) framework, which combines Large Language Models (LLMs) and Evolutionary Computation (EC) to automate the design of heuristics for complex search and optimization problems. EoH uniquely evolves both the conceptual ideas (thoughts) and their executable code representations using curated prompt strategies. Experimental results across three well-established combinatorial optimization problems—online bin packing, traveling salesman problem, and flow shop scheduling—demonstrate that EoH outperforms traditional handcrafted heuristics and other recent automatic heuristic design methods like FunSearch, while significantly reducing computational resource requirements. The findings suggest EoH offers a promising approach for efficient and adaptive algorithm design without extensive manual intervention.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">ExCP: Extreme LLM Checkpoint Compression via Weight-Momentum Joint Shrinking</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=hlvKd7Vdxm&name=pdf" class="link-primary">https://openreview.net/attachment?id=hlvKd7Vdxm&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">checkpoint compression</span>
<span class="badge bg-primary">large language models</span>
<span class="badge bg-primary">weight-momentum pruning</span>
<span class="badge bg-primary">quantization</span>
<span class="badge bg-primary">performance optimization</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents a novel framework called Extreme Checkpoint Compression (ExCP) aimed at reducing the storage requirements of training checkpoints for large language models (LLMs) while maintaining nearly lossless performance. The authors propose a method that calculates the residuals of adjacent checkpoints to capture essential sparse information, followed by a weight-momentum joint pruning technique that leverages both model and optimizer information. This approach is complemented by non-uniform quantization to further enhance compression. Through extensive evaluations on models ranging from 410M to 7B parameters, the proposed framework achieves significant storage reductions—up to 70 times for the Pythia-410M model—without notable performance degradation across various downstream tasks, thereby addressing the urgent need for efficient storage solutions in LLM training processes.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Expressivity and Generalization: Fragment-Biases for Molecular GNNs</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=rPm5cKb1VB&name=pdf" class="link-primary">https://openreview.net/attachment?id=rPm5cKb1VB&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Graph Neural Networks</span>
<span class="badge bg-primary">Molecular Modeling</span>
<span class="badge bg-primary">Expressive Power</span>
<span class="badge bg-primary">Fragmentation</span>
<span class="badge bg-primary">Generalization</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces the Fragment-WL test, an extension of the Weisfeiler & Leman test, aimed at enhancing the theoretical expressiveness of fragment-biased Graph Neural Networks (GNNs) in molecular property prediction. The authors propose a new GNN architecture, FragNet, which effectively leverages substructure fragmentations with infinite vocabulary to improve expressiveness and generalization capabilities. Empirical results demonstrate that FragNet outperforms existing GNNs and transformer models on various datasets, achieving lower error rates in molecular property predictions and showcasing superior generalization to unseen data. The findings bridge the gap between theoretical expressiveness and practical performance in molecular GNN applications.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Fast Co-Training under Weak Dependence via Stream-Based Active Learning</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=GqWy1wZKeE&name=pdf" class="link-primary">https://openreview.net/attachment?id=GqWy1wZKeE&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">co-training</span>
<span class="badge bg-primary">active learning</span>
<span class="badge bg-primary">machine learning</span>
<span class="badge bg-primary">label complexity</span>
<span class="badge bg-primary">weak dependence</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper investigates the co-training problem in the context of stream-based active learning, focusing on developing efficient co-training algorithms that maintain both label and computational efficiency under the assumption of weak dependence. The authors demonstrate that several natural concept classes can be efficiently learned via co-training, providing a reduction to online classification that results in algorithms with error-independent label complexity. They establish new co-training algorithms for specific classes, such as halfspaces and unions of intervals, achieving significant improvements in label complexity compared to existing methods. The results highlight the potential of combining co-training with online learning techniques to address challenges in semi-supervised learning.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Fast Timing-Conditioned Latent Audio Diffusion</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=jOlO8t1xdx&name=pdf" class="link-primary">https://openreview.net/attachment?id=jOlO8t1xdx&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">audio generation</span>
<span class="badge bg-primary">latent diffusion</span>
<span class="badge bg-primary">text prompts</span>
<span class="badge bg-primary">variable-length audio</span>
<span class="badge bg-primary">music synthesis</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents "Stable Audio," a latent diffusion model designed for the efficient generation of long-form, variable-length stereo audio at 44.1kHz from text prompts and timing embeddings. The model addresses the computational challenges associated with generating high-quality audio by utilizing a fully-convolutional variational autoencoder for latent representation and introducing timing conditioning to allow for precise control over the duration of generated outputs. Stable Audio achieves impressive inference speeds, generating up to 95 seconds of audio in just 8 seconds on an A100 GPU while performing competitively in public benchmarks for audio quality and text alignment. The research also introduces novel metrics for evaluating long-form audio generation, focusing on aspects such as musicality and structure, demonstrating that Stable Audio can produce structured and coherent music and sound effects, setting a new standard in the field of audio synthesis.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">FedMBridge: Bridgeable Multimodal Federated Learning</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=jrHUbftLd6&name=pdf" class="link-primary">https://openreview.net/attachment?id=jrHUbftLd6&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Federated Learning</span>
<span class="badge bg-primary">Multimodal Learning</span>
<span class="badge bg-primary">Architecture Heterogeneity</span>
<span class="badge bg-primary">Knowledge Sharing</span>
<span class="badge bg-primary">Deep Learning</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces FedMBridge, a novel framework for Multimodal Federated Learning (MFL) that addresses the challenges posed by architecture-personalized federated learning (AMFL), where multiple clients with diverse neural architectures and modalities collaborate while maintaining data privacy. Existing MFL approaches often rely on restrictive neural architectures for knowledge sharing, limiting their applicability in real-world scenarios. FedMBridge utilizes a topology-aware hypernetwork to create a bridge that effectively reconciles statistical and architectural heterogeneities among clients, promoting efficient and automated information sharing. Experimental results across four AMFL simulations demonstrate the framework’s superior performance and communication efficiency compared to baseline methods, thus showcasing its potential for enhancing personalized federated learning systems.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Flextron: Many-in-One Flexible Large Language Model</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=9vKRhnflAs&name=pdf" class="link-primary">https://openreview.net/attachment?id=9vKRhnflAs&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">large language models</span>
<span class="badge bg-primary">model optimization</span>
<span class="badge bg-primary">flexible architectures</span>
<span class="badge bg-primary">dynamic inference</span>
<span class="badge bg-primary">machine learning applications</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces FLEXTRON, a novel architecture and post-training optimization framework designed to enhance the deployment of large language models (LLMs) by enabling flexible adaptation to user-defined latency and accuracy requirements during inference without necessitating additional fine-tuning. FLEXTRON employs a nested elastic structure that allows for input-adaptive token routing through sub-networks, improving both performance and efficiency. The framework is validated through experiments on LLMs such as GPT-3 and Llama-2, demonstrating superior performance compared to traditional models and requiring significantly fewer tokens for training. Key contributions include a systematic approach for transforming existing trained LLMs into dynamic elastic networks, effective static and dynamic routing algorithms, and a surrogate model to facilitate router training. Overall, FLEXTRON presents a scalable solution for optimizing LLM deployment in resource-constrained environments.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">From Coarse to Fine: Enable Comprehensive Graph Self-supervised Learning with Multi-granular Semantic Ensemble</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=JnA9IveEwg&name=pdf" class="link-primary">https://openreview.net/attachment?id=JnA9IveEwg&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">graph self-supervised learning</span>
<span class="badge bg-primary">knowledge distillation</span>
<span class="badge bg-primary">multi-granularity</span>
<span class="badge bg-primary">graph neural networks</span>
<span class="badge bg-primary">performance enhancement</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces Multi-granularity Graph Semantic Ensemble via Knowledge Distillation (MGSE), a novel framework designed to enhance self-supervised learning (SSL) for graph neural networks by leveraging multi-granular knowledge representation. Existing SSL methods often fail to simultaneously capture high-level and fine-grained features, leading to limited generalization across tasks. MGSE addresses this by training multiple student models at different granularities, which learn from a single pre-trained teacher model, thereby improving performance on downstream tasks. The authors demonstrate that MGSE can be integrated into various state-of-the-art graph SSL frameworks, yielding performance improvements of up to 9.2% across multiple datasets. The framework’s effectiveness is validated through comprehensive experiments, suggesting that multi-granularity enhances the interpretability and robustness of graph representations in diverse applications, including molecular and protein analysis.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=hYHsrKDiX7&name=pdf" class="link-primary">https://openreview.net/attachment?id=hYHsrKDiX7&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Large Language Models</span>
<span class="badge bg-primary">Memory Efficiency</span>
<span class="badge bg-primary">Gradient Low-Rank Projection</span>
<span class="badge bg-primary">Optimization Techniques</span>
<span class="badge bg-primary">Pre-training</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents GaLore, a novel training strategy aimed at enhancing the memory efficiency of training Large Language Models (LLMs) by utilizing Gradient Low-Rank Projection. Traditional methods like Low-Rank Adaptation (LoRA) often underperform due to limited parameter search space and altered training dynamics. In contrast, GaLore allows for full-parameter learning while significantly reducing memory usage—up to 65.5% for optimizer states and 82.5% for total training memory—making it feasible to pre-train models like LLaMA 7B on consumer-grade GPUs without requiring complex techniques like model parallelism. The approach maintains competitive performance in both pre-training and fine-tuning tasks, demonstrating its versatility and efficiency compared to existing methods.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Genie: Generative Interactive Environments</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=bJbSbJskOS&name=pdf" class="link-primary">https://openreview.net/attachment?id=bJbSbJskOS&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Generative AI</span>
<span class="badge bg-primary">Interactive Environments</span>
<span class="badge bg-primary">World Models</span>
<span class="badge bg-primary">Video Generation</span>
<span class="badge bg-primary">Latent Actions</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces Genie, a novel generative interactive environment capable of creating diverse, action-controllable virtual worlds from unlabelled internet videos, using a model with 11 billion parameters. It combines a spatiotemporal video tokenizer, an autoregressive dynamics model, and a latent action model, trained entirely without ground-truth action labels. Genie allows users to interact with generated environments on a frame-by-frame basis, facilitating the training of generalist agents that can imitate behaviors from unseen videos. The model demonstrates robust performance in video fidelity and controllability, providing a scalable framework for future research in generative AI and agent training.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">GPTSwarm: Language Agents as Optimizable Graphs</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=uTC9AFXIhg&name=pdf" class="link-primary">https://openreview.net/attachment?id=uTC9AFXIhg&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">language agents</span>
<span class="badge bg-primary">optimization</span>
<span class="badge bg-primary">computational graphs</span>
<span class="badge bg-primary">multimodal data</span>
<span class="badge bg-primary">hierarchical intelligence</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents GPTSwarm, a unified framework that models language agents as optimizable computational graphs, enabling improved orchestration and functionality through graph optimization techniques. By representing agents as nodes that process multimodal data and edges that define information flow, the framework allows for both node-level prompt refinement and edge optimization to enhance the efficiency of language model interactions. The authors demonstrate the framework's capability through various experiments, showing significant performance improvements across multiple benchmarks, including MMLU, Mini Crosswords, HumanEval, and GAIA. The results indicate that automatic optimization can lead to better integration and collaboration among language agents, providing a robust foundation for future developments in autonomous problem-solving systems.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">High-Probability Convergence for Composite and Distributed Stochastic Minimization and Variational Inequalities with Heavy-Tailed Noise</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=DBI6AuCD4a&name=pdf" class="link-primary">https://openreview.net/attachment?id=DBI6AuCD4a&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">stochastic optimization</span>
<span class="badge bg-primary">high-probability convergence</span>
<span class="badge bg-primary">heavy-tailed noise</span>
<span class="badge bg-primary">gradient clipping</span>
<span class="badge bg-primary">distributed optimization</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents novel stochastic optimization methods that achieve high-probability convergence for composite and distributed optimization problems subject to heavy-tailed noise. The authors identify limitations in existing approaches, particularly regarding the naive application of gradient clipping, which can hinder convergence. To overcome these issues, they propose methods that involve clipping stochastic gradient differences instead and derive nearly optimal convergence rates for both composite minimization and variational inequalities. The paper highlights the effectiveness of these methods in distributed settings, demonstrating their ability to leverage parallelization while maintaining strong convergence guarantees. The results are supported by theoretical analysis and numerical experiments, showcasing improvements in accuracy and efficiency over traditional methods.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">How do Large Language Models Navigate Conflicts between Honesty and Helpfulness?</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=685vj0lC9z&name=pdf" class="link-primary">https://openreview.net/attachment?id=685vj0lC9z&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Large Language Models</span>
<span class="badge bg-primary">Honesty</span>
<span class="badge bg-primary">Helpfulness</span>
<span class="badge bg-primary">Reinforcement Learning</span>
<span class="badge bg-primary">Communication</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper investigates how large language models (LLMs) balance the trade-off between honesty and helpfulness in conversational contexts, drawing parallels with human communication behaviors. It employs psychological models and experimental paradigms, specifically the signaling bandits approach, to evaluate various LLMs, including GPT-4 Turbo. The findings reveal that reinforcement learning from human feedback (RLHF) enhances both honesty and helpfulness, while chain-of-thought prompting tends to prioritize helpfulness at the expense of honesty. Notably, GPT-4 Turbo exhibits human-like sensitivity to conversational context, demonstrating the ability to adjust its responses based on prompts that emphasize either honesty or helpfulness. The study highlights the complex interplay of these values and suggests potential avenues for steering LLMs toward desired conversational behaviors.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">How Private are DP-SGD Implementations?</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=xWI0MKwJSS&name=pdf" class="link-primary">https://openreview.net/attachment?id=xWI0MKwJSS&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Differential Privacy</span>
<span class="badge bg-primary">DP-SGD</span>
<span class="badge bg-primary">Batch Sampling</span>
<span class="badge bg-primary">Privacy Analysis</span>
<span class="badge bg-primary">Adaptive Batch Linear Queries</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper examines the privacy guarantees of Differentially Private Stochastic Gradient Descent (DP-SGD) implementations, focusing specifically on the differences in privacy analysis between two batch sampling methods: shuffling and Poisson subsampling. The authors highlight a significant discrepancy in privacy outcomes when using these methods, demonstrating that shuffling-based DP-SGD, while popular in practice, may not provide the expected privacy amplification compared to Poisson subsampling, which has a well-defined privacy analysis. The study warns practitioners to exercise caution when reporting privacy parameters for DP-SGD, as the choice of batch sampler can greatly influence the actual privacy loss, revealing that assumptions based on Poisson subsampling can lead to underestimations of privacy costs in shuffling-based implementations. Overall, the findings suggest a need for more accurate privacy accounting methods in the context of DP-SGD to ensure robust privacy protections in machine learning applications.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Hybrid 2 Neural ODE Causal Modeling and an Application to Glycemic Response</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=GHZVjmaGQM&name=pdf" class="link-primary">https://openreview.net/attachment?id=GHZVjmaGQM&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Hybrid Models</span>
<span class="badge bg-primary">Causal Inference</span>
<span class="badge bg-primary">Neural Networks</span>
<span class="badge bg-primary">Type 1 Diabetes</span>
<span class="badge bg-primary">Glycemic Response</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces Hybrid2Neural ODE Causal Modeling (H2NCM), a novel approach that integrates mechanistic ordinary differential equation (ODE) dynamics with neural network components to model complex systems, particularly focusing on glycemic responses in type 1 diabetes (T1D) management. The authors highlight the challenge of maintaining causal validity in flexible hybrid models and propose a hybrid loss function that combines predictive and causal losses, leveraging domain knowledge about treatment effect rankings. Results demonstrate that H2NCM achieves superior predictive accuracy while preserving causal integrity, outperforming both traditional mechanistic models and standard blackbox neural networks in predicting glucose dynamics following exercise in T1D patients.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">I/O Complexity of Attention, or How Optimal is FlashAttention?</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=MdPBVWTfwG&name=pdf" class="link-primary">https://openreview.net/attachment?id=MdPBVWTfwG&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">I/O complexity</span>
<span class="badge bg-primary">FlashAttention</span>
<span class="badge bg-primary">attention mechanism</span>
<span class="badge bg-primary">memory hierarchy</span>
<span class="badge bg-primary">algorithm optimization</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper investigates the I/O complexity of the attention mechanism in Transformer architectures, particularly addressing whether the I/O complexity of FlashAttention is optimal across different cache sizes. The authors establish a lower bound for I/O complexity that matches the upper bound of FlashAttention for any values of cache size (M) and dimensions. They demonstrate that FlashAttention is optimal when M is large relative to the square of the head dimension (d^2) and propose a more efficient algorithm for smaller cache sizes (M < d^2). The paper also introduces a new communication complexity protocol for matrix compression, linking it to I/O complexity, which may have broader implications for future research in this area.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Image Clustering with External Guidance</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=JSYN891WnB&name=pdf" class="link-primary">https://openreview.net/attachment?id=JSYN891WnB&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">image clustering</span>
<span class="badge bg-primary">external knowledge</span>
<span class="badge bg-primary">supervision signals</span>
<span class="badge bg-primary">cross-modal learning</span>
<span class="badge bg-primary">WordNet</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces an innovative approach to image clustering by utilizing external knowledge as a supervisory signal, contrasting the prevalent focus on internal data-driven signals. The proposed method, Text-Aided Clustering (TAC), leverages semantic information from WordNet to enhance image feature discriminability and improve clustering accuracy. TAC retrieves distinguishing nouns for images and implements a cross-modal mutual distillation strategy to optimize the collaboration between text and image modalities. Experimental results demonstrate that TAC achieves state-of-the-art performance across various challenging image clustering benchmarks, outperforming traditional methods and even zero-shot classification models, thereby highlighting the effectiveness of externally guided clustering.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Improving Transformers with Dynamically Composable Multi-Head Attention</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=RbiBKPtuHp&name=pdf" class="link-primary">https://openreview.net/attachment?id=RbiBKPtuHp&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Transformer</span>
<span class="badge bg-primary">Multi-Head Attention</span>
<span class="badge bg-primary">DCMHA</span>
<span class="badge bg-primary">Language Modeling</span>
<span class="badge bg-primary">Dynamic Composition</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces Dynamically Composable Multi-Head Attention (DCMHA), an innovative architecture that enhances the traditional Multi-Head Attention (MHA) mechanism in Transformers. DCMHA addresses key issues in MHA, such as low-rank bottlenecks and head redundancy, by dynamically composing attention heads based on input data. The core of DCMHA is a Compose function that allows for the transformation of attention score and weight matrices in a context-sensitive manner, significantly increasing the model's expressive power. Experimental results demonstrate that models utilizing DCMHA, referred to as DCFormer, outperform traditional Transformers across various architectures and scales in language modeling tasks, achieving performance comparable to larger models with lower computational costs. The findings suggest that DCMHA not only improves efficiency and scalability but also holds promise for applications in vision transformers and other domains.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Inferring the Long-Term Causal Effects of Long-Term Treatments from Short-Term Experiments</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=lQ2o7JteMO&name=pdf" class="link-primary">https://openreview.net/attachment?id=lQ2o7JteMO&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">long-term treatments</span>
<span class="badge bg-primary">causal inference</span>
<span class="badge bg-primary">short-term experiments</span>
<span class="badge bg-primary">reinforcement learning</span>
<span class="badge bg-primary">estimators</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper addresses the challenge of inferring long-term causal effects of continual interventions, termed long-term treatments, using data from short-term experiments. Unlike short-term treatments where effects can be assessed through surrogate methods, long-term treatments require a different approach due to their continuous nature. The authors propose a novel methodology that leverages offline reinforcement learning principles and doubly-robust estimators to estimate long-term effects without relying on surrogacy assumptions or observational datasets. They demonstrate the efficacy of their method through simulations, showing that it accurately estimates long-term average treatment effects (ATEs) across varying treatment durations, outperforming traditional surrogate methods. This work opens avenues for better understanding long-term effects in various fields where long-term data is often unavailable.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">InfoNet: Neural Estimation of Mutual Information without Test-Time Optimization</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=40hCy8n5XH&name=pdf" class="link-primary">https://openreview.net/attachment?id=40hCy8n5XH&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">mutual information</span>
<span class="badge bg-primary">neural networks</span>
<span class="badge bg-primary">real-time estimation</span>
<span class="badge bg-primary">attention mechanism</span>
<span class="badge bg-primary">efficiency</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces InfoNet, a novel neural network architecture designed for efficient estimation of mutual information (MI) between data streams without the need for test-time optimization. Unlike traditional methods, including MINE, which require retraining for different distributions, InfoNet leverages a dual formulation of MI and employs an attention mechanism to directly output estimates based on large-scale simulated training. The authors demonstrate that InfoNet not only achieves superior computational efficiency but also maintains a robust accuracy-performance trade-off across various distribution families. Their extensive evaluations confirm that InfoNet generalizes well to real-world scenarios, making it suitable for applications demanding rapid MI estimation.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Information Complexity of Stochastic Convex Optimization: Applications to Generalization, Memorization, and Tracing</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=CyEJn71Z00&name=pdf" class="link-primary">https://openreview.net/attachment?id=CyEJn71Z00&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Stochastic Convex Optimization</span>
<span class="badge bg-primary">Information Complexity</span>
<span class="badge bg-primary">Generalization</span>
<span class="badge bg-primary">Memorization</span>
<span class="badge bg-primary">Learning Algorithms</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper explores the relationship between memorization and learning within the framework of stochastic convex optimization (SCO). It introduces conditional mutual information (CMI) as a metric to quantify the information a learning algorithm reveals about its training data, establishing a tradeoff between the accuracy of a learning algorithm and its CMI. Key findings include that optimal performance requires a significant amount of CMI, highlighting the essential role of memorization. The study also addresses limitations in existing generalization bounds based on CMI, demonstrating that such bounds can be vacuous for algorithms with optimal sample complexity. Furthermore, it presents adversarial strategies to identify memorized training samples, emphasizing the necessity of memorization in certain learning contexts.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Interpreting and Improving Large Language Models in Arithmetic Calculation</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=CfOtiepP8s&name=pdf" class="link-primary">https://openreview.net/attachment?id=CfOtiepP8s&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">large language models</span>
<span class="badge bg-primary">arithmetic calculations</span>
<span class="badge bg-primary">attention heads</span>
<span class="badge bg-primary">multi-layer perceptrons</span>
<span class="badge bg-primary">fine-tuning</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper investigates the mechanisms by which large language models (LLMs) perform arithmetic calculations, revealing that fewer than 5% of attention heads and associated multi-layer perceptrons (MLPs) significantly influence the models' ability to focus on operands and operators during computations. The authors conducted experiments demonstrating that these key components exhibit transferability across different datasets and tasks. They introduced a method of precise fine-tuning, selectively adjusting only the critical attention heads and MLPs, which substantially improved mathematical performance without negatively impacting non-mathematical tasks. These findings enhance the understanding of LLMs' arithmetic capabilities and propose a targeted approach to enhance their computational skills.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=6XH8R7YrSk&name=pdf" class="link-primary">https://openreview.net/attachment?id=6XH8R7YrSk&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">LLM Alignment</span>
<span class="badge bg-primary">DPO</span>
<span class="badge bg-primary">PPO</span>
<span class="badge bg-primary">Reinforcement Learning</span>
<span class="badge bg-primary">Human Feedback</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper investigates the effectiveness of Direct Preference Optimization (DPO) compared to Proximal Policy Optimization (PPO) for aligning large language models (LLMs) with human preferences through Reinforcement Learning from Human Feedback (RLHF). While DPO has shown strong performance in academic benchmarks, the authors conduct both theoretical and empirical analyses that reveal fundamental limitations in DPO, particularly its susceptibility to out-of-distribution responses and distribution shifts between model outputs and preference data. In contrast, they find that PPO consistently outperforms DPO across various tasks, including challenging code generation competitions, by leveraging factors such as advantage normalization, large batch sizes, and exponential moving averages in model updates. Overall, the findings suggest that PPO is superior for LLM alignment, achieving state-of-the-art results in multiple complex scenarios.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">LCA-on-the-Line: Benchmarking Out of Distribution Generalization with Class Taxonomies</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=HPXRzM9BYZ&name=pdf" class="link-primary">https://openreview.net/attachment?id=HPXRzM9BYZ&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Out-of-Distribution Generalization</span>
<span class="badge bg-primary">Class Taxonomies</span>
<span class="badge bg-primary">Model Evaluation</span>
<span class="badge bg-primary">Lowest Common Ancestor (LCA)</span>
<span class="badge bg-primary">Vision-Language Models</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces the LCA-on-the-Line framework, which uses the Lowest Common Ancestor (LCA) distance to benchmark out-of-distribution (OOD) generalization of models based on in-distribution (ID) performance, without needing OOD data. The study reveals that LCA distance provides a strong linear correlation with OOD accuracy across various models, particularly highlighting that Vision-Language Models (VLMs) can generalize better than Vision Models (VMs) despite lower ID accuracy. Additionally, the authors propose methods for constructing taxonomic hierarchies using K-means clustering and demonstrate how aligning model predictions with class taxonomies can enhance generalization. Overall, the findings advocate for the LCA distance as a robust metric for understanding and improving model generalization under severe distribution shifts.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Learning to Model the World With Language</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=7dP6Yq9Uwv&name=pdf" class="link-primary">https://openreview.net/attachment?id=7dP6Yq9Uwv&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">multimodal learning</span>
<span class="badge bg-primary">future prediction</span>
<span class="badge bg-primary">language understanding</span>
<span class="badge bg-primary">reinforcement learning</span>
<span class="badge bg-primary">robotics</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces Dynalang, an agent designed to enhance interaction with humans by leveraging diverse language inputs to develop a multimodal understanding of its environment. Unlike existing agents that only follow simple commands, Dynalang interprets language that conveys general knowledge and situational context, using it to predict future observations, environmental dynamics, and rewards. This method integrates language understanding with future prediction, enabling the agent to excel in various tasks, from game-playing to navigating complex environments, while outperforming traditional language-conditioned policies. The research highlights Dynalang's ability to learn from diverse language types, generate grounded language, and improve its performance through offline text pretraining, ultimately paving the way for more intuitive human-agent interactions in real-world scenarios.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Learning Useful Representations of Recurrent Neural Network Weight Matrices</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=QBj7Uurdwf&name=pdf" class="link-primary">https://openreview.net/attachment?id=QBj7Uurdwf&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">RNNs</span>
<span class="badge bg-primary">weight representation</span>
<span class="badge bg-primary">functionalist approach</span>
<span class="badge bg-primary">mechanistic approach</span>
<span class="badge bg-primary">self-supervised learning</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper explores methods for learning effective representations of recurrent neural network (RNN) weight matrices to enhance RNN analysis and performance in downstream tasks. It contrasts mechanistic approaches, which directly analyze RNN weights, with functionalist approaches that focus on the overall functionality through probing inputs. The authors introduce several innovative encoder architectures, including interactive and non-interactive probing methods, and develop a theoretical framework demonstrating the efficiency of these approaches. They present two datasets for RNN weight representation learning, validating their methods through empirical comparisons that show interactive probing significantly outperforms other techniques, especially in complex tasks like predicting RNN behavior. The paper establishes a foundation for future research in RNN interpretability and representation learning, emphasizing the importance of diverse datasets and robust encoding architectures.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Less is More: on the Over-Globalizing Problem in Graph Transformers</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=uKmcyyrZae&name=pdf" class="link-primary">https://openreview.net/attachment?id=uKmcyyrZae&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Graph Transformers</span>
<span class="badge bg-primary">Over-globalizing Problem</span>
<span class="badge bg-primary">Attention Mechanism</span>
<span class="badge bg-primary">Collaborative Training</span>
<span class="badge bg-primary">Node Classification</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper investigates the over-globalizing problem in Graph Transformers, revealing that their global attention mechanism tends to excessively focus on distant nodes, which diminishes the effectiveness of information extraction from nearer, more informative nodes. The authors present a novel architecture called Bi-Level Global Graph Transformer with Collaborative Training (CoBFormer), which utilizes intra-cluster and inter-cluster Transformers to balance local and global information while addressing the over-globalizing issue. Collaborative training is introduced to enhance model generalization. Extensive experiments across various datasets demonstrate that CoBFormer outperforms existing state-of-the-art models in node classification tasks, validating the proposed improvements in attention strategies and training methodologies.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Listenable Maps for Audio Classifiers</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=kAfYYg6PX8&name=pdf" class="link-primary">https://openreview.net/attachment?id=kAfYYg6PX8&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">audio classification</span>
<span class="badge bg-primary">interpretability</span>
<span class="badge bg-primary">machine learning</span>
<span class="badge bg-primary">deep learning</span>
<span class="badge bg-primary">explainable AI</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents Listenable Maps for Audio Classifiers (L-MAC), a novel post-hoc interpretability method designed to enhance the understanding of audio classifiers by generating "listenable" interpretations of model predictions. L-MAC utilizes a decoder built on top of a pretrained classifier to create binary masks that identify relevant audio segments, which are then transformed back into a listenable waveform. The method focuses on maximizing the classifier's confidence for masked audio segments while minimizing it for unmasked portions. Experimental results demonstrate that L-MAC provides more faithful interpretations compared to existing gradient and masking-based methods, with user studies indicating a preference for its outputs. Overall, L-MAC significantly improves the interpretability of audio classifiers, bridging the gap between complex model decisions and human understanding.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Locality-Sensitive Hashing-Based Efficient Point Transformer with Applications in High-Energy Physics</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=vJx6fld6l0&name=pdf" class="link-primary">https://openreview.net/attachment?id=vJx6fld6l0&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Locality-Sensitive Hashing</span>
<span class="badge bg-primary">Efficient Transformers</span>
<span class="badge bg-primary">Point Cloud Processing</span>
<span class="badge bg-primary">High-Energy Physics</span>
<span class="badge bg-primary">Machine Learning</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents the Locality-Sensitive Hashing-Based Efficient Point Transformer (HEPT), a novel transformer architecture designed for efficient processing of large-scale point cloud data in scientific fields such as high-energy physics (HEP) and astrophysics. HEPT addresses the limitations of traditional graph neural networks and standard transformers by integrating local inductive bias, achieving near-linear complexity through hardware-friendly operations. The paper provides a quantitative analysis of the error-complexity tradeoff for various sparsification techniques, demonstrating the superiority of locality-sensitive hashing (LSH), particularly the combination of OR and AND constructions, for kernel approximation in point cloud applications. Empirical evaluations on critical HEP tasks, including charged particle tracking and pileup mitigation, indicate that HEPT significantly outperforms existing models in both accuracy and computational efficiency, marking a notable advancement in geometric deep learning and scientific data processing.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">LoRA Training in the NTK Regime has No Spurious Local Minima</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=s1sdx6vNsU&name=pdf" class="link-primary">https://openreview.net/attachment?id=s1sdx6vNsU&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">LoRA</span>
<span class="badge bg-primary">NTK regime</span>
<span class="badge bg-primary">local minima</span>
<span class="badge bg-primary">fine-tuning</span>
<span class="badge bg-primary">generalization</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents a theoretical analysis of Low-Rank Adaptation (LoRA) in the Neural Tangent Kernel (NTK) regime, demonstrating that LoRA can effectively eliminate spurious local minima during the fine-tuning of large language models (LLMs). The authors show that full fine-tuning admits low-rank solutions, and with LoRA's rank sufficiently high, gradient descent can reliably converge to these low-rank solutions, which also generalize well to unseen data. The findings contribute to the understanding of LoRA's mechanisms in optimization and generalization, emphasizing the absence of spurious local minima in this context and providing a foundation for future research in parameter-efficient fine-tuning methods.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Low-Cost High-Power Membership Inference Attacks</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=sT7UJh5CTc&name=pdf" class="link-primary">https://openreview.net/attachment?id=sT7UJh5CTc&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Membership Inference Attacks</span>
<span class="badge bg-primary">Data Privacy</span>
<span class="badge bg-primary">Statistical Testing</span>
<span class="badge bg-primary">Machine Learning</span>
<span class="badge bg-primary">Model Evaluation</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces a novel statistical method for conducting robust membership inference attacks (RMIA) that significantly enhances the ability to determine if a specific data point was included in the training set of a machine learning model, while maintaining low computational overhead. By refining the null hypothesis modeling through likelihood ratio tests and using limited pre-trained reference models, RMIA achieves superior true positive rates (TPR) across various false positive rates (FPR), even outperforming existing methods by a substantial margin, particularly in low-resource scenarios. This method not only improves the accuracy of privacy risk assessments in machine learning but also lays the groundwork for practical applications in data privacy auditing, addressing the limitations of prior approaches that often falter under computational constraints or require extensive reference model training.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">LSEnet: Lorentz Structural Entropy Neural Network for Deep Graph Clustering</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=L6SRXG92s6&name=pdf" class="link-primary">https://openreview.net/attachment?id=L6SRXG92s6&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Graph Clustering</span>
<span class="badge bg-primary">Structural Information</span>
<span class="badge bg-primary">Deep Learning</span>
<span class="badge bg-primary">Hyperbolic Geometry</span>
<span class="badge bg-primary">Neural Networks</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces LSEnet, a novel approach for deep graph clustering that addresses the challenge of clustering with an unknown number of clusters using a differentiable structural information (DSI) framework grounded in graph information theory. By minimizing DSI, LSEnet constructs an optimal partitioning tree that effectively groups densely connected nodes without requiring predefined cluster numbers. The proposed method leverages the Lorentz model of hyperbolic space to integrate node features, employing manifold-valued graph convolutional networks for enhanced clustering performance. Extensive empirical evaluations demonstrate the superiority of LSEnet over existing methods across various real-world datasets, showcasing its ability to reveal cluster structures effectively.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">MagicLens: Self-Supervised Image Retrieval with Open-Ended Instructions</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=Zc22RDtsvP&name=pdf" class="link-primary">https://openreview.net/attachment?id=Zc22RDtsvP&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">image retrieval</span>
<span class="badge bg-primary">self-supervised learning</span>
<span class="badge bg-primary">multimodal models</span>
<span class="badge bg-primary">text instructions</span>
<span class="badge bg-primary">semantic relations</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces MagicLens, a self-supervised image retrieval model designed to interpret open-ended text instructions for effective image retrieval beyond mere visual similarity. By leveraging a dataset of 36.7 million triplets of query images, instructions, and target images sourced from the web, MagicLens captures diverse semantic relations. It employs a dual-encoder architecture, demonstrating significantly improved retrieval performance on various benchmarks compared to previous state-of-the-art methods while maintaining a smaller model size. Human evaluations further validate its efficacy in satisfying complex retrieval intents, showcasing its potential for diverse real-world applications in image search.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Making Old Things New: A Unified Algorithm for Differentially Private Clustering</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=3ajK5xplDL&name=pdf" class="link-primary">https://openreview.net/attachment?id=3ajK5xplDL&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Differential privacy</span>
<span class="badge bg-primary">clustering algorithms</span>
<span class="badge bg-primary">continual observation</span>
<span class="badge bg-primary">k-means</span>
<span class="badge bg-primary">algorithm unification</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents a unified algorithm for differentially private clustering that adapts a 20-year-old greedy algorithm to work across various privacy models, including centralized, local, shuffle, and the continual observation model. The authors demonstrate that this adapted algorithm can achieve near-optimal performance in terms of accuracy while maintaining privacy guarantees. By integrating key properties of the private k-means problem, they show that this algorithm not only reproduces existing results but also improves on them for several privacy settings. Notably, the paper highlights the first successful application of differentially private clustering in the continual observation scenario, addressing the challenges posed by dynamically changing datasets. The study contributes a clearer framework for future research into private clustering algorithms across various data privacy models.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Mean-field Chaos Diffusion Models</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=lgcFX4VFrM&name=pdf" class="link-primary">https://openreview.net/attachment?id=lgcFX4VFrM&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Generative Models</span>
<span class="badge bg-primary">Score-based Models</span>
<span class="badge bg-primary">Mean-field Theory</span>
<span class="badge bg-primary">High-cardinality Data</span>
<span class="badge bg-primary">Chaos Propagation</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces Mean-field Chaos Diffusion Models (MF-CDMs), a novel class of score-based generative models designed to effectively handle high-cardinality data distributions by employing concepts from mean-field theory. MF-CDMs mitigate the curse of dimensionality by treating high-cardinality data as a large stochastic system of interacting particles, utilizing the propagation of chaos property to enhance scalability and effectiveness, particularly for complex structures like 3D point clouds. The authors develop a mean-field score matching method, establish a variational framework for chaotic particle systems, and introduce an approximation scheme that enhances computational efficiency. Theoretical and empirical results demonstrate MF-CDMs' robustness in managing large data structures, outperforming existing models in challenging scenarios characterized by high dimensionality and cardinality.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">MLLM-as-a-Judge: Assessing Multimodal LLM-as-a-Judge with Vision-Language Benchmark</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=dbFEFHAD79&name=pdf" class="link-primary">https://openreview.net/attachment?id=dbFEFHAD79&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Multimodal Models</span>
<span class="badge bg-primary">Evaluation Benchmark</span>
<span class="badge bg-primary">Human Alignment</span>
<span class="badge bg-primary">Judgment Bias</span>
<span class="badge bg-primary">Performance Analysis</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces the MLLM-as-a-Judge benchmark to evaluate the judging capabilities of Multimodal Large Language Models (MLLMs) across three tasks: Scoring Evaluation, Pair Comparison, and Batch Ranking. The study reveals that while MLLMs like GPT-4V demonstrate strong performance in Pair Comparison tasks, they struggle significantly in Scoring Evaluation and Batch Ranking, exhibiting notable biases and hallucinations. The findings underscore the challenges of aligning MLLM outputs with human preferences and highlight the need for further research to enhance their reliability as evaluators. The authors provide curated datasets for future studies and advocate for continued development in this area.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Monitoring AI-Modified Content at Scale: A Case Study on the Impact of ChatGPT on AI Conference Peer Reviews</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=bX3J7ho18S&name=pdf" class="link-primary">https://openreview.net/attachment?id=bX3J7ho18S&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">AI-generated content</span>
<span class="badge bg-primary">Peer review</span>
<span class="badge bg-primary">Natural language processing</span>
<span class="badge bg-primary">Scientific publishing</span>
<span class="badge bg-primary">Machine learning conferences</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces a novel method to estimate the proportion of text in large corpora that has been significantly modified or generated by large language models (LLMs), utilizing a maximum likelihood framework that incorporates both expert-written and AI-generated reference texts. The authors apply this method to peer reviews from major AI conferences (ICLR, NeurIPS, CoRL, EMNLP) post-ChatGPT release, revealing that between 6.5% and 16.9% of the reviews may have been altered by LLMs beyond minor edits. The study identifies factors influencing LLM usage, such as low reviewer confidence, last-minute submissions, and the presence of scholarly citations. The implications of AI text generation on peer review processes and the potential for homogenization in feedback due to LLM influence are discussed, emphasizing the need for interdisciplinary research to understand the evolving role of AI in academic communication.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">MorphGrower: A Synchronized Layer-by-layer Growing Approach for Plausible Neuronal Morphology Generation</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=ZTN866OsGx&name=pdf" class="link-primary">https://openreview.net/attachment?id=ZTN866OsGx&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">neuronal morphology</span>
<span class="badge bg-primary">computational neuroscience</span>
<span class="badge bg-primary">MorphGrower</span>
<span class="badge bg-primary">machine learning</span>
<span class="badge bg-primary">morphology generation</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces MorphGrower, a novel method for generating plausible neuronal morphologies by mimicking the natural growth process of neurons. Unlike traditional methods that rely on expert rules and are limited by their generalizability, MorphGrower employs a synchronized layer-by-layer generation strategy, conditioning each layer's growth on the previously generated structure to ensure topological validity. The method overcomes limitations of previous learning-based approaches, such as MorphV AE, which produced unrealistic and topologically invalid structures. Experimental results demonstrate that MorphGrower significantly outperforms MorphV AE across multiple real-world datasets, both in morphological realism and electrophysiological response simulations, thereby providing a valuable tool for advancing research in neuroscience and understanding neural connectivity.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Multiplicative Weights Update, Area Convexity and Random Coordinate Descent for Densest Subgraph Problems</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=d2E2i5rJ4x&name=pdf" class="link-primary">https://openreview.net/attachment?id=d2E2i5rJ4x&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">densest subgraph</span>
<span class="badge bg-primary">multiplicative weights update</span>
<span class="badge bg-primary">area convexity</span>
<span class="badge bg-primary">coordinate descent</span>
<span class="badge bg-primary">algorithm efficiency</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper investigates the densest subgraph problem by presenting novel algorithms that utilize multiplicative weights update (MWU) and area convexity techniques, achieving convergence in O(log m²) and O(log m) iterations, respectively, with nearly-linear time per iteration. The MWU algorithm simplifies the extraction of dense subgraphs from fractional solutions without requiring binary search, while the area convexity approach improves upon existing methods by reducing iteration complexity significantly. Additionally, the paper introduces a practical iterative algorithm for dense subgraph decomposition using accelerated random coordinate descent, which exhibits linear convergence and outperforms previous algorithms in both theoretical efficiency and empirical scalability, demonstrating competitiveness with established methods in handling large graphs.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=dVhrnjZJad&name=pdf" class="link-primary">https://openreview.net/attachment?id=dVhrnjZJad&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Text-to-Speech</span>
<span class="badge bg-primary">Speech Synthesis</span>
<span class="badge bg-primary">Factorized Diffusion Models</span>
<span class="badge bg-primary">Zero-Shot Learning</span>
<span class="badge bg-primary">Neural Codec</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents NaturalSpeech 3, an advanced text-to-speech (TTS) system that utilizes factorized diffusion models and a novel neural codec to enhance speech synthesis quality, similarity, and prosody in a zero-shot context. By decomposing speech attributes into distinct subspaces—such as content, prosody, timbre, and acoustic details—NaturalSpeech 3 efficiently generates high-quality speech while allowing for greater control over these attributes through targeted prompts. Experimental results demonstrate that this approach outperforms state-of-the-art TTS systems in various metrics, achieving notable improvements in speech quality, similarity, intelligibility, and prosody on benchmark datasets. The findings indicate the potential of factorization in simplifying complex speech generation tasks, paving the way for future advancements in TTS technology.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Neural Collapse meets Differential Privacy: Curious behaviors of NoisyGD with Near-Perfect Representation Learning</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=7rrN6E4KU0&name=pdf" class="link-primary">https://openreview.net/attachment?id=7rrN6E4KU0&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Neural Collapse</span>
<span class="badge bg-primary">Differential Privacy</span>
<span class="badge bg-primary">Representation Learning</span>
<span class="badge bg-primary">Noisy Gradient Descent</span>
<span class="badge bg-primary">Feature Shift Parameter</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper investigates the intersection of Neural Collapse (NC) theory and differential privacy (DP) in the context of fine-tuning pre-trained models. It establishes that under NC, the misclassification error can be dimension-independent when the distance between actual and ideal last-layer features remains below a certain threshold. The study reveals that while pre-trained models enhance feature representation quality, DP fine-tuning is less robust to perturbations compared to non-DP methods. The authors propose strategies like feature normalization and PCA for improving the robustness of noisy gradient descent (NoisyGD) against various perturbations, showing that PCA effectively mitigates the impact of high dimensionality on testing accuracy. Overall, the findings contribute to the understanding of private learning mechanisms and provide practical approaches for enhancing robustness in private fine-tuning scenarios.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">NExT-GPT: Any-to-Any Multimodal LLM</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=NZQkumsNlf&name=pdf" class="link-primary">https://openreview.net/attachment?id=NZQkumsNlf&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">multimodal</span>
<span class="badge bg-primary">large language models</span>
<span class="badge bg-primary">AI</span>
<span class="badge bg-primary">content generation</span>
<span class="badge bg-primary">semantic understanding</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces NExT-GPT, an end-to-end general-purpose any-to-any multimodal large language model (MM-LLM) that can process and generate content across various modalities, including text, images, audio, and video. Unlike existing models that primarily focus on understanding multimodal inputs, NExT-GPT is designed to seamlessly accept inputs in any modality and produce outputs in any combination, thus bridging a critical gap in current AI capabilities. The authors leverage pre-trained high-performance encoders and diffusion models, requiring only a minimal fine-tuning of parameters (1%) for training, which enhances efficiency and facilitates potential future expansions. They also introduce a novel modality-switching instruction tuning (MosIT) technique and a curated dataset to improve cross-modal understanding and generation. The results demonstrate NExT-GPT's superior performance in generating high-quality multimodal content and complex reasoning tasks, suggesting its potential for advancing human-like AI interactions.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Offline Actor-Critic Reinforcement Learning Scales to Large Models</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=tl2qmO5kpD&name=pdf" class="link-primary">https://openreview.net/attachment?id=tl2qmO5kpD&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">offline reinforcement learning</span>
<span class="badge bg-primary">actor-critic methods</span>
<span class="badge bg-primary">scaling laws</span>
<span class="badge bg-primary">robotics</span>
<span class="badge bg-primary">transformer models</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper explores the scalability of offline actor-critic reinforcement learning (RL) methods, particularly focusing on the Perceiver-based Actor-Critic (PAC) model, which can efficiently handle large models and datasets, including those with sub-optimal data. The authors demonstrate that PAC outperforms strong behavioral cloning baselines across 132 continuous control tasks, including real-world robotics applications, by optimizing a KL-regularized RL objective that allows for a smooth transition from behavioral cloning to RL. Through extensive experiments, the study establishes that offline RL adheres to similar scaling laws as those observed in supervised learning, enabling significant performance improvements as model size and data volume increase. The findings indicate the potential of offline actor-critic methods as a promising alternative for training large models in complex multi-task environments.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">OMPO: A Unified Framework for RL under Policy and Dynamics Shifts</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=R83VIZtHXA&name=pdf" class="link-primary">https://openreview.net/attachment?id=R83VIZtHXA&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">reinforcement learning</span>
<span class="badge bg-primary">policy shifts</span>
<span class="badge bg-primary">dynamics shifts</span>
<span class="badge bg-primary">occupancy matching</span>
<span class="badge bg-primary">robotics applications</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces a novel approach called Occupancy-Matching Policy Optimization (OMPO) for enhancing reinforcement learning (RL) performance in environments that experience policy and dynamics shifts. OMPO addresses the challenge of distribution discrepancies in online RL by utilizing a unified strategy known as transition occupancy matching, allowing the method to effectively learn from data collected under various policies and changing dynamics. The authors propose a surrogate policy learning objective, which they reformulate into a tractable min-max optimization problem. Extensive experiments in diverse environments, including OpenAI Gym and robotics tasks, demonstrate that OMPO outperforms existing specialized algorithms in terms of performance and stability, particularly excelling in scenarios involving domain randomization and sim-to-real applications. The findings highlight OMPO's potential for practical RL applications, particularly in robotics, while still indicating areas for further exploration, such as optimizing local buffer sizes and addressing reward definitions.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">On the Last-Iterate Convergence of Shuffling Gradient Methods</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=Xdy9bjwHDu&name=pdf" class="link-primary">https://openreview.net/attachment?id=Xdy9bjwHDu&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">shuffling gradient methods</span>
<span class="badge bg-primary">last-iterate convergence</span>
<span class="badge bg-primary">convex optimization</span>
<span class="badge bg-primary">stochastic gradient descent</span>
<span class="badge bg-primary">theoretical analysis</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper investigates the last-iterate convergence rates of shuffling gradient methods—specifically Random Reshuffle (RR), Shuffle Once (SO), and Incremental Gradient (IG)—in the context of convex optimization, addressing a significant gap between empirical performance and theoretical understanding. The authors establish the first theoretical guarantees for last-iterate convergence based on the objective function value, without requiring strong convexity assumptions. Their results demonstrate that the last iterate of these methods achieves convergence rates that either match existing lower bounds or are comparable to the best upper bounds previously known for average iterates. The findings enhance the theoretical framework surrounding shuffling gradient methods and highlight their practical applicability in various optimization settings, including constrained problems.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Online Matching with Stochastic Rewards: Provable Better Bound via Adversarial Reinforcement Learning</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=TujtZgdRxB&name=pdf" class="link-primary">https://openreview.net/attachment?id=TujtZgdRxB&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">online bipartite matching</span>
<span class="badge bg-primary">adversarial reinforcement learning</span>
<span class="badge bg-primary">stochastic rewards</span>
<span class="badge bg-primary">competitive ratio</span>
<span class="badge bg-primary">algorithm robustness</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper investigates the online matching with stochastic rewards (OMSR) problem, a variant of online bipartite matching (OBM) where the optimal competitive ratio remains unknown. By employing an adversarial reinforcement learning (RL) framework, the authors train two agents: one to generate hard instances that challenge the matching algorithm and another to improve the algorithm's performance against these instances. This iterative approach leads to a robust algorithm that not only empirically outperforms existing solutions but also theoretically improves the upper bound on the competitive ratio of OMSR from 0.621 to 0.597. Notably, the study demonstrates that RL can enhance the theoretical understanding of online optimization problems, marking a significant contribution to the field.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Optimal Hessian/Jacobian-Free Nonconvex-PL Bilevel Optimization</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=eZiQWM5U0E&name=pdf" class="link-primary">https://openreview.net/attachment?id=eZiQWM5U0E&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">bilevel optimization</span>
<span class="badge bg-primary">nonconvex problems</span>
<span class="badge bg-primary">machine learning</span>
<span class="badge bg-primary">convergence analysis</span>
<span class="badge bg-primary">Hessian-free methods</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents a novel algorithm, HJFBiO, designed for solving nonconvex bilevel optimization problems that satisfy the Polyak-Łojasiewicz (PL) condition. Unlike existing methods that often depend on the computation of Hessian or Jacobian matrices, which can be computationally expensive, HJFBiO operates without these matrices by utilizing a finite-difference estimator and a new projection operator. The authors demonstrate that their method achieves an optimal convergence rate of \(O(1/T)\) for finding \(\epsilon\)-stationary solutions, with a gradient complexity of \(O(1)\), thus improving efficiency in various applications like hyperparameter learning and meta-learning. Empirical results validate the algorithm's effectiveness compared to other existing methods.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Parameterized Physics-informed Neural Networks for Parameterized PDEs</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=n3yYrtt9U7&name=pdf" class="link-primary">https://openreview.net/attachment?id=n3yYrtt9U7&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Physics-informed neural networks</span>
<span class="badge bg-primary">Parameterized PDEs</span>
<span class="badge bg-primary">Machine learning</span>
<span class="badge bg-primary">Computational efficiency</span>
<span class="badge bg-primary">Deep learning</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces Parameterized Physics-informed Neural Networks (P2INNs), a novel extension of traditional physics-informed neural networks (PINNs) designed to address the challenges of solving parameterized partial differential equations (PDEs). P2INNs improve the modeling of complex physical systems by explicitly encoding a latent representation of PDE parameters, which allows for efficient multi-query evaluations without needing repetitive training. Extensive empirical evaluations demonstrate that P2INNs significantly outperform existing baseline models in terms of accuracy and parameter efficiency across various benchmark PDEs, including convection, diffusion, and reaction equations. The results illustrate P2INNs' robustness in overcoming known failure modes of PINNs, showcasing their potential for effective applications in scientific machine learning.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Pausing Policy Learning in Non-stationary Reinforcement Learning</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=qY622O6Ehg&name=pdf" class="link-primary">https://openreview.net/attachment?id=qY622O6Ehg&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Reinforcement Learning</span>
<span class="badge bg-primary">Policy Learning</span>
<span class="badge bg-primary">Non-stationary Environments</span>
<span class="badge bg-primary">Dynamic Regret</span>
<span class="badge bg-primary">Aleatoric Uncertainty</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper investigates the challenges of real-time inference in non-stationary reinforcement learning (RL) environments, proposing a novel approach that emphasizes the strategic pausing of policy updates instead of continuous updates. The authors argue that pausing can enhance overall performance by better managing aleatoric uncertainty, leading to an optimal ratio between policy update and hold durations that minimizes dynamic regret. Analytical solutions and empirical results demonstrate that maintaining a non-zero hold duration yields superior rewards compared to constant updates across various tested environments. The findings bridge theoretical insights with practical implications for real-world applications of RL, suggesting that careful temporal management of policy updates can significantly improve decision-making in dynamic settings.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Position: A Safe Harbor for AI Evaluation and Red Teaming</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=dLojMSgSFW&name=pdf" class="link-primary">https://openreview.net/attachment?id=dLojMSgSFW&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">AI safety</span>
<span class="badge bg-primary">evaluation</span>
<span class="badge bg-primary">red teaming</span>
<span class="badge bg-primary">legal protection</span>
<span class="badge bg-primary">independent research</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper highlights the critical need for independent evaluation and red teaming of generative AI systems to identify risks but argues that current terms of service from major AI companies create disincentives for researchers, leading to a chilling effect on good faith safety evaluations. It proposes that these companies establish legal and technical safe harbors to protect researchers conducting public interest evaluations, ensuring they are shielded from account suspensions and legal repercussions. The authors recommend that firms provide clear guidelines, transparent access processes, and independent review of research proposals to enhance community participation and improve safety research, ultimately fostering more accountability and trust in generative AI technologies.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Position: AI-Powered Autonomous Weapons Risk Geopolitical Instability and Threaten AI Research</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=ZwUThOE7Zc&name=pdf" class="link-primary">https://openreview.net/attachment?id=ZwUThOE7Zc&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Autonomous Weapons</span>
<span class="badge bg-primary">Geopolitical Stability</span>
<span class="badge bg-primary">AI Research</span>
<span class="badge bg-primary">Military Ethics</span>
<span class="badge bg-primary">Arms Race</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper discusses the risks posed by the increasing development and deployment of AI-powered Autonomous Weapons Systems (AWS), arguing that they could significantly destabilize global politics and threaten the integrity of AI research. Unlike concerns regarding superintelligent AGI, the authors emphasize that AWS are a more immediate threat, already being integrated into military operations worldwide. The substitution of human soldiers with AWS lowers the political costs of warfare, potentially leading to more frequent conflicts and an arms race among nations. The authors advocate for regulatory measures that ensure transparency and human oversight in AWS deployment to mitigate these risks and maintain ethical standards in military AI applications. They call on AI researchers and policymakers to collaborate in shaping responsible development practices for AWS to avoid adverse effects on global stability and academic freedom in AI.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Position: Automatic Environment Shaping is the Next Frontier in RL</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=dslUyy1rN4&name=pdf" class="link-primary">https://openreview.net/attachment?id=dslUyy1rN4&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Reinforcement Learning</span>
<span class="badge bg-primary">Environment Shaping</span>
<span class="badge bg-primary">Robotics</span>
<span class="badge bg-primary">Data Collection</span>
<span class="badge bg-primary">Policy Optimization</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">In this position paper, Park et al. argue that the key bottleneck in scaling reinforcement learning (RL) for robotics is the manual effort required for environment shaping, which includes designing observations, actions, rewards, and simulation dynamics. They emphasize the need to automate this shaping process to facilitate the collection of diverse robotic data, thereby enabling robots to learn tasks independently with minimal human input. The authors critique existing benchmarks for RL that incorporate task-specific modifications, suggesting that future research should focus on unshaped environments to accurately measure RL algorithms' capabilities. They propose a framework for understanding environment shaping as an optimization problem and advocate for advancements in computational efficiency and better understanding of human design choices to enhance the automation of this critical process.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Position: Beyond Personhood: Agency, Accountability, and the Limits of Anthropomorphic Ethical Analysis</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=4XlGXIh2BB&name=pdf" class="link-primary">https://openreview.net/attachment?id=4XlGXIh2BB&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">agency</span>
<span class="badge bg-primary">accountability</span>
<span class="badge bg-primary">ethical AI</span>
<span class="badge bg-primary">mechanistic agency</span>
<span class="badge bg-primary">volitional agency</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper examines the concept of agency in the context of AI, contrasting two primary views: mechanistic and volitional agency. The mechanistic view, prevalent in AI research, treats AI systems as simulators of ethical human behavior but is criticized for its limitations in establishing true moral agency and accountability. In contrast, the volitional view argues that AI lacks intrinsic desires and motivations, thus disqualifying it from being considered an ethical agent. The authors propose that instead of viewing AI as an agent, we should understand it as a product of political processes, emphasizing the need for accountability in terms of the political legitimacy surrounding AI development. Finally, the paper advocates for alternative frameworks that focus on application specificity and the ethical agency of human contributors to AI systems, rather than attributing agency to the AI itself.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Position: Considerations for Differentially Private Learning with Large-Scale Public Pretraining</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=ncjhi4qAPV&name=pdf" class="link-primary">https://openreview.net/attachment?id=ncjhi4qAPV&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">differential privacy</span>
<span class="badge bg-primary">transfer learning</span>
<span class="badge bg-primary">machine learning</span>
<span class="badge bg-primary">public datasets</span>
<span class="badge bg-primary">privacy concerns</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This position paper critiques the emerging paradigm of leveraging large-scale public pretraining to enhance differentially private learning, questioning the assumption that data scraped from the web is non-sensitive and thus suitable for training models intended to protect privacy. The authors argue that using publicly available datasets can still pose privacy risks, as these datasets may contain sensitive information and models may inadvertently memorize this data during pretraining. They also highlight the inadequacy of current benchmarks in assessing the utility of such models for privacy-sensitive tasks, suggesting that many benchmarks conflate public and private data distributions. Furthermore, the reliance on large models trained on public data often necessitates outsourcing sensitive data to third-party services, compromising user privacy. The paper calls for clearer privacy considerations, better benchmarks, and a holistic view of privacy in machine learning to ensure that differentially private learning methods remain effective and trustworthy in real-world applications.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Position: Do pretrained Transformers Learn In-Context by Gradient Descent?</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=WsawczEqO6&name=pdf" class="link-primary">https://openreview.net/attachment?id=WsawczEqO6&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">In-Context Learning</span>
<span class="badge bg-primary">Gradient Descent</span>
<span class="badge bg-primary">Transformers</span>
<span class="badge bg-primary">Natural Language Processing</span>
<span class="badge bg-primary">Empirical Analysis</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper investigates the relationship between In-Context Learning (ICL) and Gradient Descent (GD) in pre-trained Transformers, questioning the validity of claims that equate the two processes. The authors highlight limitations in existing studies that utilize theoretical frameworks and simplified experimental setups, arguing that these do not accurately reflect the behavior of real-world language models. Through comprehensive empirical analysis using the LLaMa-7B model, the authors demonstrate significant differences in performance and sensitivity to the order of demonstrations between ICL and GD, suggesting that the equivalence between the two remains unproven and necessitates further investigation into the true nature of ICL in practical applications.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Position: Embracing Negative Results in Machine Learning</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=3RXAiU7sss&name=pdf" class="link-primary">https://openreview.net/attachment?id=3RXAiU7sss&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">negative results</span>
<span class="badge bg-primary">machine learning</span>
<span class="badge bg-primary">publication bias</span>
<span class="badge bg-primary">empirical research</span>
<span class="badge bg-primary">research incentives</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper advocates for the normalization of publishing negative results in machine learning research, arguing that an overemphasis on predictive performance hinders scientific progress and creates inefficiencies within the community. It distinguishes between two types of negative results—Novel Method Negative Results (NMNR) and Existing Method Negative Results (EMNR)—and highlights how neglecting negative outcomes can lead to publication bias and a disconnect between research and practical applications. By promoting the publication of negative results, the authors believe that the research community could improve its efficiency, foster innovation, and enhance the overall quality of scientific contributions. The paper outlines several concrete recommendations for encouraging this paradigm shift, including special conference tracks for negative results and a reevaluation of the review process to accommodate them.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Position: Measure Dataset Diversity, Don't Just Claim It</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=jsKr6RVDDs&name=pdf" class="link-primary">https://openreview.net/attachment?id=jsKr6RVDDs&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">dataset diversity</span>
<span class="badge bg-primary">measurement theory</span>
<span class="badge bg-primary">machine learning</span>
<span class="badge bg-primary">social constructs</span>
<span class="badge bg-primary">dataset evaluation</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper critiques the characterization of machine learning datasets as neutral, arguing that terms like diversity and bias lack clear definitions and validation. By analyzing 135 image and text datasets, the authors apply principles from measurement theory to propose a structured approach for conceptualizing, operationalizing, and evaluating dataset diversity. They highlight the ambiguity in existing definitions and the need for transparent documentation of data collection processes. Recommendations include developing precise definitions of diversity, assessing collection methodologies, and employing robust validation methods to ensure datasets embody their claimed characteristics, ultimately advocating for improved standards in dataset creation to enhance reproducibility and ethical considerations in machine learning research.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Position: Near to Mid-term Risks and Opportunities of Open-Source Generative AI</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=8q4EPdjTLE&name=pdf" class="link-primary">https://openreview.net/attachment?id=8q4EPdjTLE&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Open-source AI</span>
<span class="badge bg-primary">Generative AI</span>
<span class="badge bg-primary">Risks</span>
<span class="badge bg-primary">Regulation</span>
<span class="badge bg-primary">Opportunities</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper explores the near to mid-term risks and opportunities of open-source generative AI, especially as its applications are expected to revolutionize various sectors such as science, medicine, and education. The authors advocate for responsible open sourcing of generative AI models while emphasizing the importance of a balanced regulatory approach that safeguards innovation. They introduce a taxonomy of openness for generative AI models, analyze the benefits and risks of open versus closed models, and present recommendations for developers to enhance transparency and safety. The paper highlights that while open-source models foster customization, innovation, and public trust, they also pose safety risks that necessitate careful management and community engagement to mitigate potential harms.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Position: On the Societal Impact of Open Foundation Models</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=jRX6yCxFhx&name=pdf" class="link-primary">https://openreview.net/attachment?id=jRX6yCxFhx&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Open Foundation Models</span>
<span class="badge bg-primary">Societal Impact</span>
<span class="badge bg-primary">Risk Assessment</span>
<span class="badge bg-primary">Customizability</span>
<span class="badge bg-primary">Policy Recommendations</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This position paper explores the societal impact of open foundation models, defined as models with publicly accessible weights, highlighting their unique properties such as increased customizability and challenges in monitoring misuse. The authors identify significant benefits, including fostering innovation, enhancing competition, and enabling transparency, while also addressing risks related to misuse, such as cybersecurity threats and disinformation. They propose a risk assessment framework to evaluate the marginal risks of these models compared to existing technologies, emphasizing the need for empirical research to better understand these dynamics. Recommendations for stakeholders, including developers and policymakers, are outlined to enhance responsible development and deployment of open foundation models, aiming to maximize their benefits while mitigating associated risks.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Position: Open-Endedness is Essential for Artificial Superhuman Intelligence</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=Bc4vZ2CX7E&name=pdf" class="link-primary">https://openreview.net/attachment?id=Bc4vZ2CX7E&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">open-endedness</span>
<span class="badge bg-primary">artificial superhuman intelligence</span>
<span class="badge bg-primary">foundation models</span>
<span class="badge bg-primary">learnability</span>
<span class="badge bg-primary">safety</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This position paper argues that achieving open-endedness in AI systems is crucial for the development of artificial superhuman intelligence (ASI). The authors define open-endedness as a system's ability to continuously generate novel and learnable artifacts from the perspective of a human observer. They suggest that while recent advancements in foundation models (like large language models) have improved AI capabilities, these models currently lack the open-endedness necessary for true ASI. The paper explores potential pathways to incorporate open-endedness into foundation models, emphasizing the need for continual adaptation and the creation of new knowledge beyond pre-collected data. Furthermore, it discusses the safety implications of developing generally capable open-ended systems, highlighting the importance of ensuring these models remain understandable and beneficial to humanity. The authors conclude that fostering open-ended foundation models could significantly enhance scientific and technological progress while necessitating a careful consideration of associated risks.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Position: Opportunities Exist for Machine Learning in Magnetic Fusion Energy</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=arwP5FA2dO&name=pdf" class="link-primary">https://openreview.net/attachment?id=arwP5FA2dO&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Machine Learning</span>
<span class="badge bg-primary">Magnetic Fusion Energy</span>
<span class="badge bg-primary">Disruption Prediction</span>
<span class="badge bg-primary">Tokamak</span>
<span class="badge bg-primary">Data Infrastructure</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This position paper discusses the significant opportunities for Machine Learning (ML) applications within the field of magnetic fusion energy, specifically in tokamak systems, which are pivotal for achieving carbon-free energy. The authors identify six key research challenges ripe for ML intervention: disruption prediction, simulation and dynamics modeling, resolving partially observed data, improving controls, guiding optimal experiment design, and enhancing materials discovery. Each challenge is explored in detail, highlighting current ML approaches, future model features, and specific challenges that need to be addressed. The paper emphasizes the potential of ML to accelerate advancements in fusion research, ultimately contributing to decarbonization efforts and the future of energy production. Collaboration between ML practitioners and fusion researchers is deemed vital to overcoming existing technical hurdles and optimizing fusion data infrastructure.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Position: Rethinking Post-Hoc Search-Based Neural Approaches for Solving Large-Scale Traveling Salesman Problems</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=cEJ9jNJuJP&name=pdf" class="link-primary">https://openreview.net/attachment?id=cEJ9jNJuJP&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Traveling Salesman Problem</span>
<span class="badge bg-primary">Machine Learning</span>
<span class="badge bg-primary">Monte Carlo Tree Search</span>
<span class="badge bg-primary">Heatmap Generation</span>
<span class="badge bg-primary">Heuristic Algorithms</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper critiques the effectiveness of machine learning (ML)-based heatmap generation methods that guide Monte Carlo Tree Search (MCTS) for solving large-scale Traveling Salesman Problems (TSPs). The authors demonstrate that traditional heuristic methods, such as the LKH-3 algorithm, outperform these ML approaches, including a novel baseline method called SoftDist, which generates heatmaps efficiently with superior solution quality. The paper introduces a new performance metric, Score, to objectively assess MCTS against LKH-3, revealing significant inefficiencies in MCTS's performance. The authors advocate for future research to focus on developing theoretically robust heatmap generation methods and exploring end-to-end ML solutions for combinatorial optimization problems.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Position: Technical Research and Talent is Needed for Effective AI Governance</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=Be2B6f0ps1&name=pdf" class="link-primary">https://openreview.net/attachment?id=Be2B6f0ps1&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">AI Governance</span>
<span class="badge bg-primary">Technical Research</span>
<span class="badge bg-primary">Policy Integration</span>
<span class="badge bg-primary">Regulatory Gaps</span>
<span class="badge bg-primary">AI/ML Expertise</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This position paper argues for the urgent need to integrate technical research and talent into AI governance to address the gaps between regulatory aspirations and the current state of AI technologies. The authors analyze policy documents from the EU, US, and China, highlighting significant disconnects between proposed regulations and the available technical solutions for AI governance. They advocate for targeted AI/ML research to develop necessary tools and for increasing technical expertise within government bodies to ensure informed policy-making and effective enforcement. The paper concludes with a call for closer collaboration between researchers and policymakers to enhance governance capabilities in light of AI's rapid advancements and associated risks.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Position: The Platonic Representation Hypothesis</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=BH8TYy0r6u&name=pdf" class="link-primary">https://openreview.net/attachment?id=BH8TYy0r6u&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">AI</span>
<span class="badge bg-primary">deep learning</span>
<span class="badge bg-primary">representations</span>
<span class="badge bg-primary">convergence</span>
<span class="badge bg-primary">statistical model</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces the Platonic Representation Hypothesis, positing that representations in AI models, particularly deep learning networks, are converging toward a unified statistical model of reality, akin to Plato's ideal forms. The authors provide extensive evidence of this convergence across various neural network architectures, training objectives, and data modalities. They argue that increasing model size and task diversity drive this alignment, resulting in representations that reflect underlying statistical structures. Several factors contributing to this convergence are discussed, including task generality, model capacity, and simplicity bias. The implications of these trends, including potential benefits and limitations, are also explored, suggesting pathways for future research in AI representation learning.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">PrE-Text: Training Language Models on Private Federated Data in the Age of LLMs</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=3WCvnkHnxV&name=pdf" class="link-primary">https://openreview.net/attachment?id=3WCvnkHnxV&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Private Federated Learning</span>
<span class="badge bg-primary">Differential Privacy</span>
<span class="badge bg-primary">Language Models</span>
<span class="badge bg-primary">Synthetic Data Generation</span>
<span class="badge bg-primary">On-Device Training</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents PrE-Text, a novel approach for training language models on private federated data using differentially private (DP) synthetic textual data, addressing limitations of traditional on-device training. PrE-Text significantly reduces communication and computation costs while enhancing model performance compared to on-device methods. It generates high-quality synthetic data through a two-phase process involving DP synthetic seed collection and seed expansion using large pretrained models. Experimental results demonstrate that models trained with PrE-Text outperform those trained on-device under practical privacy constraints, suggesting a promising direction for privacy-compliant language model training in resource-constrained environments.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Preference Optimization for Molecule Synthesis with Conditional Residual Energy-based Models</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=oLfq1KKneW&name=pdf" class="link-primary">https://openreview.net/attachment?id=oLfq1KKneW&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">molecule synthesis</span>
<span class="badge bg-primary">energy-based models</span>
<span class="badge bg-primary">retrosynthesis</span>
<span class="badge bg-primary">machine learning</span>
<span class="badge bg-primary">optimization</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents a novel framework for optimizing molecule synthesis using Conditional Residual Energy-based Models (CREBMs). Traditional data-driven approaches for retrosynthetic planning often fail to consider long-term criteria such as material costs and yields due to their greedy, one-step prediction methods. The proposed framework enhances the quality of synthetic routes by incorporating an energy-based function that evaluates entire routes based on specific criteria, allowing for better control over the generation process. Experimental results demonstrate that the CREBM significantly improves the performance of existing strategies, achieving a state-of-the-art increase in top-1 accuracy by 2.5%. This work highlights the potential for future advancements in the field by integrating more comprehensive evaluation metrics and controllable generation techniques in molecule synthesis.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Principled Preferential Bayesian Optimization</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=YqMOM5W9GF&name=pdf" class="link-primary">https://openreview.net/attachment?id=YqMOM5W9GF&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Bayesian optimization</span>
<span class="badge bg-primary">preferential feedback</span>
<span class="badge bg-primary">regret bounds</span>
<span class="badge bg-primary">algorithm design</span>
<span class="badge bg-primary">convergence guarantees</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents a novel algorithm for Principled Preferential Bayesian Optimization (POP-BO), which addresses the challenge of optimizing black-box functions using only preference feedback between pairs of candidate solutions. The authors develop a confidence set based on the likelihood ratio and construct an optimistic algorithm that achieves information-theoretic bounds on cumulative regret, a first for this domain. The proposed algorithm is shown to efficiently compute the optimal solution and guarantees convergence rates for reported solutions. Experimental results demonstrate that POP-BO outperforms existing heuristic methods in various scenarios, including Gaussian processes and real-world applications like thermal comfort optimization, while also providing significant computational efficiency.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">PRISE: LLM-Style Sequence Compression for Learning Temporal Action Abstractions in Control</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=p225Od0aYt&name=pdf" class="link-primary">https://openreview.net/attachment?id=p225Od0aYt&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">temporal action abstraction</span>
<span class="badge bg-primary">sequence compression</span>
<span class="badge bg-primary">reinforcement learning</span>
<span class="badge bg-primary">imitation learning</span>
<span class="badge bg-primary">behavior cloning</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces PRISE (Primitive Sequence Encoding), a novel approach that frames the learning of temporal action abstractions as a sequence compression problem, akin to techniques used in large language models (LLMs). By leveraging Byte Pair Encoding (BPE) alongside continuous action quantization, PRISE efficiently learns variable-timespan action primitives from multitask robotic manipulation demonstrations. The authors demonstrate that the action abstractions derived from PRISE significantly enhance the performance of Behavior Cloning in downstream tasks, indicating the effectiveness of integrating NLP methodologies into continuous control scenarios. Extensive experiments validate the efficacy of PRISE over traditional methods, particularly in multi-task learning and few-shot adaptation scenarios.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Privacy Preserving Adaptive Experiment Design</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=1QmFKwVwwI&name=pdf" class="link-primary">https://openreview.net/attachment?id=1QmFKwVwwI&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">adaptive experiment design</span>
<span class="badge bg-primary">privacy preservation</span>
<span class="badge bg-primary">conditional average treatment effect</span>
<span class="badge bg-primary">contextual bandits</span>
<span class="badge bg-primary">multi-objective optimization</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper investigates the tradeoff between social welfare loss and statistical power in adaptive experiment design, particularly focusing on the estimation of Conditional Average Treatment Effect (CATE) in clinical trials within a contextual bandit framework. It proposes a matched upper and lower bound for a multi-objective optimization problem, emphasizing the importance of balancing regret minimization and estimation accuracy. The authors introduce a differentially private algorithm named DP-ConSE, demonstrating that privacy can be maintained without significantly compromising estimation accuracy. The results show that the proposed method achieves optimal estimation accuracy and regret bounds, supporting the conclusion that privacy in adaptive experimental design is nearly cost-free.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Private Truly-Everlasting Robust-Prediction</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=BdQTCAuT6L&name=pdf" class="link-primary">https://openreview.net/attachment?id=BdQTCAuT6L&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">private everlasting prediction</span>
<span class="badge bg-primary">differential privacy</span>
<span class="badge bg-primary">robust learning</span>
<span class="badge bg-primary">poisoning attacks</span>
<span class="badge bg-primary">sample complexity</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces conceptual modifications to the Private Everlasting Prediction (PEP) framework, enhancing its robustness against poisoning attacks and creating a relaxed privacy definition that decouples the privacy parameter from the number of queries. The authors define a new model, Private Everlasting Robust Prediction (PERP), which ensures that the predictor remains effective even when a portion of the queries is adversarial. They provide efficient constructions for specific classes of functions, such as axis-aligned rectangles and decision stumps, demonstrating significant improvements in sample complexity and runtime compared to prior works. These advancements position PEP as a viable alternative to classical private learning models, particularly in scenarios where traditional methods may falter.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Probabilistic Generating Circuits - Demystified</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=EqFxIbGWRU&name=pdf" class="link-primary">https://openreview.net/attachment?id=EqFxIbGWRU&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">probabilistic generating circuits</span>
<span class="badge bg-primary">probabilistic circuits</span>
<span class="badge bg-primary">determinantal point processes</span>
<span class="badge bg-primary">tractable inference</span>
<span class="badge bg-primary">complexity theory</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper critically examines the concept of probabilistic generating circuits (PGCs), introduced by Zhang et al. (2021), positing that their power derives not from their unique representation of probability distributions but from their allowance of negative weights, a feature absent in traditional probabilistic circuits (PCs). The authors demonstrate that any PGC for binary variables can be converted into a nonmonotone PC with negative weights, preserving tractability for marginalization. They establish that PGCs do not support efficient marginalization for categorical variables with more than two values unless NP=P, and they show that nonmonotone PCs that compute set-multilinear polynomials are more general and can efficiently marginalize over such variables. The paper also explores the relationship between nonmonotone PCs and determinantal point processes, concluding that the complexity of determining whether a nonmonotone PC computes a probability distribution is likely NP-hard.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Probabilistic Inference in Language Models via Twisted Sequential Monte Carlo</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=frA0NNBS1n&name=pdf" class="link-primary">https://openreview.net/attachment?id=frA0NNBS1n&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Sequential Monte Carlo</span>
<span class="badge bg-primary">Language Models</span>
<span class="badge bg-primary">Probabilistic Inference</span>
<span class="badge bg-primary">Reinforcement Learning</span>
<span class="badge bg-primary">Contrastive Learning</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces a novel framework for probabilistic inference in language models using Twisted Sequential Monte Carlo (TSMC), enhancing techniques for sampling from unnormalized target distributions tied to various tasks like reinforcement learning from human feedback (RLHF) and red-teaming. By employing learned twist functions, the method estimates future potential values at each time step, allowing efficient sampling focused on promising sequences. The authors propose a contrastive twist learning approach for estimating these functions and establish new bidirectional bounds for evaluating inference quality in language models. Experimental results demonstrate TSMC's effectiveness in generating varied sentiment outputs and assessing the reliability of inference techniques, marking significant advancements in LLM safety and capability tasks.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Provable Multi-Task Representation Learning by Two-Layer ReLU Neural Networks</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=M8UbECx485&name=pdf" class="link-primary">https://openreview.net/attachment?id=M8UbECx485&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">multi-task learning</span>
<span class="badge bg-primary">feature representation</span>
<span class="badge bg-primary">neural networks</span>
<span class="badge bg-primary">gradient descent</span>
<span class="badge bg-primary">theoretical analysis</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents a theoretical study of multi-task representation learning using two-layer ReLU neural networks. It establishes that pretraining on multiple tasks with gradient descent enables effective feature learning in nonlinear settings, specifically revealing that a pseudo-contrastive loss emerges which aligns representations of data points sharing the same labels across tasks. The authors prove that when tasks depend on a low-dimensional subspace of the input space, a simple gradient-based algorithm can recover this subspace, allowing for effective generalization to downstream tasks. They demonstrate that multi-task pretraining significantly reduces the sample and neuron complexity required for learning, contrasting it with single-task learning which often fails to capture all relevant features. Additionally, numerical simulations support their theoretical findings, showing that increasing the number of tasks improves representation quality and downstream performance.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Pruned Pivot: Correlation Clustering Algorithm for Dynamic, Parallel, and Local Computation Models</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=saP7s0ZgYE&name=pdf" class="link-primary">https://openreview.net/attachment?id=saP7s0ZgYE&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">correlation clustering</span>
<span class="badge bg-primary">dynamic algorithms</span>
<span class="badge bg-primary">parallel computation</span>
<span class="badge bg-primary">local computation</span>
<span class="badge bg-primary">approximation algorithms</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents a novel correlation clustering algorithm named PRUNED PIVOT, which addresses the challenge of clustering nodes in graphs with positive and negative edge labels. The authors focus on the dynamic, parallel, and local computation models, significantly improving runtime complexities. PRUNED PIVOT achieves an expected amortized constant time update for fully dynamic graphs, without dependence on graph size, while matching the approximation guarantee of the well-known PIVOT algorithm. The proposed algorithm allows efficient clustering in various computational frameworks and provides empirical results showing that it queries significantly fewer nodes than existing algorithms, with minimal increase in approximation cost.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Rate-Optimal Policy Optimization for Linear Markov Decision Processes</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=VJwsDwuiuH&name=pdf" class="link-primary">https://openreview.net/attachment?id=VJwsDwuiuH&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">linear Markov Decision Processes</span>
<span class="badge bg-primary">policy optimization</span>
<span class="badge bg-primary">regret minimization</span>
<span class="badge bg-primary">computational efficiency</span>
<span class="badge bg-primary">reinforcement learning</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents a novel algorithm for regret minimization in online episodic linear Markov Decision Processes (MDPs), achieving rate-optimal \(O(\sqrt{T})\) regret, where \(T\) is the number of episodes. The authors establish optimal convergence rates in both stochastic settings with bandit feedback and adversarial settings with full information feedback, marking significant advancements in policy optimization approaches. A key innovation is the use of an optimistic variant of the natural policy gradient combined with a reward-free warmup phase to effectively manage exploration and estimation errors. This approach provides strong theoretical guarantees and practical applicability across various domains in reinforcement learning.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Rejuvenating image-GPT as Strong Visual Representation Learners</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=mzGtunvpJH&name=pdf" class="link-primary">https://openreview.net/attachment?id=mzGtunvpJH&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">autoregressive pretraining</span>
<span class="badge bg-primary">visual representation learning</span>
<span class="badge bg-primary">D-iGPT</span>
<span class="badge bg-primary">semantic tokens</span>
<span class="badge bg-primary">ImageNet-1K</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents D-iGPT, an enhanced version of the original image-GPT model, which shifts the autoregressive prediction target from raw pixels to semantic tokens and introduces additional supervision by predicting visible tokens. These modifications enable D-iGPT to achieve remarkable performance on the ImageNet-1K dataset, reaching a top-1 accuracy of 90.0% using only publicly available datasets, thus surpassing previous state-of-the-art results. The authors highlight the effectiveness of their approach through extensive experiments, demonstrating that D-iGPT not only excels in visual representation learning but also shows strong generalization capabilities across various downstream tasks.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Repoformer: Selective Retrieval for Repository-Level Code Completion</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=moyG54Okrj&name=pdf" class="link-primary">https://openreview.net/attachment?id=moyG54Okrj&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">code completion</span>
<span class="badge bg-primary">retrieval-augmented generation</span>
<span class="badge bg-primary">selective retrieval</span>
<span class="badge bg-primary">language models</span>
<span class="badge bg-primary">efficiency</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces REPOFORMER, a novel framework for repository-level code completion that addresses the inefficiencies and performance issues inherent in conventional retrieval-augmented generation (RAG) methods. Instead of always retrieving supplementary code contexts, REPOFORMER employs a selective retrieval mechanism that allows the model to assess whether retrieval will enhance its output. This is achieved through a self-supervised learning approach that enables the code language model (LM) to evaluate its own knowledge and decide on the necessity of retrieval. The experimental results demonstrate that REPOFORMER not only outperforms existing methods in accuracy across various benchmarks but also achieves significant inference speedups, indicating its potential for practical applications in software development. Additionally, the framework shows versatility across different programming languages and retrieval strategies, marking a significant advancement in the field of code completion.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Rethinking Data Shapley for Data Selection Tasks: Misleads and Merits</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=mKYBMf1hHG&name=pdf" class="link-primary">https://openreview.net/attachment?id=mKYBMf1hHG&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Data Shapley</span>
<span class="badge bg-primary">Data selection</span>
<span class="badge bg-primary">Utility functions</span>
<span class="badge bg-primary">Machine learning</span>
<span class="badge bg-primary">Experimental analysis</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper critically examines the application of Data Shapley in data selection tasks, highlighting its inconsistent performance across various settings. The authors introduce a hypothesis testing framework that reveals that Data Shapley can perform no better than random selection unless specific constraints on utility functions are enforced. They identify a class of utility functions, termed monotonically transformed modular functions, where Data Shapley is optimal for data selection. The study proposes a heuristic for predicting Data Shapley's effectiveness based on the fitting quality of these utility functions, backed by experimental results that illustrate the correlation between Data Shapley's performance and the defined utility function characteristics. Overall, the research offers significant theoretical and practical insights into when and how Data Shapley can be effectively utilized for data selection in machine learning contexts.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Robust CLIP: Unsupervised Adversarial Fine-Tuning of Vision Embeddings for Robust Large Vision-Language Models</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=WLPhywf1si&name=pdf" class="link-primary">https://openreview.net/attachment?id=WLPhywf1si&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">adversarial robustness</span>
<span class="badge bg-primary">vision-language models</span>
<span class="badge bg-primary">unsupervised fine-tuning</span>
<span class="badge bg-primary">CLIP</span>
<span class="badge bg-primary">zero-shot classification</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents a novel approach called FARE (Fine-tuning for Adversarially Robust Embeddings) for enhancing the adversarial robustness of the CLIP vision encoder used in large vision-language models (LVLMs) without requiring retraining of downstream tasks. Unlike existing methods, FARE employs an unsupervised adversarial fine-tuning strategy that maintains the original embeddings' integrity while improving the model's resistance to adversarial attacks. The authors demonstrate that integrating FARE into models like LLaVA and OpenFlamingo significantly reduces the models' susceptibility to stealthy targeted attacks and adversarial perturbations while preserving or even enhancing their performance on zero-shot classification tasks. Extensive experimental results confirm that FARE outperforms supervised approaches in both clean and adversarial settings, making it a promising solution for the deployment of robust LVLMs in real-world applications.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Robustness of Nonlinear Representation Learning</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=GyV33H5Uuk&name=pdf" class="link-primary">https://openreview.net/attachment?id=GyV33H5Uuk&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Nonlinear Representation Learning</span>
<span class="badge bg-primary">Robustness</span>
<span class="badge bg-primary">Independent Component Analysis</span>
<span class="badge bg-primary">Misspecification</span>
<span class="badge bg-primary">Identifiability</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper investigates the robustness of nonlinear representation learning in slightly misspecified settings, particularly focusing on unsupervised representation learning under conditions where mixing functions approximate local isometries. The authors demonstrate that even with minor deviations from ideal assumptions, it is possible to identify latent variables and mixing functions with reasonable accuracy. They build on existing theories and establish that Independent Component Analysis (ICA) can effectively recover mixing matrices and independent components in the presence of small perturbations. Their findings indicate that approximate identifiability can be achieved under relaxed conditions that better reflect real-world data scenarios, thereby advancing the understanding of robustness in representation learning frameworks.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">S  I: Score-based O-INFORMATION Estimation</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=LuhWZ2oJ5L&name=pdf" class="link-primary">https://openreview.net/attachment?id=LuhWZ2oJ5L&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">O-INFORMATION</span>
<span class="badge bg-primary">Information Theory</span>
<span class="badge bg-primary">Multivariate Systems</span>
<span class="badge bg-primary">Machine Learning</span>
<span class="badge bg-primary">Neuroscience</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces a novel methodology, SI (Score-based O-INFORMATION estimation), for estimating O-INFORMATION, an information-theoretic measure that captures the balance between synergy and redundancy in multivariate systems. Traditional measures like mutual information are limited to pairwise interactions, whereas O-INFORMATION can effectively characterize higher-order dependencies. The authors address the scalability and practical application issues of O-INFORMATION by leveraging score functions from recent advancements in mutual information estimation, enabling SI to operate without stringent assumptions about data distributions. Experimental validation demonstrates SI's effectiveness on synthetic datasets and real-world applications, particularly in analyzing brain activity in mice, showcasing its robustness and scalability compared to existing methods.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">SAM as the Guide: Mastering Pseudo-Label Refinement in Semi-Supervised Referring Expression Segmentation</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=M5kn9NKIs4&name=pdf" class="link-primary">https://openreview.net/attachment?id=M5kn9NKIs4&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">semi-supervised learning</span>
<span class="badge bg-primary">referring expression segmentation</span>
<span class="badge bg-primary">pseudo-label refinement</span>
<span class="badge bg-primary">segmentation accuracy</span>
<span class="badge bg-primary">Segment Anything Model (SAM)</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents SemiRES, a semi-supervised framework designed to enhance referring expression segmentation (RES) by effectively utilizing both labeled and unlabeled data while addressing the challenge of noisy pseudo-labels at object boundaries. By incorporating the Segment Anything Model (SAM), which excels in precise boundary delineation, SemiRES employs two innovative matching strategies—IoU-based Optimal Matching (IOM) and Composite Parts Integration (CPI)—to refine pseudo-labels and improve segmentation accuracy. Furthermore, when ideal matches are unavailable, a Pixel-Wise Adjustment (PWA) strategy is utilized to guide model training using pseudo-labels directly. Extensive evaluations on benchmark datasets RefCOCO, RefCOCO+, and G-Ref demonstrate that SemiRES significantly outperforms both fully supervised and baseline semi-supervised methods, achieving substantial accuracy gains even with minimal labeled data, thus showcasing its potential for real-world applications in resource-constrained settings.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">SAMformer: Unlocking the Potential of Transformers in Time Series Forecasting with Sharpness-Aware Minimization and Channel-Wise Attention</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=8kLzL5QBh2&name=pdf" class="link-primary">https://openreview.net/attachment?id=8kLzL5QBh2&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Transformers</span>
<span class="badge bg-primary">Time Series Forecasting</span>
<span class="badge bg-primary">Sharpness-Aware Minimization</span>
<span class="badge bg-primary">Channel-Wise Attention</span>
<span class="badge bg-primary">Machine Learning</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents SAMformer, a novel transformer architecture designed for multivariate long-term time series forecasting, addressing the issue of transformers underperforming compared to simpler models. Through extensive analysis, the authors demonstrate that traditional transformer models struggle due to poor generalization caused by their attention mechanisms, which often lead to convergence in sharp local minima. SAMformer incorporates sharpness-aware minimization techniques and channel-wise attention, allowing it to escape these local minima and achieve better performance on several real-world datasets. Empirical results show that SAMformer surpasses existing state-of-the-art methods while maintaining a significantly smaller parameter size, highlighting its effectiveness and efficiency in time series forecasting tasks.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">SAPG: Split and Aggregate Policy Gradients</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=4dOJAfXhNV&name=pdf" class="link-primary">https://openreview.net/attachment?id=4dOJAfXhNV&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">reinforcement learning</span>
<span class="badge bg-primary">policy gradients</span>
<span class="badge bg-primary">sample efficiency</span>
<span class="badge bg-primary">GPU simulation</span>
<span class="badge bg-primary">multi-policy framework</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces SAPG (Split and Aggregate Policy Gradients), a novel on-policy reinforcement learning algorithm designed to address the limitations of existing methods like PPO (Proximal Policy Optimization) in leveraging large-scale parallel environments. Current algorithms suffer from performance saturation when batch sizes exceed a certain limit due to redundant data sampling across environments. SAPG improves upon this by dividing environments into blocks that optimize distinct policies, allowing for the aggregation of diverse data via importance sampling. This approach enhances learning efficiency and significantly outperforms PPO and other state-of-the-art methods across various challenging tasks in simulation, demonstrating higher asymptotic performance and better utilization of abundant simulation data.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Scalable AI Safety via Doubly-Efficient Debate</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=6jmdOTRMIO&name=pdf" class="link-primary">https://openreview.net/attachment?id=6jmdOTRMIO&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">AI Safety</span>
<span class="badge bg-primary">Debate Protocols</span>
<span class="badge bg-primary">Human Feedback</span>
<span class="badge bg-primary">Large Language Models</span>
<span class="badge bg-primary">Computational Complexity</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents a novel approach to scalable AI safety through the development of "doubly-efficient debate" protocols, enhancing the framework proposed by Irving et al. (2018). The authors address challenges around verifying the alignment of powerful AI systems, particularly in complex tasks where human judgment is limited. They introduce a model where two polynomial-time provers debate to convince a significantly more efficient verifier using only a constant number of human judgments. The paper demonstrates that this approach allows for verifying any polynomial-time computation with minimal human oversight, thereby facilitating the safe training of large language models (LLMs) in high-stakes contexts, such as drafting legal documents. The proposed methods leverage insights from computational complexity theory to ensure that it is easier to tell the truth than to lie during the debate, thereby ensuring a robust mechanism for scalable AI oversight.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Scaling Rectified Flow Transformers for High-Resolution Image Synthesis</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=FPnUhsQJ5B&name=pdf" class="link-primary">https://openreview.net/attachment?id=FPnUhsQJ5B&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Generative Modeling</span>
<span class="badge bg-primary">Image Synthesis</span>
<span class="badge bg-primary">Transformers</span>
<span class="badge bg-primary">Rectified Flow</span>
<span class="badge bg-primary">Diffusion Models</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents advancements in high-resolution image synthesis using a novel transformer-based architecture, termed MM-DiT, in conjunction with rectified flow models for generative modeling. The authors introduce improved noise sampling techniques that prioritize perceptually relevant scales and demonstrate their effectiveness through extensive comparisons with existing diffusion models. The study highlights the architecture's ability to facilitate a bidirectional flow of information between text and image modalities, resulting in superior performance in text-to-image generation tasks. Through a large-scale scaling analysis, the researchers reveal predictable correlations between lower validation loss and enhanced image quality, as assessed by various metrics and human evaluations. The findings indicate that their largest model, comprising 8 billion parameters, surpasses state-of-the-art models in performance, suggesting significant potential for future advancements in generative modeling.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">SceneCraft: An LLM Agent for Synthesizing 3D Scenes as Blender Code</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=gAyzjHw2ml&name=pdf" class="link-primary">https://openreview.net/attachment?id=gAyzjHw2ml&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">3D Scene Generation</span>
<span class="badge bg-primary">Large Language Models</span>
<span class="badge bg-primary">Blender Scripting</span>
<span class="badge bg-primary">Spatial Planning</span>
<span class="badge bg-primary">Self-Improvement Mechanism</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents SceneCraft, an advanced Large Language Model (LLM) agent designed to convert textual descriptions into executable Blender Python scripts for rendering intricate 3D scenes with multiple assets. SceneCraft employs a dual-loop process that includes inner-loop optimization for scene layout through iterative script refinement based on feedback from a multimodal LLM, and outer-loop library learning to enhance its spatial skill library without the need for human intervention. The framework effectively models spatial relationships using a scene graph, enabling it to handle complex arrangements autonomously. Evaluations reveal that SceneCraft significantly outperforms existing LLM-based agents, demonstrating superior fidelity in translating text to 3D scenes and showcasing potential applications in video generation by providing structured scene inputs.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Self-Composing Policies for Scalable Continual Reinforcement Learning</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=f5gtX2VWSB&name=pdf" class="link-primary">https://openreview.net/attachment?id=f5gtX2VWSB&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Continual Reinforcement Learning</span>
<span class="badge bg-primary">Neural Networks</span>
<span class="badge bg-primary">Catastrophic Forgetting</span>
<span class="badge bg-primary">Policy Learning</span>
<span class="badge bg-primary">Knowledge Transfer</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents CompoNet, a modular neural network architecture designed for scalable continual reinforcement learning (CRL) that effectively mitigates issues of catastrophic forgetting and interference commonly encountered in traditional neural networks. CompoNet achieves this by allowing each module to selectively compose previous policies with its internal policy, facilitating accelerated learning for new tasks while maintaining a linear growth in parameters relative to the number of tasks. Empirical results demonstrate that CompoNet significantly outperforms existing CRL methods across various benchmarks, showcasing enhanced performance, knowledge transfer, and robustness, even when learning from scratch in unrelated tasks. The findings suggest that CompoNet provides a promising direction for developing efficient CRL agents capable of handling a continuous influx of tasks without compromising scalability or performance.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Sparse Inducing Points in Deep Gaussian Processes: Enhancing Modeling with Denoising Diffusion Variational Inference</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=jTn4AIOgpM&name=pdf" class="link-primary">https://openreview.net/attachment?id=jTn4AIOgpM&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Deep Gaussian Processes</span>
<span class="badge bg-primary">Variational Inference</span>
<span class="badge bg-primary">Denoising Diffusion</span>
<span class="badge bg-primary">Posterior Inference</span>
<span class="badge bg-primary">Computational Efficiency</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces Denoising Diffusion Variational Inference (DDVI) as a novel approach to improve posterior inference of inducing points in Deep Gaussian Processes (DGPs). It addresses the limitations of traditional variational inference methods, which often introduce significant bias, by employing a denoising diffusion stochastic differential equation (SDE) to generate posterior samples. The authors utilize score matching methods to approximate score functions with a neural network, enabling a more accurate and efficient representation of complex dependencies among inducing points. Extensive experimental results demonstrate the effectiveness of DDVI across various datasets, showcasing its advantages in computational efficiency and reliability in training DGP models, thereby enhancing the overall framework for Bayesian deep learning.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">SparseTSF: Modeling Long-term Time Series Forecasting with *1k* Parameters</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=54NSHO0lFe&name=pdf" class="link-primary">https://openreview.net/attachment?id=54NSHO0lFe&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Time Series Forecasting</span>
<span class="badge bg-primary">Lightweight Models</span>
<span class="badge bg-primary">Cross-Period Sparse Forecasting</span>
<span class="badge bg-primary">Long-term Predictions</span>
<span class="badge bg-primary">Computational Efficiency</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents SparseTSF, an innovative and highly efficient model for Long-term Time Series Forecasting (LTSF), which utilizes fewer than 1,000 parameters through a novel Cross-Period Sparse Forecasting technique. This approach simplifies the forecasting process by decoupling periodic trends from the data, effectively enhancing the model's capability to predict long-term dependencies while minimizing computational demands. SparseTSF achieves competitive or superior forecasting performance compared to state-of-the-art models, showcasing robust generalization capabilities, making it suitable for scenarios with limited resources or low-quality data. The model's lightweight architecture positions it as a significant advancement in the field of LTSF, with promising applications across various domains that exhibit clear periodic patterns.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Speech Self-Supervised Learning Using Diffusion Model Synthetic Data</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=ecnpYYHjt9&name=pdf" class="link-primary">https://openreview.net/attachment?id=ecnpYYHjt9&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">speech processing</span>
<span class="badge bg-primary">self-supervised learning</span>
<span class="badge bg-primary">synthetic data</span>
<span class="badge bg-primary">diffusion models</span>
<span class="badge bg-primary">low-resource languages</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces DIFFS4L, a novel pretraining method that enhances self-supervised learning (SSL) for speech processing by generating synthetic data using diffusion models. While SSL has reduced the need for large annotated datasets, its performance heavily relies on the availability of extensive unannotated corpora, which can be challenging for low-resource languages. DIFFS4L tackles this issue by augmenting limited unannotated data with synthetically generated speech that exhibits variations in prosody, speaker identity, and content, thereby improving the information efficiency of existing SSL models. Experimental results demonstrate significant performance improvements, such as a 6.26 percentage point reduction in word error rate for the HuBERT model in English automatic speech recognition tasks. The findings indicate that leveraging synthetic data, even when containing nonsensical content, can effectively enhance SSL capabilities, particularly in low-resource settings, and suggest further exploration into optimizing information sharing between models for better efficiency.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Stealing part of a production language model</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=VE3yWXt3KB&name=pdf" class="link-primary">https://openreview.net/attachment?id=VE3yWXt3KB&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">model stealing</span>
<span class="badge bg-primary">language models</span>
<span class="badge bg-primary">black-box attacks</span>
<span class="badge bg-primary">embedding extraction</span>
<span class="badge bg-primary">API vulnerabilities</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents a novel model-stealing attack capable of extracting significant information from black-box production language models like OpenAI's ChatGPT and Google's PaLM-2 through API access. The proposed attack specifically targets the embedding projection layer of transformer models, demonstrating the ability to recover the entire projection matrix of certain models at a low cost. The authors reveal the hidden dimensions of various models and discuss the implications of their findings, which highlight the potential risks associated with API access to these models. They also suggest possible defensive measures to mitigate the effectiveness of such attacks, underscoring the need for improved security in machine learning systems.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Stereo Risk: A Continuous Modeling Approach to Stereo Matching</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=Mfk6ZbD6eY&name=pdf" class="link-primary">https://openreview.net/attachment?id=Mfk6ZbD6eY&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">stereo matching</span>
<span class="badge bg-primary">continuous risk minimization</span>
<span class="badge bg-primary">deep learning</span>
<span class="badge bg-primary">disparity estimation</span>
<span class="badge bg-primary">computer vision</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents Stereo Risk, a novel deep-learning framework aimed at enhancing stereo matching in computer vision by framing the disparity estimation problem as a continuous risk minimization task rather than relying on discrete disparity values. By employing L1 minimization of a continuous risk function, the approach effectively captures the continuous nature of scene depth and improves performance in scenarios with multi-modal probability distributions. The authors utilize the implicit function theorem to facilitate end-to-end training of the non-differentiable L1 risk optimization, demonstrating superior results compared to existing state-of-the-art methods across multiple benchmark datasets, including KITTI and SceneFlow. The findings highlight the theoretical robustness and practical effectiveness of risk minimization in stereo matching applications.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Stop Regressing: Training Value Functions via Classification for Scalable Deep RL</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=dVpFKfqF3R&name=pdf" class="link-primary">https://openreview.net/attachment?id=dVpFKfqF3R&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">value functions</span>
<span class="badge bg-primary">classification</span>
<span class="badge bg-primary">deep reinforcement learning</span>
<span class="badge bg-primary">scalability</span>
<span class="badge bg-primary">categorical cross-entropy</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper explores the potential of using classification, specifically categorical cross-entropy, to train value functions in deep reinforcement learning (RL) instead of traditional mean squared error regression. It argues that this shift enhances scalability and performance across various domains, including Atari games, multi-task RL, chess, and robotic manipulation. The authors demonstrate that categorical cross-entropy mitigates common issues in value-based RL, such as noisy targets and non-stationarity, leading to improved robustness and better representation learning. Empirical results show significant performance gains with this new approach, suggesting that classifying value functions can facilitate the scaling and effectiveness of deep RL methods.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Symbolic Music Generation with Non-Differentiable Rule Guided Diffusion</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=g8AigOTNXL&name=pdf" class="link-primary">https://openreview.net/attachment?id=g8AigOTNXL&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Symbolic Music Generation</span>
<span class="badge bg-primary">Non-Differentiable Guidance</span>
<span class="badge bg-primary">Stochastic Control</span>
<span class="badge bg-primary">Diffusion Models</span>
<span class="badge bg-primary">Rule-Based Music Composition</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents a novel framework for symbolic music generation that addresses the challenges posed by non-differentiable musical rules through a method called Stochastic Control Guidance (SCG). By allowing for plug-and-play integration with pre-trained diffusion models, SCG enables the generation of music that adheres to specific rules—such as note density and chord progression—without requiring extensive retraining. The authors introduce a latent diffusion architecture capable of generating high-resolution symbolic music, achieving significant improvements in music quality and rule compliance compared to existing state-of-the-art methods. Comprehensive evaluations demonstrate SCG's effectiveness across various tasks, highlighting its potential to enhance creative music composition by incorporating flexibility and interpretability.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Test-Time Model Adaptation with Only Forward Passes</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=qz1Vx1v9iK&name=pdf" class="link-primary">https://openreview.net/attachment?id=qz1Vx1v9iK&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Test-Time Adaptation</span>
<span class="badge bg-primary">Forward Optimization</span>
<span class="badge bg-primary">Covariance Matrix Adaptation</span>
<span class="badge bg-primary">Resource-Constrained Devices</span>
<span class="badge bg-primary">Model Generalization</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents a novel approach to test-time model adaptation called Forward-Optimization Adaptation (FOA), which operates without backpropagation, making it suitable for deployment on resource-limited devices like FPGAs and smartphones. FOA employs a derivative-free optimization strategy using covariance matrix adaptation to learn new prompts for model inputs, along with a fitness function designed to measure prediction entropy and feature distribution discrepancies to enhance performance. Additionally, an activation shifting mechanism is introduced to align model activations from out-of-distribution test samples back to the source training domain. The proposed method achieves superior accuracy and memory efficiency compared to traditional gradient-based methods, demonstrating its effectiveness across various benchmarks, including those involving quantized models.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">The Stronger the Diffusion Model, the Easier the Backdoor: Data Poisoning to Induce Copyright BreachesWithout Adjusting Finetuning Pipeline</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=ZvFLbEPv6x&name=pdf" class="link-primary">https://openreview.net/attachment?id=ZvFLbEPv6x&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">copyright infringement</span>
<span class="badge bg-primary">diffusion models</span>
<span class="badge bg-primary">data poisoning</span>
<span class="badge bg-primary">backdoor attacks</span>
<span class="badge bg-primary">machine learning</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper investigates the vulnerabilities of text-to-image diffusion models (DMs) to copyright infringement through a novel backdoor attack method named SilentBadDiffusion. The authors formalize the Copyright Infringement Attack, demonstrating how attackers can secretly embed poisoned data into clean training datasets, enabling the model to generate copyrighted images when prompted with specific text. Their experiments reveal that even a low ratio of poisoned data (0.20%) can trigger copyright breaches, especially in more advanced models, highlighting significant flaws in existing copyright protection strategies. The findings suggest a pressing need for enhanced scrutiny and preventative measures to mitigate the potential misuse of diffusion models in generating infringing content.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Theoretical Analysis of Learned Database Operations under Distribution Shift through Distribution Learnability</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=oowQ8LPA12&name=pdf" class="link-primary">https://openreview.net/attachment?id=oowQ8LPA12&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">learned database operations</span>
<span class="badge bg-primary">distribution shift</span>
<span class="badge bg-primary">theoretical analysis</span>
<span class="badge bg-primary">distribution learnability</span>
<span class="badge bg-primary">machine learning performance</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper provides a theoretical framework for understanding the performance of learned database operations, such as indexing, cardinality estimation, and sorting, in the context of distribution shifts in dynamic datasets. It highlights the inadequacy of existing methods under changing data distributions, leading to potential performance degradation. The authors introduce the concept of distribution learnability, which allows for the performance of learned models to be characterized theoretically. They establish bounds on the performance of these models compared to non-learned alternatives, demonstrating scenarios where learned approaches can outperform traditional methods. The analysis is supported by theoretical results that outline complexities for query, insertion, and space requirements for learned operations, thus paving the way for future research in this area.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Towards Optimal Adversarial Robust Q-learning with Bellman Infinity-error</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=pgI9inG2Ny&name=pdf" class="link-primary">https://openreview.net/attachment?id=pgI9inG2Ny&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">adversarial robustness</span>
<span class="badge bg-primary">Q-learning</span>
<span class="badge bg-primary">deep reinforcement learning</span>
<span class="badge bg-primary">Bellman optimal policy</span>
<span class="badge bg-primary">optimal robust policy</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper investigates the establishment of an optimal robust policy (ORP) for deep reinforcement learning (DRL) agents against adversarial attacks, particularly focusing on the Bellman optimal policy. By introducing a consistency assumption of policy (CAP), the authors demonstrate that a deterministic and stationary ORP can coexist with the Bellman optimal policy under certain conditions. They emphasize the necessity of minimizing Bellman Infinity-error using L-norm instead of L1-norm to improve robustness, leading to the development of the Consistent Adversarial Robust Deep Q-Network (CAR-DQN). Experimental results show that CAR-DQN significantly outperforms existing methods across various benchmarks, validating the theoretical findings of the study.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Trained Random Forests Completely Reveal your Dataset</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=cc72Vnfvoc&name=pdf" class="link-primary">https://openreview.net/attachment?id=cc72Vnfvoc&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">random forests</span>
<span class="badge bg-primary">dataset reconstruction</span>
<span class="badge bg-primary">privacy attacks</span>
<span class="badge bg-primary">constraint programming</span>
<span class="badge bg-primary">machine learning</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper presents a novel reconstruction attack on random forests (RFs), demonstrating that it is possible to reconstruct an entire dataset used for training RFs by utilizing information available in libraries like scikit-learn. The authors formulate the reconstruction problem as a maximum likelihood estimation and show that it is NP-hard, but solvable at scale using constraint programming techniques. Through extensive experiments, they reveal that RFs trained without bootstrap aggregation can be nearly perfectly reconstructed, while those trained with aggregation still allow for the recovery of a substantial portion of the data. These findings highlight significant vulnerabilities in widely used ensemble methods and the ethical implications of using sensitive data in machine learning, necessitating stronger privacy protections. The authors provide their tool, named DRAFT, as an accessible resource for further research in this area.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Transformers Learn Nonlinear Features In Context: Nonconvex Mean-field Dynamics on the Attention Landscape</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=xm2lU7tteQ&name=pdf" class="link-primary">https://openreview.net/attachment?id=xm2lU7tteQ&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Transformers</span>
<span class="badge bg-primary">In-Context Learning</span>
<span class="badge bg-primary">Mean-Field Dynamics</span>
<span class="badge bg-primary">Nonconvex Optimization</span>
<span class="badge bg-primary">Wasserstein Gradient Flow</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper investigates the optimization dynamics of a Transformer model that incorporates a multi-layer perceptron (MLP) followed by a linear attention layer, focusing on the phenomenon of in-context learning (ICL). Unlike prior research that examined single-layer attention models, this study demonstrates that the MLP significantly enhances the model's ability to learn complex functions, thereby broadening the class of learnable tasks. The authors analyze the loss landscape of this architecture and establish that, in the mean-field limit, the highly nonconvex landscape becomes benign, allowing for effective optimization via Wasserstein gradient flow. The paper also presents a novel saddle point analysis, showing that mean-field dynamics typically avoids saddle points, and provides convergence rates for the optimization process in various critical regions. Additionally, the theoretical findings are supported by numerical experiments that validate the model's performance in learning tasks.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Unified Training of Universal Time Series Forecasting Transformers</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=Yd8eHMY1wz&name=pdf" class="link-primary">https://openreview.net/attachment?id=Yd8eHMY1wz&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">time series forecasting</span>
<span class="badge bg-primary">deep learning</span>
<span class="badge bg-primary">universal forecasting</span>
<span class="badge bg-primary">Transformer architecture</span>
<span class="badge bg-primary">zero-shot learning</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents MOIRAI, a novel Transformer architecture designed for universal time series forecasting, addressing the limitations of traditional deep learning approaches that typically train separate models for distinct datasets. By leveraging the Large-scale Open Time Series Archive (LOTSA) containing over 27 billion observations from diverse domains, MOIRAI incorporates enhancements such as multi-frequency learning, any-variate attention, and flexible distribution modeling to effectively handle the heterogeneous nature of time series data. Experimental results demonstrate that MOIRAI achieves competitive or superior performance in both in-distribution and zero-shot forecasting settings compared to state-of-the-art models, thereby advancing the paradigm of universal forecasting in deep learning.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Video-LaVIT: Unified Video-Language Pre-training with Decoupled Visual-Motional Tokenization</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=S9lk6dk4LL&name=pdf" class="link-primary">https://openreview.net/attachment?id=S9lk6dk4LL&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">video-language pre-training</span>
<span class="badge bg-primary">multimodal models</span>
<span class="badge bg-primary">tokenization</span>
<span class="badge bg-primary">video generation</span>
<span class="badge bg-primary">spatiotemporal dynamics</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces Video-LaVIT, a novel framework for unified video-language pre-training that addresses the challenges of effectively modeling video data's spatiotemporal dynamics. By decomposing videos into keyframes and motion vectors, the framework utilizes innovative tokenizers to efficiently represent visual and temporal information as discrete tokens, enabling Large Language Models (LLMs) to comprehend and generate both video and image content. The proposed method demonstrates competitive performance across 13 multimodal benchmarks, achieving state-of-the-art results in various tasks, including video comprehension and text-to-video generation without requiring extensive fine-tuning. The authors present extensive evaluations that showcase Video-LaVIT's capabilities and efficiency in handling complex video data, highlighting its potential as a robust solution for developing advanced multimodal AI systems.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Video-of-Thought: Step-by-Step Video Reasoning from Perception to Cognition</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=fO31YAyNbI&name=pdf" class="link-primary">https://openreview.net/attachment?id=fO31YAyNbI&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">video reasoning</span>
<span class="badge bg-primary">spatial-temporal understanding</span>
<span class="badge bg-primary">multimodal large language models</span>
<span class="badge bg-primary">cognitive interpretation</span>
<span class="badge bg-primary">commonsense reasoning</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper introduces "Video-of-Thought" (VoT), a novel framework designed to enhance video reasoning capabilities by integrating a Multimodal Large Language Model (MLLM) called MotionEpic, which facilitates fine-grained spatial-temporal understanding of videos through a structured video scene graph representation. The VoT framework employs a systematic, step-by-step approach to decompose complex video tasks into manageable sub-problems, progressing from low-level pixel perception to high-level cognitive interpretation. Extensive experiments across various complex video question-answering benchmarks demonstrate significant improvements over existing state-of-the-art approaches, highlighting the potential of this framework to achieve human-level reasoning in video understanding.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">VideoPoet: A Large Language Model for Zero-Shot Video Generation</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=LRkJwPIDuE&name=pdf" class="link-primary">https://openreview.net/attachment?id=LRkJwPIDuE&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">video generation</span>
<span class="badge bg-primary">large language models</span>
<span class="badge bg-primary">multimodal inputs</span>
<span class="badge bg-primary">zero-shot learning</span>
<span class="badge bg-primary">video editing</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper introduces VideoPoet, a novel architecture for high-quality video generation leveraging a large language model (LLM) framework. VideoPoet employs a decoder-only transformer that processes diverse input types—images, videos, text, and audio—through a two-stage training process: pretraining with multimodal generative objectives and task-specific adaptation. The model excels in zero-shot video generation, producing high-fidelity motions and the ability to generate coherent videos up to 10 seconds long. Unlike traditional diffusion models, VideoPoet integrates various video generation tasks into a single framework, allowing for seamless task chaining and editing capabilities, thus demonstrating state-of-the-art performance in generating realistic videos while maintaining temporal coherence.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">ViP: A Differentially Private Foundation Model for Computer Vision</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=6aKwVmHQI1&name=pdf" class="link-primary">https://openreview.net/attachment?id=6aKwVmHQI1&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">Differential Privacy</span>
<span class="badge bg-primary">Foundation Models</span>
<span class="badge bg-primary">Computer Vision</span>
<span class="badge bg-primary">Self-Supervised Learning</span>
<span class="badge bg-primary">Representation Learning</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">The paper presents ViP, a novel differentially private foundation model for computer vision that addresses privacy concerns associated with training on internet-scale datasets containing sensitive information. By employing masked autoencoders as a self-supervised learning technique, ViP is trained on the LAION400M dataset while maintaining a strict differential privacy budget. This model demonstrates comparable representation quality to traditional models like AlexNet, achieving a linear probing accuracy of 55.7% on ImageNet. The authors advocate for the potential of scaling differential privacy training using large unlabeled datasets, while highlighting the efficacy of combining synthetic data pre-training with differential privacy methods to enhance model performance. Overall, ViP sets a precedent for private learning in vision tasks, suggesting future avenues for improving privacy-preserving AI systems.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Weak-to-Strong Generalization: Eliciting Strong Capabilities With Weak Supervision</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=ghNRg2mEgN&name=pdf" class="link-primary">https://openreview.net/attachment?id=ghNRg2mEgN&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">weak supervision</span>
<span class="badge bg-primary">strong generalization</span>
<span class="badge bg-primary">AI alignment</span>
<span class="badge bg-primary">model training</span>
<span class="badge bg-primary">reinforcement learning</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper investigates the concept of weak-to-strong generalization, where strong pretrained models (like those in the GPT-4 family) are fine-tuned using labels generated by weaker models, and explores whether this weak supervision can effectively elicit the strong capabilities of these models. The authors demonstrate that strong models can outperform their weak supervisors through naive fine-tuning, but caution that this method alone does not fully recover their capabilities. They find that employing techniques such as auxiliary confidence loss, bootstrapping, and unsupervised fine-tuning significantly improves performance, suggesting that weak-to-strong generalization is feasible and can be enhanced with simple methods. The study highlights the challenges of aligning superhuman models, indicating that future research must address how to leverage weak supervision to ensure safe and effective AI behavior.</p>
</div>
</div>
</div>
</div>

<div class="col-sm-12 col-lg-6 col-xl-4 mb-4">
<div class="card shadow-sm">
<div class="card-body">
<h3 class="card-title">Zeroth-Order Methods for Constrained Nonconvex Nonsmooth Stochastic Optimization</h3>
<p class="card-text"><strong>Paper URL:</strong> <a href="https://openreview.net/attachment?id=PxHmxoFOgI&name=pdf" class="link-primary">https://openreview.net/attachment?id=PxHmxoFOgI&name=pdf</a></p>
<div class="mb-3">
<h3 class="h5">Topics</h3>
<div class="d-flex gap-2 flex-wrap">
<span class="badge bg-primary">stochastic optimization</span>
<span class="badge bg-primary">nonconvex functions</span>
<span class="badge bg-primary">nonsmooth analysis</span>
<span class="badge bg-primary">zeroth-order methods</span>
<span class="badge bg-primary">convergence guarantees</span>
</div>
</div>
<div class="mb-3">
<h3 class="h5">Summary</h3>
<p class="card-text">This paper addresses the challenge of constrained nonconvex nonsmooth stochastic optimization by providing non-asymptotic convergence analysis for zeroth-order methods. The authors introduce refined notions of approximate stationarity, specifically the (, , )-generalized Goldstein stationary points and (, )-Goldstein Frank-Wolfe stationary points, to facilitate the convergence analysis. They propose several stochastic zeroth-order algorithms, including projection-based and projection-free methods, demonstrating theoretical guarantees for achieving these approximate stationary points. Numerical experiments highlight the efficiency and effectiveness of the proposed algorithms in practical applications, particularly in robust low-rank matrix recovery problems.</p>
</div>
</div>
</div>
</div>

        </div>
    </div>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>
